[["data-table.html", "2 data.table", " 2 data.table data.table包是我最常用的R包，是我目前觉得最好用的数据处理包,大部分我需要用到的功能集成在包里，不需要很多的依赖包。我简单接触过python，julia两种语言，并没有深入比较，所以我这个好用的印象仅仅是个人感受。 data.table包是我用了较长一段时间tidyverse系列后发现的“数据处理包”。已经忘记最初是什么吸引了我，我猜测可能是“大数据处理利器”之类的标签吸引了我，因为我喜欢“快”。但是和大部分人可能不同的是，初次接触时，语法的“怪异”并没有给我带来多少麻烦，因为我本来就没有编程基础以及很深的R语言基础。 所以我死记硬背data.table里一些常用用法，尤其喜欢拿Excle的一些用法参照，去实现Excle上面的部分操作，从读取、增、改、删除、筛选、计算列等常规操作入手。慢慢熟悉data.table语法之后，将会享受data.table带来的便利，其简洁的语法以及高效的计算速度（相比tidyverse系列）。 另外，Python中也有该包，目前正在积极开发中，期待ing，毕竟python也是很好用，在不同需求下选择不同的语言实现功能。 官方关于data.table的基础介绍请参阅: https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html data.table 优势： 速度快 内存效率高 API生命周期管理好 语法简洁 "],["基础介绍.html", "2.1 基础介绍", " 2.1 基础介绍 本部分从data.table安装，内置的案例查看，到data.table的句式语法，实现基础行列筛选和聚合计算。 1.安装 安装详细信息请参考the Installation wiki，有关于不同系统安装首次以及相关说明。 install.packages(&quot;data.table&quot;) # latest development version: data.table::update.dev.pkg() 2.使用说明 通过以下代码查看内置的使用案例。 library(data.table) example(data.table) 2.1.1 读取数据 在我实际工作中接触的数据大部分以数据库,csv,Excel等形式存在，并且CSV格式数据较少。但是data.table包读取数据的fread函数仅接受CSV格式。如果是Excel格式文件，需要通过如readxl，openxlsx等包读入后转换为data.table格式数据。 fread 函数可以直接读取CSV格式文件,无论是本地文件或者在线文件. 本文会照搬很多官方关于data.table的demo. library(data.table) input &lt;- if (file.exists(&quot;./data/flights.csv&quot;)) { &quot;./data/flights.csv&quot; #本地文件 } else { &quot;https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights.csv&quot; #在线文件需翻墙 } flights &lt;- fread(input) #具体参数请参照文档 实际工作中可能会用到的encoding参数,编码 encoding=&#39;UTF-8&#39; head(flights) #&gt; year month day dep_delay arr_delay carrier origin dest air_time distance #&gt; 1: 2014 1 1 14 13 AA JFK LAX 359 2475 #&gt; 2: 2014 1 1 -3 13 AA JFK LAX 363 2475 #&gt; 3: 2014 1 1 2 9 AA JFK LAX 351 2475 #&gt; 4: 2014 1 1 -8 -26 AA LGA PBI 157 1035 #&gt; 5: 2014 1 1 2 1 AA JFK LAX 350 2475 #&gt; 6: 2014 1 1 4 0 AA EWR LAX 339 2454 #&gt; hour #&gt; 1: 9 #&gt; 2: 11 #&gt; 3: 19 #&gt; 4: 7 #&gt; 5: 13 #&gt; 6: 18 本文读取本地文件,如果该数据集下载失败,可更改地址为(http://www.zhongyufei.com/datatable/data/flights.csv) flights &lt;- fread(&quot;http://www.zhongyufei.com/datatable/data/flights.csv&quot;) 数据集记录的是 2014 年,纽约市3大机场(分别为:JFK 肯尼迪国际机场、 LGA 拉瓜迪亚机场,和 EWR 纽瓦克自由国际机场)起飞的航班信息。 具体的记录信息(特征列)，包括起飞时间、到达时间、延误时长、航空公司、始发机场、目的机场、飞行时长，和飞行距离等。 2.1.2 基本格式 DT[i, j, by]是data.table的基本样式，在不同位置上实现不同功能。 i-j-by DT[i, j, by] ## R: i j by ## SQL: where | order by select | update group by data.table个人理解主要有三大类参数,i参数做筛选,j参数做计算,by参数做分组. 拿Excel透视表类别,i位置参数当作『筛选』,by位置用来做汇总字段『行』,j位置当作『值』,如下所示: 透视表截图 1.代码实例 代码求2014年6月,从各始发机场到各目的机场的飞行距离求和. library(data.table) flights &lt;- fread(&quot;./data/flights.csv&quot;) flights[year==2014 &amp; month==6,.(求和项distance=sum(distance)),by=.(origin,dest)] #&gt; origin dest 求和项distance #&gt; 1: JFK LAX 2663100 #&gt; 2: JFK DFW 82069 #&gt; 3: JFK LAS 795792 #&gt; 4: JFK SFO 1967946 #&gt; 5: JFK SAN 349778 #&gt; --- #&gt; 191: EWR ANC 13480 #&gt; 192: EWR BZN 15056 #&gt; 193: LGA TVC 7205 #&gt; 194: LGA BZN 3788 #&gt; 195: JFK HYA 980 2.代码解释 i 的部分：条件year==2014 和 month==6 ; j 的部分：求和项distance=sum(distance)，写在.()中或者list()中； by 的部分.(origin,dest),重点是写在.()中,和Excel透视表一一对应。 至于为什么要用.()包裹起来，最开始默认为格式强制要求。就这个问题我想说：大部分人可能觉得是比较“怪异”的用法，并且不理解，从而可能留下data.table不好用，很古怪的印象，但是我觉得任何东西存在即合理，你学一个东西总得接受一些你可能不认可的东西，这样可能才是真正的学习，就像拿Python来做数据分析，我刚开始觉得pandas很难用，很反人类，但是后来知道python代码可以直接打包封装成exe后，觉得真香，说这么多主要是想表达我们学会挑选合适的工具用，适应它，用好它就可以了。 2.1.3 i j by 使用 使用data.table处理数据，接下来我们就用该函数读取数据演示i,j,by的简单使用。 2.1.3.1 i行筛选 行筛选是一种很常见的数据操作行为，类似我们Excel中的筛选，即按照一定条件筛选符合要求的数据。条件筛选一般分为单条件筛选、多条件筛选； 在筛选时涉及到条件判断，R语言中常用的条件判断分为逻辑运算、关系运算。常用的关系运算符 &gt;、 &lt;、==、!=、&gt;=、&lt;=分别代表大于、小于、等于、不等于、大于等于、小于等于。常用的逻辑运算符 &amp;、|、！等。 #单条件筛选 filghts[year == 2014] #筛选year==2014 #多条件筛选 用 &amp; 链接 flights[ year == 2014 &amp; month == 6] # | 相当于中文条件或 flights[ month == 5 | month == 6] # %in% 类似sql中in用法 flights[month %in% c(1,3,5,7,9)] # %between% 类似sql中between and 用法 flights[month %between% c(1,7)] 2.1.3.2 j列操作 数据集较大、字段较多时，由于无效信息较多可以做适当精选，这时需要我们筛选列。与sql中的select用法一致，即保留想要的字段。 .()或list()是data.table中的比较特殊的实现列筛选的用法。常规数字索引，字符向量索引同样有效。 #注意前面的. .() flights[,.(year,month,day,dep_delay,carrier,origin)] #&gt; year month day dep_delay carrier origin #&gt; 1: 2014 1 1 14 AA JFK #&gt; 2: 2014 1 1 -3 AA JFK #&gt; 3: 2014 1 1 2 AA JFK #&gt; 4: 2014 1 1 -8 AA LGA #&gt; 5: 2014 1 1 2 AA JFK #&gt; --- #&gt; 253312: 2014 10 31 1 UA LGA #&gt; 253313: 2014 10 31 -5 UA EWR #&gt; 253314: 2014 10 31 -8 MQ LGA #&gt; 253315: 2014 10 31 -4 MQ LGA #&gt; 253316: 2014 10 31 -5 MQ LGA # flights[,list(year,month,day,dep_delay,carrier,origin)] same above # not run # flights[,1:3] # not run # flights[,c(&#39;year&#39;,&#39;month&#39;,&#39;day&#39;)] setcolorder函数可以调整列的顺序，将常用的字段信息排在前面可以用过该函数实现。 # not run # setcolorder(x = flights,neworder = c( &quot;month&quot;,&quot;day&quot;,&quot;dep_delay&quot; ,&quot;arr_delay&quot;,&quot;carrier&quot; )) # 按照指定列顺序排序 其余字段保持不变,不是建立副本,是直接修改了flights 数据的列顺序 常规计算 根据最开始的Excel透视表截图，我们想要获得如截图一样的结果该怎么实现呢？代码如下： flights[year==2014 &amp; month==6,.(求和项distance=sum(distance),平均距离=mean(distance)),by=.(origin,dest)] 在i的位置做筛选，j的位置做计算，by指定分组字段。在j的位置可以做各种各样的计算，R中自带的函数，或者是自己定义的函数。 myfun &lt;- function(x){ x^2/2 } flights[year==2014 &amp; month==6,.(myfun(distance)),by=.(origin,dest)] #&gt; origin dest V1 #&gt; 1: JFK LAX 3062813 #&gt; 2: JFK LAX 3062813 #&gt; 3: JFK LAX 3062813 #&gt; 4: JFK LAX 3062813 #&gt; 5: JFK LAX 3062813 #&gt; --- #&gt; 26484: JFK HYA 19208 #&gt; 26485: JFK HYA 19208 #&gt; 26486: JFK HYA 19208 #&gt; 26487: JFK HYA 19208 #&gt; 26488: JFK HYA 19208 2.1.3.3 by 分组 分组是按照某种分组实现一定条件下某种聚合方式的计算。分组可以是单字段，多字段以及条件字段等。 1.按月分组 flights[,.(sum(distance)),by=.(month)] #&gt; month V1 #&gt; 1: 1 25112563 #&gt; 2: 2 22840391 #&gt; 3: 3 28716598 #&gt; 4: 4 27816797 #&gt; 5: 5 28030020 #&gt; 6: 6 29093557 #&gt; 7: 7 30059175 #&gt; 8: 8 30322047 #&gt; 9: 9 27615097 #&gt; 10: 10 28900834 2.多条件分组 dt &lt;- flights[,.(sum(distance)),by=.(carrier,origin)] head(dt) #&gt; carrier origin V1 #&gt; 1: AA JFK 20492213 #&gt; 2: AA LGA 12365282 #&gt; 3: AA EWR 3550217 #&gt; 4: AS EWR 1378748 #&gt; 5: B6 JFK 38117662 #&gt; 6: B6 EWR 4508574 #可直接重新命名 dt &lt;- flights[,.(sum(distance)),by=.(newcol1 = carrier,newcol2 = origin)] head(dt) #&gt; newcol1 newcol2 V1 #&gt; 1: AA JFK 20492213 #&gt; 2: AA LGA 12365282 #&gt; 3: AA EWR 3550217 #&gt; 4: AS EWR 1378748 #&gt; 5: B6 JFK 38117662 #&gt; 6: B6 EWR 4508574 3.按月份是否大于6分组 即得到是否大于6的两类分组 dt &lt;- flights[,.(sum(distance)),by=.(month&gt;6)] #by里面可以做计算 head(dt) #&gt; month V1 #&gt; 1: FALSE 161609926 #&gt; 2: TRUE 116897153 2.1.4 行列筛选总结 行筛选在 i 的位置上进行, 列筛选在 j 的位置上进行;data.table中j的位置比较灵活多变，但是i的位置大部分时候都是进行条件筛选。我们通过上述的行列筛选已经大概知道data.table中i,j的用法。也就是我们常规数据清洗过程中的数据筛选过程，筛选符合要求的数据记录。 dt &lt;- flights[ year == 2014 &amp; month == 6 &amp; day &gt;=15,.(year,month,day,dep_delay,carrier,origin)] head(dt) #&gt; year month day dep_delay carrier origin #&gt; 1: 2014 6 15 -4 AA JFK #&gt; 2: 2014 6 15 -8 AA JFK #&gt; 3: 2014 6 15 -12 AA JFK #&gt; 4: 2014 6 15 -4 AA LGA #&gt; 5: 2014 6 15 -3 AA JFK #&gt; 6: 2014 6 15 5 AA JFK "],["常规操作.html", "2.2 常规操作", " 2.2 常规操作 2.2.1 新增更新列 新增或删除或更新列是我们数据清洗过程中的常规操作，data.table中实现该类功能是通过:=符号实现。 新增 如下所示:新增addcol列，最后的[]是为了显示新增列的数据框,可不增加。 #data.table()函数创建data.table数据框 dt &lt;- data.table(col1=1:10,col2=letters[1:10],col3=LETTERS[1:10],col4=1:10) # 新增列 := dt[,addcol:=rep(&#39;新列&#39;,10)][] #最后的[]是为了显示新增列的数据框,可不增加 #&gt; col1 col2 col3 col4 addcol #&gt; 1: 1 a A 1 新列 #&gt; 2: 2 b B 2 新列 #&gt; 3: 3 c C 3 新列 #&gt; 4: 4 d D 4 新列 #&gt; 5: 5 e E 5 新列 #&gt; 6: 6 f F 6 新列 #&gt; 7: 7 g G 7 新列 #&gt; 8: 8 h H 8 新列 #&gt; 9: 9 i I 9 新列 #&gt; 10: 10 j J 10 新列 #dt[,addcol:=rep(&#39;新列&#39;,10)] 不会显示返回结果,加上[]会显示返回 # 新增多列 dt[,`:=`(newcol1=rep(&#39;newcol1&#39;,10),newcol2=rep(&#39;newcol2&#39;,10))][] #&gt; col1 col2 col3 col4 addcol newcol1 newcol2 #&gt; 1: 1 a A 1 新列 newcol1 newcol2 #&gt; 2: 2 b B 2 新列 newcol1 newcol2 #&gt; 3: 3 c C 3 新列 newcol1 newcol2 #&gt; 4: 4 d D 4 新列 newcol1 newcol2 #&gt; 5: 5 e E 5 新列 newcol1 newcol2 #&gt; 6: 6 f F 6 新列 newcol1 newcol2 #&gt; 7: 7 g G 7 新列 newcol1 newcol2 #&gt; 8: 8 h H 8 新列 newcol1 newcol2 #&gt; 9: 9 i I 9 新列 newcol1 newcol2 #&gt; 10: 10 j J 10 新列 newcol1 newcol2 删除 删除列即将列赋值NULL即可 # 删除列 dt[,col1:=NULL][] #&gt; col2 col3 col4 addcol newcol1 newcol2 #&gt; 1: a A 1 新列 newcol1 newcol2 #&gt; 2: b B 2 新列 newcol1 newcol2 #&gt; 3: c C 3 新列 newcol1 newcol2 #&gt; 4: d D 4 新列 newcol1 newcol2 #&gt; 5: e E 5 新列 newcol1 newcol2 #&gt; 6: f F 6 新列 newcol1 newcol2 #&gt; 7: g G 7 新列 newcol1 newcol2 #&gt; 8: h H 8 新列 newcol1 newcol2 #&gt; 9: i I 9 新列 newcol1 newcol2 #&gt; 10: j J 10 新列 newcol1 newcol2 # 删除多列 dt[,c(&#39;newcol1&#39;,&#39;newcol2&#39;):=NULL][] #&gt; col2 col3 col4 addcol #&gt; 1: a A 1 新列 #&gt; 2: b B 2 新列 #&gt; 3: c C 3 新列 #&gt; 4: d D 4 新列 #&gt; 5: e E 5 新列 #&gt; 6: f F 6 新列 #&gt; 7: g G 7 新列 #&gt; 8: h H 8 新列 #&gt; 9: i I 9 新列 #&gt; 10: j J 10 新列 更新 更新即重新赋值，将现有列参与计算等于是重新赋值，可以看成是更新列。 # 更新列 dt[,col1:=11:20][] #&gt; col2 col3 col4 addcol col1 #&gt; 1: a A 1 新列 11 #&gt; 2: b B 2 新列 12 #&gt; 3: c C 3 新列 13 #&gt; 4: d D 4 新列 14 #&gt; 5: e E 5 新列 15 #&gt; 6: f F 6 新列 16 #&gt; 7: g G 7 新列 17 #&gt; 8: h H 8 新列 18 #&gt; 9: i I 9 新列 19 #&gt; 10: j J 10 新列 20 # not run # 两列间计算 也可以理解为更新 dt[,newcol:=col1/col4] 2.2.2 排序 当我们清洗数据时，我们需要将数据框排序，我们可以使用setorder或setorderv函数实现排序。函数是data.table包的函数，比base R 中的order函数要节省内存。 注意：按照函数文档说法：Note that queries like x[order(.)] are optimised internally to use data.table’s fast order。即x[order(.)]这样的用法会被优化为data.table的排序方法。 set.seed(45L) DT = data.table(A=sample(3, 10, TRUE), B=sample(letters[1:3], 10, TRUE), C=sample(10)) setorder(DT, A, -B) #将DT按照A、B排序 A 升序,-B降序 # 和上面同样的效果 但是函数变成 setorderv setorderv(DT, c(&quot;A&quot;, &quot;B&quot;), c(1, -1)) 2.2.3 行筛选 上文已经大致讲过行筛选，但是行筛选使用有一定的技巧，涉及到运算的快慢。主要是逻辑条件的设置，交集并集之间的差异。除了上文中的关系运算筛选，逻辑运算筛选除外，data.table中还有几个常用的筛选函数。 数字向量筛选 %in%用法与 sql 中 in 用法类似。 # 筛选 %in% flights[ hour %in% seq(1,24,2) ] 字符向量筛选 %chin%用法与 %in% 类似，但仅仅针对字符。 # 字符筛选 flights[ origin %chin% c(&#39;JFK&#39;,&#39;LGA&#39;)] # not run 同上 %chin% 对字符速度筛选速度更快 #flights[ origin %in% c(&#39;JFK&#39;,&#39;LGA&#39;)] between 筛选 该函数的新特性矢量化挺实用。 #between 函数参数 #between(x, lower, upper, incbounds=TRUE, NAbounds=TRUE, check=FALSE) X &lt;- data.table(a=1:5, b=6:10, c=c(5:1)) X[b %between% c(7,9)] #&gt; a b c #&gt; 1: 2 7 4 #&gt; 2: 3 8 3 #&gt; 3: 4 9 2 X[between(b, 7, 9)] #效果同上 #&gt; a b c #&gt; 1: 2 7 4 #&gt; 2: 3 8 3 #&gt; 3: 4 9 2 X[c %between% list(a,b)] # 矢量化 #&gt; a b c #&gt; 1: 1 6 5 #&gt; 2: 2 7 4 #&gt; 3: 3 8 3 like 筛选 %like% 用法与SQL中 like 类似。 # %like% 用法与SQL中 like 类似 DT = data.table(Name=c(&quot;Mary&quot;,&quot;George&quot;,&quot;Martha&quot;), Salary=c(2,3,4)) DT[Name %like% &quot;^Mar&quot;] #&gt; Name Salary #&gt; 1: Mary 2 #&gt; 2: Martha 4 2.2.4 特殊符号 .SD,.BY,.N,.I,.NGRP和.GRP,.SDcols等,只能用在 j 的位置,.N 可以用在 i 的位置. DT = data.table(x=rep(c(&quot;b&quot;,&quot;a&quot;,&quot;c&quot;),each=3), v=c(1,1,1,2,2,1,1,2,2), y=c(1,3,6), a=1:9, b=9:1) DT #&gt; x v y a b #&gt; 1: b 1 1 1 9 #&gt; 2: b 1 3 2 8 #&gt; 3: b 1 6 3 7 #&gt; 4: a 2 1 4 6 #&gt; 5: a 2 3 5 5 #&gt; 6: a 1 6 6 4 #&gt; 7: c 1 1 7 3 #&gt; 8: c 2 3 8 2 #&gt; 9: c 2 6 9 1 X = data.table(x=c(&quot;c&quot;,&quot;b&quot;), v=8:7, foo=c(4,2)) X #&gt; x v foo #&gt; 1: c 8 4 #&gt; 2: b 7 2 # 用在i的位置 DT[.N] #取DT最后一行,.N 计数函数 #&gt; x v y a b #&gt; 1: c 2 6 9 1 DT[,.N] #DT 共有多少行记录 返回一个整数 #&gt; [1] 9 DT[, .N, by=x] #分组计数 #&gt; x N #&gt; 1: b 3 #&gt; 2: a 3 #&gt; 3: c 3 DT[, .SD, .SDcols=x:y] # 选择x 到y 列 #&gt; x v y #&gt; 1: b 1 1 #&gt; 2: b 1 3 #&gt; 3: b 1 6 #&gt; 4: a 2 1 #&gt; 5: a 2 3 #&gt; 6: a 1 6 #&gt; 7: c 1 1 #&gt; 8: c 2 3 #&gt; 9: c 2 6 #DT[, .SD, .SDcols=c(&quot;x&quot;,&quot;y&quot;)] 与上面不一样 DT[, .SD[1]] #取第一行 #&gt; x v y a b #&gt; 1: b 1 1 1 9 DT[, .SD[1], by=x] #按x列分组后 #&gt; x v y a b #&gt; 1: b 1 1 1 9 #&gt; 2: a 2 1 4 6 #&gt; 3: c 1 1 7 3 DT[, c(.N, lapply(.SD, sum)), by=x] #按照x分组后 行数计数和每列求和 #&gt; x N v y a b #&gt; 1: b 3 3 10 6 24 #&gt; 2: a 3 5 10 15 15 #&gt; 3: c 3 5 10 24 6 "],["常用函数.html", "2.3 常用函数", " 2.3 常用函数 常用函数指我们常用功能的函数，如排名、排序、非重复计数、判断、表连接、长宽转换等功能。 2.3.1 排序函数 frank frank和frankv函数参数如下： frank(x, ..., na.last=TRUE, ties.method=c(&quot;average&quot;, &quot;first&quot;, &quot;last&quot;, &quot;random&quot;, &quot;max&quot;, &quot;min&quot;, &quot;dense&quot;)) frankv(x, cols=seq_along(x), order=1L, na.last=TRUE, ties.method=c(&quot;average&quot;, &quot;first&quot;, &quot;random&quot;, &quot;max&quot;, &quot;min&quot;, &quot;dense&quot;)) 官方案例,如下所示: # on vectors x = c(4, 1, 4, NA, 1, NA, 4) # NAs are considered identical (unlike base R) # default is average frankv(x) # na.last=TRUE #&gt; [1] 4.0 1.5 4.0 6.5 1.5 6.5 4.0 frankv(x, na.last=FALSE) #&gt; [1] 6.0 3.5 6.0 1.5 3.5 1.5 6.0 # on data.table DT = data.table(x, y=c(1, 1, 1, 0, NA, 0, 2)) frankv(DT, cols=&quot;x&quot;) # same as frankv(x) from before #&gt; [1] 4.0 1.5 4.0 6.5 1.5 6.5 4.0 frankv(DT, cols=&quot;x&quot;, na.last=&quot;keep&quot;) #&gt; [1] 4.0 1.5 4.0 NA 1.5 NA 4.0 frankv(DT, cols=&quot;x&quot;, ties.method=&quot;dense&quot;, na.last=NA) #&gt; [1] 2 1 2 1 2 frank(DT, x, ties.method=&quot;dense&quot;, na.last=NA) # equivalent of above using frank #&gt; [1] 2 1 2 1 2 frankv在排序时,NA被认为是一样的,基础base R 中认为不一样. x &lt;- c(4, 1, 4, NA, 1, NA, 4) frankv(x) #&gt; [1] 4.0 1.5 4.0 6.5 1.5 6.5 4.0 rank(x) #&gt; [1] 4.0 1.5 4.0 6.0 1.5 7.0 4.0 升序降序选择 order参数只能为1或者-1.默认为1代表升序 frankv(x,order = 1L) #&gt; [1] 4.0 1.5 4.0 6.5 1.5 6.5 4.0 frankv(x,order = -1L) #&gt; [1] 2.0 4.5 2.0 6.5 4.5 6.5 2.0 排序方式选择 默认 average,还有dense,random,first,last,max,min等方式。其中dense是紧凑排名，random是随机让相同的随机排列后排名 x &lt;- c(1,1,1,2,3) frankv(x) #大小相同 排名相同,下一位排名除以2 frankv(x,ties.method = &#39;min&#39;) #大小相同 排名相同,取最小排名 frankv(x,ties.method = &#39;max&#39;) #大小相同 排名相同,取最大排名 frankv(x,ties.method = &#39;first&#39;) #相同大小排名以后往后递增 根据实际情况决定 frankv(x,ties.method = &#39;dense&#39;) frankv(x,ties.method = &#39;random&#39;) NA处理 默认是将NA排在最后,NAs是相同的，与base R 不一样。 na.last参数等于TRUE时，缺失值被排最后；如果等于FALSE,放在前面；如果等于NA，将被移除；如果等于“keep,”将会保留NA. frankv(c(NA,NA,1,2,3), na.last = TRUE,ties.method = &#39;first&#39;) #&gt; [1] 4 5 1 2 3 frankv(c(NA,NA,1,2,3), na.last = FALSE,ties.method = &#39;first&#39;) #&gt; [1] 1 2 3 4 5 frankv(c(NA,NA,1,2,3), na.last = NA,ties.method = &#39;first&#39;) #&gt; [1] 1 2 3 frankv(c(NA,NA,1,2,3), na.last = &#39;keep&#39;,ties.method = &#39;first&#39;) #&gt; [1] NA NA 1 2 3 2.3.2 判断函数 fifelse fifelse()类似dplyr::if_else()函数,相比base::ifelse() 更快。 x &lt;- c(1:4, 3:2, 1:4,5) fifelse(x &gt; 2L, x, x - 1L) #&gt; [1] 0 1 3 4 3 1 0 1 3 4 5 fifelse(x &gt; 2L,fifelse(x &gt;= 4L,x + 1L,x),x-1L) #&gt; [1] 0 1 3 5 3 1 0 1 3 5 6 fcase 与sql中的case when，与dplyr中的case_when()函数用法相似。相比fifelse相比，嵌套更加方便。 x = 1:10 fcase( x &lt; 5L, 1L, x &gt; 5L, 3L ) #&gt; [1] 1 1 1 1 NA 3 3 3 3 3 # not run 两种函数实现方式 fifelse(x &gt; 5,fifelse(x &gt;8,2,1),0) #&gt; [1] 0 0 0 0 0 1 1 1 2 2 fcase( x &gt; 8,2, x &gt; 5,1, default = 0 ) #&gt; [1] 0 0 0 0 0 1 1 1 2 2 2.3.3 交集 差集 合并 相当于base R 中 union(),intersect(),setdiff() 和setequal() 功能.all参数控制如何处理重复的行,和SQL中不同的是,data.table将保留行顺序. fintersect(x, y, all = FALSE) fsetdiff(x, y, all = FALSE) funion(x, y, all = FALSE) fsetequal(x, y, all = TRUE) x &lt;- data.table(c(1,2,2,2,3,4,4)) x2 &lt;- data.table(c(1,2,3,4)) # same set of rows as x y &lt;- data.table(c(2,3,4,4,4,5)) fintersect(x, y) # intersect fintersect(x, y, all=TRUE) # intersect all fsetdiff(x, y) # except fsetdiff(x, y, all=TRUE) # except all funion(x, y) # union funion(x, y, all=TRUE) # union all fsetequal(x, x2, all=FALSE) # setequal fsetequal(x, x2) # setequal all 2.3.4 连接 两个数据框之间左连,右连等操作,类似数据库中的left_join right_join,inner_join 等函数. 键入?merge()查看函数帮助,data.table 包中和base R 中都有merge 函数,当第一个数据框是data.table格式时启用data.table::merge(). ?merge() merge(x, y, by = NULL, by.x = NULL, by.y = NULL, all = FALSE, all.x = all, all.y = all, sort = TRUE, suffixes = c(&quot;.x&quot;, &quot;.y&quot;), no.dups = TRUE, allow.cartesian=getOption(&quot;datatable.allow.cartesian&quot;), # default FALSE ...) x.y为连个数据框,当两个数据框连接字段相同时,用by=c(’‘,’’)连接,不同时采用,by.x=,by.y= ,all,all.x,all.y等参数决定连接方式,sort 默认为排序,当不需要排序时更改参数,allow.cartesian=是否允许笛卡尔,默认不允许,当需要时设置为TURE. 2.3.5 长宽转换 主要是两个函数dcast以及melt实现长宽转换，实现Excel中部分透视表功能。具体的函数参数请自行查阅文档。 dcast函数能实现长转宽 参数如下：fun.aggregate函数指定聚合函数，value.var参数指定参与聚合的字段。formula指定聚合维度，格式用x+y~z，其中x,y在行的位置，z在列的位置。 dcast(data, formula, fun.aggregate = NULL, sep = &quot;_&quot;, ..., margins = NULL, subset = NULL, fill = NULL, drop = TRUE, value.var = guess(data), verbose = getOption(&quot;datatable.verbose&quot;)) 示例如下： dt &lt;- data.table(分公司=rep(c(&#39;华东&#39;,&#39;华南&#39;,&#39;华西&#39;,&#39;华北&#39;),1000), 季度=rep(c(&#39;一季度&#39;,&#39;二季度&#39;,&#39;三季度&#39;,&#39;四季度&#39;),1000), 销售额=sample(100:200,4000,replace = TRUE)) dcast(dt,分公司~季度,value.var = &quot;销售额&quot;,fun.aggregate = sum) #&gt; 分公司 一季度 三季度 二季度 四季度 #&gt; 1: 华东 149135 0 0 0 #&gt; 2: 华北 0 0 0 150585 #&gt; 3: 华南 0 0 149451 0 #&gt; 4: 华西 0 150649 0 0 从版本V1.9.6起可以同时对多个值实现不同聚合后的长转宽。 fun参数即 fun.aggregate的简写，可以是自定义的函数。 dt &lt;- data.table(x=sample(5,20,TRUE), y=sample(2,20,TRUE), z=sample(letters[1:2], 20,TRUE), d1 = runif(20), d2=1L) dcast(dt, x + y ~ z, fun=list(sum,mean), value.var=c(&quot;d1&quot;,&quot;d2&quot;)) #&gt; x y d1_sum_a d1_sum_b d2_sum_a d2_sum_b d1_mean_a d1_mean_b d2_mean_a #&gt; 1: 1 1 0.000 0.3141 0 1 NaN 0.3141 NaN #&gt; 2: 1 2 0.675 0.7524 1 1 0.675 0.7524 1 #&gt; 3: 2 1 0.722 1.9725 1 3 0.722 0.6575 1 #&gt; 4: 2 2 1.062 0.0657 2 1 0.531 0.0657 1 #&gt; 5: 3 2 0.329 0.0000 1 0 0.329 NaN 1 #&gt; 6: 4 1 1.934 0.3536 3 1 0.645 0.3536 1 #&gt; 7: 4 2 1.968 0.0000 3 0 0.656 NaN 1 #&gt; 8: 5 2 0.404 0.8995 1 1 0.404 0.8995 1 #&gt; d2_mean_b #&gt; 1: 1 #&gt; 2: 1 #&gt; 3: 1 #&gt; 4: 1 #&gt; 5: NaN #&gt; 6: 1 #&gt; 7: NaN #&gt; 8: 1 dcast(dt, x + y ~ z, fun=list(sum,mean), value.var=list(&quot;d1&quot;,&quot;d2&quot;)) #注意value.var是向量和列表时的区别 #&gt; x y d1_sum_a d1_sum_b d2_mean_a d2_mean_b #&gt; 1: 1 1 0.000 0.3141 NaN 1 #&gt; 2: 1 2 0.675 0.7524 1 1 #&gt; 3: 2 1 0.722 1.9725 1 1 #&gt; 4: 2 2 1.062 0.0657 1 1 #&gt; 5: 3 2 0.329 0.0000 1 NaN #&gt; 6: 4 1 1.934 0.3536 1 1 #&gt; 7: 4 2 1.968 0.0000 1 NaN #&gt; 8: 5 2 0.404 0.8995 1 1 melt函数实现宽转长 melt(data, id.vars, measure.vars, variable.name = &quot;variable&quot;, value.name = &quot;value&quot;, ..., na.rm = FALSE, variable.factor = TRUE, value.factor = FALSE, verbose = getOption(&quot;datatable.verbose&quot;)) 示例如下: ChickWeight = as.data.table(ChickWeight) setnames(ChickWeight, tolower(names(ChickWeight))) DT &lt;- melt(as.data.table(ChickWeight), id=2:4) # calls melt.data.table DT #&gt; time chick diet variable value #&gt; 1: 0 1 1 weight 42 #&gt; 2: 2 1 1 weight 51 #&gt; 3: 4 1 1 weight 59 #&gt; 4: 6 1 1 weight 64 #&gt; 5: 8 1 1 weight 76 #&gt; --- #&gt; 574: 14 50 4 weight 175 #&gt; 575: 16 50 4 weight 205 #&gt; 576: 18 50 4 weight 234 #&gt; 577: 20 50 4 weight 264 #&gt; 578: 21 50 4 weight 264 2.3.6 非重复计数 uniqueN相当于length(unique(x)),但是计算更快，内存效率更高。 x &lt;-sample(1:10,50,replace = TRUE) uniqueN(x) #&gt; [1] 10 DT &lt;- data.table(A = rep(1:3, each=4), B = rep(1:4, each=3), C = rep(1:2, 6), key = &quot;A,B&quot;) uniqueN(DT, by = key(DT)) #&gt; [1] 6 uniqueN(DT) #&gt; [1] 10 "],["高级函数.html", "2.4 高级函数", " 2.4 高级函数 高级函数并不是指使用难度，而是使用频率可能不高，但在实现某些功能时特别便利的函数。 如分组聚合的groupingsets,前后移动的shift等函数。 2.4.1 groupingsets 产生多个层次的合计数据，与sql中的grouping set功能相似。 用法 rollup(x, j, by, .SDcols, id = FALSE, ...) groupingsets(x, j, by, sets, .SDcols, id = FALSE, jj, ...) # rollup rollup(DT, j = lapply(.SD, sum), by = c(&quot;color&quot;,&quot;year&quot;,&quot;status&quot;), id=TRUE, .SDcols=&quot;value&quot;) rollup(DT, j = c(list(count=.N), lapply(.SD, sum)), by = c(&quot;color&quot;,&quot;year&quot;,&quot;status&quot;), id=TRUE) 如果要达到像Excel中透视表一样的效果，如下所示: Excel groupingsets透视表 rollup library(magrittr) DT &lt;- fread(&#39;./data/data-table-groupingsets.csv&#39;,encoding = &#39;UTF-8&#39;) (rollup(DT,j =list(以下项目的总和 =sum(value)),by = c(&quot;area&quot;,&quot;store_type&quot;),id = TRUE) %&gt;% setorderv(cols=c(&#39;area&#39;,&#39;grouping&#39;),na.last = TRUE)) #&gt; grouping area store_type 以下项目的总和 #&gt; 1: 0 华东 不可比 9 #&gt; 2: 0 华东 可比 309 #&gt; 3: 1 华东 &lt;NA&gt; 318 #&gt; 4: 0 华北 不可比 72 #&gt; 5: 0 华北 可比 173 #&gt; 6: 1 华北 &lt;NA&gt; 245 #&gt; 7: 0 华南 可比 86 #&gt; 8: 0 华南 不可比 79 #&gt; 9: 1 华南 &lt;NA&gt; 165 #&gt; 10: 0 华西 可比 2 #&gt; 11: 0 华西 不可比 198 #&gt; 12: 1 华西 &lt;NA&gt; 200 #&gt; 13: 3 &lt;NA&gt; &lt;NA&gt; 928 通过上述计算,发现计算结果与Excel透视表一样。 cube 观察cube()计算结果与rollup()差异，发现cube()聚合层次更多。 cube(DT,j = sum(value),by = c(&quot;area&quot;,&quot;store_type&quot;),id = TRUE) #&gt; grouping area store_type V1 #&gt; 1: 0 华东 不可比 9 #&gt; 2: 0 华东 可比 309 #&gt; 3: 0 华西 可比 2 #&gt; 4: 0 华西 不可比 198 #&gt; 5: 0 华南 可比 86 #&gt; 6: 0 华北 不可比 72 #&gt; 7: 0 华南 不可比 79 #&gt; 8: 0 华北 可比 173 #&gt; 9: 1 华东 &lt;NA&gt; 318 #&gt; 10: 1 华西 &lt;NA&gt; 200 #&gt; 11: 1 华南 &lt;NA&gt; 165 #&gt; 12: 1 华北 &lt;NA&gt; 245 #&gt; 13: 2 &lt;NA&gt; 不可比 358 #&gt; 14: 2 &lt;NA&gt; 可比 570 #&gt; 15: 3 &lt;NA&gt; &lt;NA&gt; 928 groupingsets 根据需要指定指定聚合的层次。 # 与本例中rollup 结果一致 groupingsets(DT,j = sum(value),by = c(&quot;area&quot;,&quot;store_type&quot;),sets = list(&#39;area&#39;,c(&quot;area&quot;,&quot;store_type&quot;), character()),id = TRUE) #&gt; grouping area store_type V1 #&gt; 1: 1 华东 &lt;NA&gt; 318 #&gt; 2: 1 华西 &lt;NA&gt; 200 #&gt; 3: 1 华南 &lt;NA&gt; 165 #&gt; 4: 1 华北 &lt;NA&gt; 245 #&gt; 5: 0 华东 不可比 9 #&gt; 6: 0 华东 可比 309 #&gt; 7: 0 华西 可比 2 #&gt; 8: 0 华西 不可比 198 #&gt; 9: 0 华南 可比 86 #&gt; 10: 0 华北 不可比 72 #&gt; 11: 0 华南 不可比 79 #&gt; 12: 0 华北 可比 173 #&gt; 13: 3 &lt;NA&gt; &lt;NA&gt; 928 # 与本例中cube 结果一致 groupingsets(DT,j = sum(value),by = c(&quot;area&quot;,&quot;store_type&quot;),sets = list(&#39;area&#39;,c(&quot;area&quot;,&quot;store_type&quot;),&quot;store_type&quot;, character()),id = TRUE) #&gt; grouping area store_type V1 #&gt; 1: 1 华东 &lt;NA&gt; 318 #&gt; 2: 1 华西 &lt;NA&gt; 200 #&gt; 3: 1 华南 &lt;NA&gt; 165 #&gt; 4: 1 华北 &lt;NA&gt; 245 #&gt; 5: 0 华东 不可比 9 #&gt; 6: 0 华东 可比 309 #&gt; 7: 0 华西 可比 2 #&gt; 8: 0 华西 不可比 198 #&gt; 9: 0 华南 可比 86 #&gt; 10: 0 华北 不可比 72 #&gt; 11: 0 华南 不可比 79 #&gt; 12: 0 华北 可比 173 #&gt; 13: 2 &lt;NA&gt; 不可比 358 #&gt; 14: 2 &lt;NA&gt; 可比 570 #&gt; 15: 3 &lt;NA&gt; &lt;NA&gt; 928 groupingsets: sets参数,用list()包裹想要聚合的字段组合,最后还有一个character(),加上该部分相当于全部聚合. 当by只有一个字段时,相当于汇总.用法类似sql中“().” 2.4.2 rleid 该函数根据分组生成长度列。 即将0011001110111101类似这种分组成1 1 2 2 3 3 4 4 4 5 6 6 6 6 7 8。在特定时候是很便捷的一个函数。如在计算股票连续上涨或下跌天数时。 rleid(c(0,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1)) #&gt; [1] 1 1 2 2 3 3 4 4 4 5 6 6 6 6 7 8 用法： rleid(..., prefix=NULL) rleidv(x, cols=seq_along(x), prefix=NULL) DT = data.table(grp=rep(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;A&quot;, &quot;B&quot;), c(2,2,3,1,2)), value=1:10) rleid(DT$grp) # get run-length ids #&gt; [1] 1 1 2 2 3 3 3 4 5 5 rleidv(DT, &quot;grp&quot;) # same as above #&gt; [1] 1 1 2 2 3 3 3 4 5 5 rleid(DT$grp, prefix=&quot;grp&quot;) # prefix with &#39;grp&#39; #&gt; [1] &quot;grp1&quot; &quot;grp1&quot; &quot;grp2&quot; &quot;grp2&quot; &quot;grp3&quot; &quot;grp3&quot; &quot;grp3&quot; &quot;grp4&quot; &quot;grp5&quot; &quot;grp5&quot; 2.4.3 shift 向前或向后功能,通俗来说就是向前或向后移动位置。 示例如下： x = 1:5 # lag with n=1 and pad with NA (returns vector) shift(x, n=1, fill=NA, type=&quot;lag&quot;) #&gt; [1] NA 1 2 3 4 其中参数n控制偏移量，n正负数和type的参数相对应。, n=-1 and type=‘lead’ 与 n=1 and type=’lag’效果相同。 在data.table上使用： DT = data.table(year=2010:2014, v1=runif(5), v2=1:5, v3=letters[1:5]) cols = c(&quot;v1&quot;,&quot;v2&quot;,&quot;v3&quot;) anscols = paste(&quot;lead&quot;, cols, sep=&quot;_&quot;) DT[, (anscols) := shift(.SD, 1, 0, &quot;lead&quot;), .SDcols=cols] 例如求某人连续消费时间间隔天数时： DT = data.table(dates =lubridate::ymd(c(20210105,20210115,20210124,20210218,20210424))) DT[,newdate:=shift(dates)] DT #&gt; dates newdate #&gt; 1: 2021-01-05 &lt;NA&gt; #&gt; 2: 2021-01-15 2021-01-05 #&gt; 3: 2021-01-24 2021-01-15 #&gt; 4: 2021-02-18 2021-01-24 #&gt; 5: 2021-04-24 2021-02-18 通过构造新列newdate，然后将两列相减dates-newdate即可得到每次购物间隔天数。 2.4.4 J J 是.(),list()等的别名。SJ是排序连接，CJ是交叉连接。 用法： # DT[J(...)] # J() only for use inside DT[...] # DT[.(...)] # .() only for use inside DT[...] # DT[list(...)] # same; .(), list() and J() are identical SJ(...) # DT[SJ(...)] CJ(..., sorted=TRUE, unique=FALSE) # DT[CJ(...)] CJ 我喜欢用CJ()函数创建笛卡尔积表。例如在商品运营中，时常需要将门店和商品形成笛卡尔积表，相比起dplyr::full_join() ,data.table::merge.data.table(allow.cartesian = TRUE ),CJ更加方便快捷。 # CJ usage examples CJ(c(5, NA, 1), c(1, 3, 2)) # sorted and keyed data.table #&gt; V1 V2 #&gt; 1: NA 1 #&gt; 2: NA 2 #&gt; 3: NA 3 #&gt; 4: 1 1 #&gt; 5: 1 2 #&gt; 6: 1 3 #&gt; 7: 5 1 #&gt; 8: 5 2 #&gt; 9: 5 3 # do.call(CJ, list(c(5, NA, 1), c(1, 3, 2))) # same as above # CJ(c(5, NA, 1), c(1, 3, 2), sorted=FALSE) # same order as input, unkeyed SJ SJ : Sorted Join. The same value as J() but additionally setkey() is called on all columns in the order they were passed to SJ. For efficiency, to invoke a binary merge rather than a repeated binary full search for each row of i. "],["运用.html", "2.5 运用", " 2.5 运用 2.5.1 自定义函数计算 1.自定义函数处理列 按照自定义函数计算修改单列或多列 # 测试函数 fun &lt;- function(x){ x &lt;- x^2+1 } DT &lt;- data.table(x=rep(c(&quot;b&quot;,&quot;a&quot;,&quot;c&quot;),each=3), v=c(1,1,1,2,2,1,1,2,2), y=c(1,3,6), a=1:9, b=9:1) DT[,.(newcol=fun(y)),by=.(x)] #&gt; x newcol #&gt; 1: b 2 #&gt; 2: b 10 #&gt; 3: b 37 #&gt; 4: a 2 #&gt; 5: a 10 #&gt; 6: a 37 #&gt; 7: c 2 #&gt; 8: c 10 #&gt; 9: c 37 #Not run #DT[,lapply(.SD,fun),.SDcols=c(&#39;y&#39;,&#39;a&#39;),by=.(x)] #多列参与计算 # 批量修改列 #Not run # myfun &lt;- function(x){ # return(x) # } # # dt &lt;- dt[,colnames(dt):=lapply(.SD[,1:ncol(dt)],myfun)] #很重要的用法 2.5.2 带汇总的聚合运算 按照by的字段级别汇总. rollup 分组聚合后设置id=TRUE将各个级别的汇总显示清晰,当by字段只有一个是和正常聚合计算没有区别.以下是官方案例. #Usage #rollup(x, j, by, .SDcols, id = FALSE, ...) n = 24L set.seed(25) DT &lt;- data.table( color = sample(c(&quot;green&quot;,&quot;yellow&quot;,&quot;red&quot;), n, TRUE), year = as.Date(sample(paste0(2011:2015,&quot;-01-01&quot;), n, TRUE)), status = as.factor(sample(c(&quot;removed&quot;,&quot;active&quot;,&quot;inactive&quot;,&quot;archived&quot;), n, TRUE)), amount = sample(1:5, n, TRUE), value = sample(c(3, 3.5, 2.5, 2), n, TRUE) ) rollup(DT, j = sum(value), by = c(&quot;color&quot;,&quot;year&quot;,&quot;status&quot;)) # default id=FALSE #&gt; color year status V1 #&gt; 1: red 2015-01-01 active 3.5 #&gt; 2: green 2015-01-01 inactive 5.5 #&gt; 3: green 2014-01-01 archived 3.5 #&gt; 4: green 2015-01-01 archived 2.0 #&gt; 5: yellow 2014-01-01 active 4.5 #&gt; 6: red 2013-01-01 inactive 2.0 #&gt; 7: green 2011-01-01 active 6.0 #&gt; 8: red 2014-01-01 inactive 2.5 #&gt; 9: green 2011-01-01 archived 2.5 #&gt; 10: yellow 2015-01-01 active 2.0 #&gt; 11: red 2012-01-01 archived 2.0 #&gt; 12: red 2011-01-01 removed 3.5 #&gt; 13: green 2014-01-01 inactive 8.0 #&gt; 14: green 2011-01-01 removed 2.0 #&gt; 15: yellow 2012-01-01 archived 2.5 #&gt; 16: red 2013-01-01 removed 3.5 #&gt; 17: green 2013-01-01 active 3.0 #&gt; 18: green 2014-01-01 removed 2.5 #&gt; 19: red 2011-01-01 archived 3.0 #&gt; 20: red 2015-01-01 &lt;NA&gt; 3.5 #&gt; 21: green 2015-01-01 &lt;NA&gt; 7.5 #&gt; 22: green 2014-01-01 &lt;NA&gt; 14.0 #&gt; 23: yellow 2014-01-01 &lt;NA&gt; 4.5 #&gt; 24: red 2013-01-01 &lt;NA&gt; 5.5 #&gt; 25: green 2011-01-01 &lt;NA&gt; 10.5 #&gt; 26: red 2014-01-01 &lt;NA&gt; 2.5 #&gt; 27: yellow 2015-01-01 &lt;NA&gt; 2.0 #&gt; 28: red 2012-01-01 &lt;NA&gt; 2.0 #&gt; 29: red 2011-01-01 &lt;NA&gt; 6.5 #&gt; 30: yellow 2012-01-01 &lt;NA&gt; 2.5 #&gt; 31: green 2013-01-01 &lt;NA&gt; 3.0 #&gt; 32: red &lt;NA&gt; &lt;NA&gt; 20.0 #&gt; 33: green &lt;NA&gt; &lt;NA&gt; 35.0 #&gt; 34: yellow &lt;NA&gt; &lt;NA&gt; 9.0 #&gt; 35: &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 64.0 #&gt; color year status V1 #rollup(DT, j = sum(value), by = c(&quot;color&quot;,&quot;year&quot;,&quot;status&quot;), id=TRUE) 个人运用,实际工作中常常需要汇总项,汇总项在Excel透视表中很简单,在R中我之前是构造重复的数据源聚合汇总出现汇总项,极大浪费内存,运算速度减慢. 新方法 rollup set.seed(25) N &lt;- 1000 dt &lt;- data.table(col1=sample(LETTERS[1:5],N,replace = T),col2=sample(letters[1:5],N,replace = T),num=1:N) rollup(dt,j=c(list(sum(num))),by=c(&#39;col1&#39;,&#39;col2&#39;)) #&gt; col1 col2 V1 #&gt; 1: E a 19926 #&gt; 2: D a 20966 #&gt; 3: A d 12927 #&gt; 4: A b 20862 #&gt; 5: A c 15331 #&gt; 6: B d 15414 #&gt; 7: C e 20794 #&gt; 8: D e 16110 #&gt; 9: C d 22152 #&gt; 10: A a 18378 #&gt; 11: C c 19474 #&gt; 12: E d 18831 #&gt; 13: B b 19941 #&gt; 14: C a 19652 #&gt; 15: E c 16734 #&gt; 16: E e 24137 #&gt; 17: E b 21988 #&gt; 18: D b 16607 #&gt; 19: B c 25720 #&gt; 20: B a 22109 #&gt; 21: A e 18724 #&gt; 22: C b 24323 #&gt; 23: D d 20508 #&gt; 24: D c 19668 #&gt; 25: B e 29224 #&gt; 26: E &lt;NA&gt; 101616 #&gt; 27: D &lt;NA&gt; 93859 #&gt; 28: A &lt;NA&gt; 86222 #&gt; 29: B &lt;NA&gt; 112408 #&gt; 30: C &lt;NA&gt; 106395 #&gt; 31: &lt;NA&gt; &lt;NA&gt; 500500 #&gt; col1 col2 V1 #同上 添加汇总项名称 total #rollup(dt,j=c(list(total=sum(num))),by=c(&#39;col1&#39;,&#39;col2&#39;)) #添加id=TRUE参数,多出的grouping 列显示聚合级别 #rollup(dt,j=c(list(total=sum(num))),by=c(&#39;col1&#39;,&#39;col2&#39;),id=TRUE) 2.groupingsets 按照指定字段聚合.包作者说相同与SQL中的 GROUPING SETS 操作.详情参照postgresql res &lt;- groupingsets(DT, j = c(list(count=.N), lapply(.SD, sum)), by = c(&quot;color&quot;,&quot;year&quot;,&quot;status&quot;), sets = list(&quot;color&quot;, c(&quot;year&quot;,&quot;status&quot;), character()), id=TRUE) head(res) #&gt; grouping color year status count amount value #&gt; 1: 3 red &lt;NA&gt; &lt;NA&gt; 7 19 20.0 #&gt; 2: 3 green &lt;NA&gt; &lt;NA&gt; 13 43 35.0 #&gt; 3: 3 yellow &lt;NA&gt; &lt;NA&gt; 4 10 9.0 #&gt; 4: 4 &lt;NA&gt; 2015-01-01 active 2 8 5.5 #&gt; 5: 4 &lt;NA&gt; 2015-01-01 inactive 2 5 5.5 #&gt; 6: 4 &lt;NA&gt; 2014-01-01 archived 1 3 3.5 注意groupingsets函数中sets参数,用list()包裹想要聚合的字段组合,最后还有一个character(),加上该部分相当于全部聚合.当by只有一个字段时,相当于汇总.用法类似sql中“().” 上述语句结果等同于下面sql. select color ,year, status,count(*) count,sum(amount) amount,sum(value) value FROM dbo.DT GROUP BY GROUPING SETS( (color), (year,status), () ---- 类似 character() ) 最后还有cube()函数,可?cube查看用法 2.5.3 行列转变 一列变多行 用tstrsplit()函数实现 n &lt;- 10 dt &lt;- data.table(name=LETTERS[1:n],char=rep(&#39;我-爱-R-语-言&#39;),n) res &lt;- dt[,.(newcol=tstrsplit(char,&#39;-&#39;)),by=.(name)] head(res) #&gt; name newcol #&gt; 1: A 我 #&gt; 2: A 爱 #&gt; 3: A R #&gt; 4: A 语 #&gt; 5: A 言 #&gt; 6: B 我 多行变一列 res[,.(char=paste0(newcol,collapse = &#39;-&#39;)),by=.(name)] #&gt; name char #&gt; 1: A 我-爱-R-语-言 #&gt; 2: B 我-爱-R-语-言 #&gt; 3: C 我-爱-R-语-言 #&gt; 4: D 我-爱-R-语-言 #&gt; 5: E 我-爱-R-语-言 #&gt; 6: F 我-爱-R-语-言 #&gt; 7: G 我-爱-R-语-言 #&gt; 8: H 我-爱-R-语-言 #&gt; 9: I 我-爱-R-语-言 #&gt; 10: J 我-爱-R-语-言 #同上 #res[,.(char=stringr::str_c(newcol,collapse = &#39;-&#39;)),by=.(name)] # A 我-爱-R-语-言 # B 我-爱-R-语-言 # C 我-爱-R-语-言 # D 我-爱-R-语-言 # E 我-爱-R-语-言 # F 我-爱-R-语-言 # G 我-爱-R-语-言 # H 我-爱-R-语-言 # I 我-爱-R-语-言 # J 我-爱-R-语-言 "]]
