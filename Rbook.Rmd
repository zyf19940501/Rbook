--- 
title: "R学习笔记"
knit: "bookdown::render_book"
author: "Yufei Zhong"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
description: "个人学习R语言笔记"
---
```{r include=FALSE, cache=FALSE}
set.seed(1014)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
 # cache = TRUE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)

options(dplyr.print_min = 6, dplyr.print_max = 6)
```


# 说明

```{r eval=TRUE,include=FALSE}
a <- version
```

作为商业数据分析师，我学习使用`R`已经有较长一段时间，主要用`R`来处理数据，自动化报表，ETL，可视化等；另外用R包`shiny`做web看板。


本文主要记录个人学习数据处理相关R包的过程，主要从`tidyverse`系列以及`data.table`两套语法做数据处理。co



```{r echo=FALSE,fig.align='center'}
library(DiagrammeR)
mermaid(diagram = "
graph LR
A[R数据处理] --> B[tidyverse]
A-->C[data.table]
A-->D[Database]
A-->E[read and write data]
A-->F[loop and iteration]

B-->B1[tidyr]
B-->B2[dplyr]
B-->B3[lubridate]
B-->B4[stringr]

C-->C1[read and write]
C-->C2[f系列函数]
C-->C3[set系列函数]
C-->C4[misc]

D-->D1[DBI]
D-->D2[ROralce]

E-->E1[readxl]
E-->E2[readr]
E-->E3[vroom]
        
",width =500,height = 1250)
```


`R`极大的拓展了数据处理能力,让我很轻松方便处理数据，有更多精力时间聚焦在具体问题上。但因个人能力有限，难免出现错误，如阅读中发现错误，欢迎联系本人更正。





Email: <598253220@qq.com> 

微信公众号: 宇飞的世界 

语雀: https://www.yuque.com/zyufei




```{r}
#查看版本信息
sessionInfo()
```


<!--chapter:end:index.Rmd-->

```{r include=FALSE, cache=FALSE}
set.seed(1014)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
 # cache = TRUE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)

options(dplyr.print_min = 6, dplyr.print_max = 6)
```
```{r setup3, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,eval = FALSE)
```


# 读写数据

在我们使用R做数据处理前，我们首先需要将数据从外界导入R中。但是现实生活中数据类型复杂，存在各种各样的数据文件。我们从连接方式简单区分为文本数据、数据库数据，也就是用文件存放的数据或在数据库中的数据。

关于和数据库的连接交互，请查看数据库章节。本章主要记录常用的Excel、csv、txt等文本文件的读写方式。


## readxl

readxl软件包使R获取Excel数据变得简洁。与现有的软件包(例如：xlsx)相比，readxl没有外部依赖性。容易在所有的操作系统安装使用。

readxl[项目地址](https://readxl.tidyverse.org/)。本节大部分代码来源项目官网介绍，可自行查阅官网。

### 安装

从CRAN安装最新发行版本的最简单方法是安装整个tidyverse。

```{r eval=FALSE}
install.packages("tidyverse")
```

> 由于readxl不是tidyverse核心加载包，使用时任需要加载library(readxl)

或者是从CRAN仅安装readxl;

```{r eval = FALSE}
install.packages("readxl")
```

从github安装开发版：

```{r eval = FALSE}
# install.packages("devtools")
devtools::install_github("tidyverse/readxl")
```


### 用法

1.读取

readxl包中包含了几个示例文件，我们在接下来的案例中使用。

- 查看readxl包中自带xlsx文件

```{r}
library(readxl)
readxl_example()
readxl_example("clippy.xls")
```

`read_excel()`可读取xls和xlsx文件。

```{r}
xlsx_example <- readxl_example("datasets.xlsx")
read_excel(xlsx_example)
```

通过函数`excel_sheets()`查看Excel的sheet名称

```{r}
excel_sheets(xlsx_example)
```

指定worksheet的名字读取，可以是sheet的名字或序号。

当我们要读取的本地xlsx文件有多个sheets时，通过值定sheet参数读取指定的sheet。

```{r}
read_excel(xlsx_example, sheet = "chickwts")
```

读取xlsx文件的指定位置，有多种方法控制。本处提供几个案例，请`?read_excel()`查看帮助。

```{r eval=FALSE}
read_excel(path, sheet = NULL, range = NULL, col_names = TRUE,
  col_types = NULL, na = "", trim_ws = TRUE, skip = 0,
  n_max = Inf, guess_max = min(1000, n_max),
  progress = readxl_progress(), .name_repair = "unique")
```

range接受单元格范围，最简单的表示方式即Excle中单元格表示方法,如as range = "D12:F15" or range = "R1C12:R6C15".

其余参数中，个人觉得col_types比较重要，可以指定列的类型。可用选项:"skip", "guess", "logical", "numeric", "date", "text" or "list"。

## writexl


writexl包目前的功能比较简单，仅有读写Excel功能，但优势是速度较快，尤其是写入Excel时。[项目地址](https://docs.ropensci.org/writexl/)

### 用法

安装 

```{r eval = FALSE}
install.packages("writexl")
```

参数

```{r eval=FALSE}
write_xlsx(
  x,
  path = tempfile(fileext = ".xlsx"),
  col_names = TRUE,
  format_headers = TRUE,
  use_zip64 = FALSE
)
```


输出Excel

```{r eval=FALSE}
library(writexl)
writexl::write_xlsx(iris,path = 'iris.xlsx')
write_xlsx(list(mysheet1 = iris,mysheet2 = iris),path = 'iris.xlsx')

```


效率比较

```{r}
library(microbenchmark)
library(nycflights13)
microbenchmark(
  writexl = writexl::write_xlsx(flights, tempfile()),
  openxlsx = openxlsx::write.xlsx(flights, tempfile()),
  times = 2
)
```

其它功能

```{r eval=FALSE}
df <- data.frame(
  name = c("UCLA", "Berkeley", "Jeroen"),
  founded = c(1919, 1868, 2030),
  website = xl_hyperlink(c("http://www.ucla.edu", "http://www.berkeley.edu", NA), "homepage")
)
df$age <- xl_formula('=(YEAR(TODAY()) - INDIRECT("B" & ROW()))')
write_xlsx(df, 'universities.xlsx')

# cleanup
unlink('universities.xlsx')
```

## openxlsx

openxlsx是当我需要定制输出Excel表格或报表时常用R包。目前该包的版本4.2.3，通过使用Rcpp加速，包的读写速度在Excel的百万级下是可接受状态，包的相关函数功能完善且简易好用，并且正在积极开发中，相信它以后功能会越来越强大。

项目官方地址:<https://ycphs.github.io/openxlsx/index.html>

个人感觉主要优势：

- 不依赖java环境
- 读写速度可接受
- 可设置条件格式，与Excel中『开始』选项卡的条件格式功能接近
- 可批量插入ggplot2图
- 可插入公式
- 可渲染大部分Excel格式，并且效率相比部分python包高效
- 可添加页眉页脚以及其他格式，方便直接打印
- 功能稳定可用并且在积极开发中

版本信息查看

```{r}
packageVersion("openxlsx")
```


本人公众号:宇飞的世界中有更加详细的阐述:<https://mp.weixin.qq.com/s/ZD0dJb0y8fsWGI1dCPh2mQ>

### 安装

稳定版

```{r eval=FALSE}
# 稳定版
install.packages("openxlsx", dependencies = TRUE, repos = "https://mirrors.tuna.tsinghua.edu.cn/CRAN/")
```

开发版

```{r eval = FALSE}
install.packages(c("Rcpp", "devtools"), dependencies = TRUE)
library(devtools)
install_github("ycphs/openxlsx")
```


### 基础功能

本文仅呈现基础功能部分，即读写EXCEL文件。其它功能，请查阅项目官方地址或微信公众号文章[R包-openxlsx-学习笔记](https://mp.weixin.qq.com/s/ZD0dJb0y8fsWGI1dCPh2mQ)

#### 读取Excel

read.xlsx()是读取函数，主要参数如下：

```{r eval=FALSE}
library(openxlsx)
read.xlsx(
  xlsxFile,
  sheet = 1,
  startRow = 1,
  colNames = TRUE,
  rowNames = FALSE,
  detectDates = FALSE,
  skipEmptyRows = TRUE,
  skipEmptyCols = TRUE,
  rows = NULL,
  cols = NULL,
  check.names = FALSE,
  sep.names = ".",
  namedRegion = NULL,
  na.strings = "NA",
  fillMergedCells = FALSE
)
```

以上参数中需要注意 ：

detecDates参数，当你的Excel表格中带日期列时需要将参数设置为TRUE,不然将会把日期识别为数字读入。


fillMergedCells参数，当你读取的表格中存在合并单元格，将用值填充其他全部单元格,如下所示：

![](https://gitee.com/zhongyufei/photo-bed/raw/pic/img/merge-cell-xlsx.png)

```{r eval=FALSE}
read.xlsx('./test.xlsx',detectDates = TRUE,fillMergedCells = TRUE)
```

读取后如下所示：

![openxlsx-merge-xlsx](https://gitee.com/zhongyufei/photo-bed/raw/pic/img/R-read-merge-xlsx.png)


readWorkbook()也可以读取Excel表格数据，参数与read.xlsx基本一致。

```{r eval=FALSE}
xlsxFile <- system.file("extdata", "readTest.xlsx", package = "openxlsx")
df1 <- readWorkbook(xlsxFile = xlsxFile, sheet = 1)
```

#### 写入Excel

我们将R中的数据有时候需要导出到Excle中，这时就利用函数将data.frame写入Excle。

write.xlsx()函数写入

```{r eval=FALSE}
write.xlsx(iris, file = "writeXLSX1.xlsx", colNames = TRUE, borders = "columns")
```


带格式输出

```{r eval=FALSE}
hs <- createStyle(
  textDecoration = "BOLD", fontColour = "#FFFFFF", fontSize = 12,
  fontName = "Arial Narrow", fgFill = "#4F80BD"
)
## Not run: 
write.xlsx(iris,
  file = "writeXLSX3.xlsx",
  colNames = TRUE, borders = "rows", headerStyle = hs
)
```

或者是用如下方式写入：

不带任何格式写入，共计四步。第一步创建workbook,第二步添加sheet,第三步写入数据，第四步保存workbook。

```{r eval=FALSE}
df <- data.frame(a=1:10,b=1:10,d=1:10)
wb <- createWorkbook(creator = 'zhongyf',title = 'test')
addWorksheet(wb,sheetName = 'test')
writeData(wb,sheet = 'test',x = df)
saveWorkbook(wb, "test.xlsx", overwrite = TRUE)
```


### 带格式输出

我们以上面四步输出的方式举例，拆解其中四个函数的参数。

- createWorkbook()

- addWorksheet()

- writeData()

- saveWorkbook()

首先看看包中自带的例子，我们分解其中的参数。

```{r eval=FALSE}
wb <- createWorkbook("Fred")

## Add 3 worksheets
addWorksheet(wb, "Sheet 1")
addWorksheet(wb, "Sheet 2", gridLines = FALSE)
addWorksheet(wb, "Sheet 3", tabColour = "red")
addWorksheet(wb, "Sheet 4", gridLines = FALSE, tabColour = "#4F81BD")

## Headers and Footers
addWorksheet(wb, "Sheet 5",
  header = c("ODD HEAD LEFT", "ODD HEAD CENTER", "ODD HEAD RIGHT"),
  footer = c("ODD FOOT RIGHT", "ODD FOOT CENTER", "ODD FOOT RIGHT"),
  evenHeader = c("EVEN HEAD LEFT", "EVEN HEAD CENTER", "EVEN HEAD RIGHT"),
  evenFooter = c("EVEN FOOT RIGHT", "EVEN FOOT CENTER", "EVEN FOOT RIGHT"),
  firstHeader = c("TOP", "OF FIRST", "PAGE"),
  firstFooter = c("BOTTOM", "OF FIRST", "PAGE")
)

addWorksheet(wb, "Sheet 6",
  header = c("&[Date]", "ALL HEAD CENTER 2", "&[Page] / &[Pages]"),
  footer = c("&[Path]&[File]", NA, "&[Tab]"),
  firstHeader = c(NA, "Center Header of First Page", NA),
  firstFooter = c(NA, "Center Footer of First Page", NA)
)

addWorksheet(wb, "Sheet 7",
  header = c("ALL HEAD LEFT 2", "ALL HEAD CENTER 2", "ALL HEAD RIGHT 2"),
  footer = c("ALL FOOT RIGHT 2", "ALL FOOT CENTER 2", "ALL FOOT RIGHT 2")
)

addWorksheet(wb, "Sheet 8",
  firstHeader = c("FIRST ONLY L", NA, "FIRST ONLY R"),
  firstFooter = c("FIRST ONLY L", NA, "FIRST ONLY R")
)

## Need data on worksheet to see all headers and footers
writeData(wb, sheet = 5, 1:400)
writeData(wb, sheet = 6, 1:400)
writeData(wb, sheet = 7, 1:400)
writeData(wb, sheet = 8, 1:400)

## Save workbook
## Not run: 
saveWorkbook(wb, "addWorksheetExample.xlsx", overwrite = TRUE)
```

### 基础函数


输出Excel的四步。`createWorkbook`，` addWorksheet`,`writeDataTable`,`saveWorkbook`四个函数的参数解释。

- createWorkbook

```{r eval=FALSE }
createWorkbook(
  creator = ifelse(.Platform$OS.type == "windows", Sys.getenv("USERNAME"),
    Sys.getenv("USER")),
  title = NULL,
  subject = NULL,
  category = NULL
)
```

```{r eval=FALSE}
wb <- createWorkbook(
  creator = "宇飞的世界",
  title = "标题",
  subject = "主题",
  category = "类别目录"
)

```



- addWorksheet


```{r eval=FALSE}
addWorksheet(
  wb,
  sheetName,
  gridLines = TRUE,
  tabColour = NULL,
  zoom = 100,
  header = NULL,
  footer = NULL,
  evenHeader = NULL,
  evenFooter = NULL,
  firstHeader = NULL,
  firstFooter = NULL,
  visible = TRUE,
  paperSize = getOption("openxlsx.paperSize", default = 9),
  orientation = getOption("openxlsx.orientation", default = "portrait"),
  vdpi = getOption("openxlsx.vdpi", default = getOption("openxlsx.dpi", default = 300)),
  hdpi = getOption("openxlsx.hdpi", default = getOption("openxlsx.dpi", default = 300))
)
```


```{r eval=FALSE}
gridLines参数：表格中是否有网格线，在Excle『视图』选项卡下面的网格线去除打勾的效果一致

tabColour参数：输出表格sheet标签颜色

zoom：发大缩小，默认是100，可选范围10-400

header:页眉 长度为3的字符向量，左、中、右三个位置，用Na可跳过一位置，以下页眉页脚相同。

footer: 页脚

evenHeader: 每页页眉

evenFooter: 每页页脚

firstHeader: 第一页页眉

firstFooter: 第一页页脚

visible:sheet是否隐藏，如果为否sheet将被隐藏

paperSize:页面大小,详见 ?pageSetup 

orientation:One of "portrait" or "landscape" 不清楚干嘛用

vdpi: 屏幕分辨率 默认值即可，不用调整

hdpi: 屏幕分辨率 默认值即可，不用调整
```




- writeDataTable


writeDataTable()函数将data.frame写入Excel。

wb:即createWorkbook()函数创建



- saveWorkbook

```{r eval=FALSE}
saveWorkbook(wb, file, overwrite = FALSE, returnValue = FALSE)
```

参数较为简单，wb即上文中的workbook对象，file即输出的文件名，overwrite即如果存在是否覆盖，returnValue如果设置为TRUE，返回TRUE代表保存成功




## readr

## vroom

<!--chapter:end:read-write-data.Rmd-->

```{r include=FALSE, cache=FALSE}
set.seed(1014)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
 # cache = TRUE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)

options(dplyr.print_min = 6, dplyr.print_max = 6)
```

```{r setup2, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#  dplyr

`dplyr`包是`tidyverse`系列中的核心包之一,dplyr是**A Grammar of Data Manipulation **，即dplyr是数据处理的语法。


与`sql`相比，用R实现相同功能的好处：

- 代码量极大减少

- 当逻辑复杂时，`R`可以按照顺序一步步实现，无需嵌套，实现过程简单

- 该包就是从数据库相关操作中抽象而来，迁移成本低

- 配合`dbplyr`包使用，大部分情况下可以扔掉`sql`语法，从而实现不同数据库间语法并不完全一致时，代码可重复使用


本章节利用`R`语言完成与`Excel透视表`或`sql`语句的功能，将从行条件筛选、排序、分组聚合、表关联等方面记录`R`的实现方式。

> 本章节会照搬dplyr包中的部分案例

## 前言


数据操作在数据库中往往被增、改、删、查四字描述，加上表连接查询基本涵盖了大部分的数据库数据操作。在tidyverse系列中的dplyr包通过一组动词来解决相似数据操作动作。

在本章介绍部分，我们将拿R与Excel中的数据操作做类比，以达到Excel中透视表等功能。

###  安装

dplyr包可以直接安装。

```{r eval=FALSE}
## 最简单是的方式就是安装tidyverse
install.packages('tidyverse')

## 或者仅仅安装 tidyr:
install.packages('dplyr')

## 或者从github 安装开发版本
## install.packages("devtools")
devtools::install_github("tidyverse/dplyr")
```


### 介绍

`dplyr`包提供一组动词来解决最常见的数据处理问题：

- `mutate()` 添加新变量,现有变量的函数

- `select()` 筛选列,根据现有变量名称选择变量

- `filter()` 筛选行，根据条件筛选

- `summarise()` 按照一定条件汇总聚合

- `arrange()` 行排序

以上动词都可以和`group_by()`结合，使我们可以按组执行以上任何操作。除了以上单个表操作的动词，dplyr中还有操作两表(表关联)的动词，可以通过`vignette("two-table")`查看学习。   


**Excel类比**

类比Excel数据操作功能,`filter`实现筛选，`mutate`实现列计算，`summarise`配合`group_by`实现数据透视表，`arrange`实现排序功能。
另外配合`dplyr::left_join()`等表连接功能，实现Excel中的`vlookup`,`xlookup`等函数效果。

dplyr包中的动词可实现Excel中的大部分数据操作功能。
如下所示：筛选订单表中的1-5月订单数据，按照城市汇总，求每个城市的销售额和门店数(去重)。


```{r eval=FALSE}
data %>% 
  filter(between(月,1,5)) %>% 
  group_by(城市) %>% 
  summarise(金额 = sum(金额),门店数 = n_distinct(门店编码))
```



**Cheat Sheet**

手册搬运于dplyr[官方介绍](https://dplyr.tidyverse.org/)

![dplyr-sheet](./picture/dplyr/data-transformation.pdf){width=100% height=400}

Rstudio其它手册:<https://www.rstudio.com/resources/cheatsheets/>





## 基础用法

基础用法部分，我们将从行筛选，重命名、列位置调整、新增计算列、排序、分组聚合几个方面阐述`dplyr`动词功能。

### 加载包

```{r}
#library(dplyr)
# 禁掉提示
library(dplyr,warn.conflicts = FALSE)
```

### filter

`filter`动词顾名思义即筛选功能，按照一定条件筛选data.frame；与Excel中的筛选功能和`SQL`中`where`条件一致。

filter条件筛选中可以分为单条件筛选和多条件筛选；多条件中间用`,`分隔。

- 单条件

条件为` species == "Droid" `时，如下所示：

```{r}
starwars %>% 
  filter(species == "Droid")
```

```{sql eval = FALSE}
select * from starwars where species = "Droid" -- 注意=与==的区别
```


- 多条件

多条件筛选时，用英文逗号隔开多个条件。用“and”连接多个条件与用逗号隔开效果相同,“and”在R中用&表示。

```{r}
starwars %>% 
  filter(species == "Droid",skin_color == "gold")

# same above
# starwars %>% 
#   filter(species == "Droid" & skin_color == "gold")

```



```{sql eval =FALSE}
select * from starwars where species = "Droid" and skin_color = "gold" 
```


- 多情况筛选

类似`SQL`中 `in` 的用法，或Excel中筛选条件时"或"条件


```{r}
starwars %>% 
  filter(species %in%  c("Droid",'Clawdite'))
```


```{sql eval = FALSE}
select * from starwars where species in ("Droid","Clawdite") --sql查询
```


- 逻辑关系筛选

条件运算分为逻辑运算、关系运算。
关系运算符 >、<、==、!=、>=、<=分别代表大于、小于、等于、不等于、大于等于、小于等于。

逻辑运算符 &、|、！。 `|`为 或, `&` 为并、且条件，`!`为非。

```{r}
library(nycflights13)
filter(flights, !(arr_delay > 120 | dep_delay > 120))
filter(flights, arr_delay <= 120, dep_delay <= 120)

# same above
filter(flights, arr_delay <= 120 & dep_delay <= 120)

# %in% 的反面
starwars %>% 
  filter(!species %in%  c("Droid",'Clawdite'))
```

> !的运算级别相比 %in% 更高


### select 

当完整数据集列数较多时，我们某次分析可能并不需要那么多列，通过动词`select()`筛选列

- 基础用法

通过指定列名称筛选，并指定列之间顺序

```{r}
starwars %>% 
  select(name,height,mass,hair_color,skin_color,eye_color)
```

- 列索引

通过列名或数字向量索引，但是不建议用数字索引，避免原始数据列顺序变化后导致报错。

```{r}
starwars %>% 
  select(name : eye_color)
#same above
starwars %>% 
  select(1:6)
# starwars %>% 
#   select(c(1,2,4,5,7))
```


### rename

列重命名使用`rename()`函数，新名称写前面，如下所示：

```{r rename}
starwars %>% rename(home_world = homeworld)
# 多列同换
starwars %>% rename(home_world = homeworld,skincolor = skin_color)
```

```{sql eval = FALSE}
select * ,homeworld as home_word from starwars 
select * ,homeworld  home_word from starwars 
```

> as 可以省略，但中间有一个以上空格。与R的差异是新增home_word列，原始列继续存在，R中是替换列名。


### relocate

更改列顺序，与使用`select()`动词指定列顺序功能相似。

参数

```{r eval=FALSE}
relocate(.data, ..., .before = NULL, .after = NULL)
```


```{r}
# sex:homeworld列在height列前面
starwars %>% relocate(sex:homeworld, .before = height)
```


### mutate

动词`mutate`

- 新增计算列

```{r}
starwars %>% 
  mutate(bmi = mass / ((height / 100)  ^ 2)) %>% 
  select(name:mass,bmi)
```

- 新增计算列基础上新增列

```{r}
starwars %>% 
  mutate(bmi = mass / ((height / 100)  ^ 2),newbmi = bmi *2) %>% 
  select(name:mass,bmi,newbmi)
```

- 删除列

```{r}
starwars %>% mutate(height = NULL)
```


### arrange

- 单列排序，默认升序，通过`desc()`降序排列


```{r}
starwars %>% 
  arrange(desc(mass))
```

- 多列排序

```{r}
starwars %>% 
  arrange(height,desc(mass))
```


```{sql eval=FALSE}
select * from starwars order by height,mass desc
```



### summarise

`summarise`常与`group_by`结合使用。

```{r}
mtcars %>%
  summarise(mean = mean(disp), n = n())
```

> n()是dplyr包中的计算当前组的大小，用在summarise()和mutate()中。通常可用来组计算。

### group_by

聚合前一般都需要分组，`group_by()`动词实现该功能，与`SQL`中`group by ···`类似。

```{r}
starwars %>%
  group_by(species) %>%
  summarise(
    n = n(),
    mass = mean(mass, na.rm = TRUE)
  )
```

```{sql eval=FALSE}
SELECT species,
  count(species) n,
  AVG(mass) mass
FROM [spb].[dbo].[starwars]
GROUP BY  species
```


## 表操作

1. 指像`sql`中的`left join`,`inner join`等表格之间的操作，或者是Excel中`Power Piovt`建模的建立关系，从而实现不同表格间的关联

2. 表格中的列操作，如列求和，均值等

3. 行操作指不同字段间的计算，如`Excle`的列与列之间计算,`Excle`中的函数对行列不敏感，没有明显区别，但是`R`中`tidyverse`里列计算简单，行间计算依赖`rowwise()`函数实现

### 基础

`left_join()`,`full_join`,`inner_join()`等动词关联两个表。详情请查看：`vignette("two-table")`

`left_join()`实现类似Excel中`VLOOKUP`函数功能或数据库中`left join`功能，将“右表”的字段依据“主键”关联到“左表”上。

- 基础用法

`left_join()`,`right_join()`,`full_join()`,`inner_join`()，第一个以左表为主，第二个右表为主，第三个全连接，第四个内连接(只返回两表中都有的记录)，和数据库中连接方式一致。

默认会自动寻找两表中相同的字段名作为关联的条件

```{r}
library("nycflights13")
# Drop unimportant variables so it's easier to understand the join results.
flights2 <- flights %>% select(year:day, hour, origin, dest, tailnum, carrier)

flights2 %>% 
  left_join(airlines)
```

指定关联条件列，类似数据库中`on a.column = b.column `

```{r}
flights2 %>% left_join(planes, by = "tailnum")
```

- 不同名称列关联

`left_join(x,y,by = c("a" = "b", "c" = "d"))` 将会匹配 x$a to y$b 和 x$c to y$d 作为关联条件

```{r}
#出发机场和目的机场信息
flights2 %>% left_join(airports, by = c("dest" = "faa"))
#flights2 %>% left_join(airports, c("origin" = "faa"))
# 组合条件 多条件时用向量包裹即可c("dest" = "faa","cola" = "colb"))
```


- 筛选连接

`anti_join()` 删除所有左表中在右表中匹配到的行

`semi_join()`保留所有左表在右表中匹配到的行


```{r}
df1 <- tibble(a=letters[1:20],b=1:20)
df2 <- tibble(a=letters,b=1:26)

df1 %>% semi_join(df2)
df2 %>% anti_join(df1)
```

- 集合操作

1. `intersect(x,y)`返回x,y交集

2. `union(x,y)`返回x,y中唯一的值

3. `setdiff(x,y)`返回存在x中但是不存在y中的记录

```{r}
(df1 <- tibble(x = 1:2, y = c(1L, 1L)))
(df2 <- tibble(x = 1:2, y = 1:2))
intersect(df1, df2)
union(df1, df2)
setdiff(df1, df2)
setdiff(df2, df1)
```

### 多表操作

多表操作请使用`purrr::reduce()`,当需要合并多个表格时，可用以下方式减少合并代码量。

```{r}
dt1 <- data.frame(x = letters)
dt2 <- data.frame(x = letters,cola = 1:26)
dt3 <- data.frame(x = letters,colb = 1:26)
dt4 <- data.frame(x = letters,cold = 1:26)
dt5 <- data.frame(x = letters,cole = 1:26)

dtlist <- list(dt1,dt2,dt3,dt4,dt5)
purrr::reduce(dtlist,left_join,by='x')

```



## 列操作

在多列上执行相同的操作是常用的操作，但是通过复制和粘贴代码，麻烦不说还容易错：

```{r eval=FALSE}
df %>% 
  group_by(g1, g2) %>% 
  summarise(a = mean(a), b = mean(b), c = mean(c), d = mean(d))
```

通过`across()`函数可以更简洁地重写上面代码：

```{r eval=FALSE}
df %>% 
  group_by(g1, g2) %>% 
  summarise(across(a:d, mean))
```


### 基本操作

across() 有两个主要参数：

- 第一个参数，.cols选择要操作的列。它使用`tidyr`的方式选择（例如select()），因此您可以按位置，名称和类型选择变量。

- 第二个参数，.fns是要应用于每一列的一个函数或函数列表。这也可以是purrr样式的公式（或公式列表），例如~ .x / 2。


```{r}
starwars %>% 
  summarise(across(where(is.character), ~ length(unique(.x))))

# 列属性是字符的列求唯一值数
# starwars %>% 
#   summarise(length(unique(name)))
# starwars %>% 
#   summarise(length(unique(hair_color)))

starwars %>% 
  group_by(species) %>% 
  filter(n() > 1) %>% 
  summarise(across(c(sex, gender, homeworld), ~ length(unique(.x))))

starwars %>% 
  group_by(homeworld) %>% 
  filter(n() > 1) %>% 
  summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)))
```


`across()` 不会选择分组变量：

```{r}
df <- data.frame(g = c(1, 1, 2), x = c(-1, 1, 3), y = c(-1, -4, -9))
df %>% 
  group_by(g) %>% 
  summarise(across(where(is.numeric), sum))
```

### 多种函数功能

通过在第二个参数提供函数或lambda函数的命名列表，可是使用多个函数转换每个变量：


```{r}
min_max <- list(
  min = ~min(.x, na.rm = TRUE), 
  max = ~max(.x, na.rm = TRUE)
)
starwars %>% summarise(across(where(is.numeric), min_max))
```


通过`.names`参数控制名称：

NB:该参数的机制没有特别理解，需多练习体会。主要是运用到匿名函数时

以下是官方图册中的案例，但是报错：

```{r eval=FALSE}
starwars %>% summarise(across(where(is.numeric), min_max, .names = "{.fn}.{.col}"))
```

修改后正常运行：

```{r}
starwars %>% summarise(across(where(is.numeric), min_max, .names = "{fn}.{col}"))
```


区别主要是`.names`参数的使用方式问题，`.`加不加的问题。

```{r eval=FALSE}

starwars %>% summarise(across(where(is.numeric), min_max, .names = "{fn}——{col}"))

```

### 当前列

如果需要，可以通过调用访问内部的“当前”列的名称`cur_column()`。

该函数不是特别容易理解，需要多尝试使用加深认识。

```{r}
df <- tibble(x = 1:3, y = 3:5, z = 5:7)
mult <- list(x = 1, y = 10, z = 100)

df %>% mutate(across(all_of(names(mult)), ~ .x * mult[[cur_column()]]))
```

## 行操作

在操纵数据框中，`dplyr`等工具让我们对列操作相对简单，但是对行操作则困难些。

### 构造数据集

```{r}
df <- tibble(x = 1:2, y = 3:4, z = 5:6)
df %>% rowwise()
```

像`group_by()`,`rowwise()`并没有做任何事情，它的作用是改变其他动词的工作方式：
比较以下代码中不的不同

```{r}
df %>% mutate(m = mean(c(x, y, z)))
df %>% rowwise() %>% mutate(m = mean(c(x, y, z)))
```

`data.table`中的操作:

```{r eval=FALSE}
library(data.table)

dt <- data.table(x = 1:2, y = 3:4, z = 5:6)
dt[,m:=mean(c(x,y,z))][]
dt[,m:=mean(c(x,y,z)),by=.(x)][]
```

您可以选择在调用中提供“标识符”变量`rowwise()`。这些变量在您调用时被保留`summarise()`，因此它们的行为与传递给的分组变量有些相似`group_by()`：

```{r}
df <- tibble(name = c("Mara", "Hadley"), x = 1:2, y = 3:4, z = 5:6)

df %>% 
  rowwise() %>% 
  summarise(m = mean(c(x, y, z)))

df %>% 
  rowwise(name) %>% 
  summarise(m = mean(c(x, y, z)))
```


### 行汇总统计

`dplyr::summarise()`使得汇总一列中各行的值非常容易。当与之结合使用时`rowwise()`，还可以轻松汇总一行中各列的值：

```{r}
df <- tibble(id = 1:6, w = 10:15, x = 20:25, y = 30:35, z = 40:45)
rf <- df %>% rowwise(id)
rf %>% mutate(total = sum(c(w, x, y, z)))
rf %>% summarise(total = sum(c(w, x, y, z)))
```


键入每个变量名称很繁琐，通过`c_across()`使更简单

```{r}
rf %>% mutate(total = sum(c_across(w:z)))
rf %>% mutate(total = sum(c_across(where(is.numeric))))

rf %>% 
  mutate(total = sum(c_across(w:z))) %>% 
  ungroup() %>% 
  mutate(across(w:z, ~ . / total))
```




## 分组操作

详情: <https://cloud.r-project.org/web/packages/dplyr/vignettes/grouping.html>

`group_by()`最重要的分组动词,需要一个数据框和一个或多个变量进行分组：

### 添加分组

```{r}
by_species <- starwars %>% group_by(species)
by_sex_gender <- starwars %>% group_by(sex, gender)
```

除了按照现有变量分组外，还可以按照函数处理后的变量分组，等效在`mutate()`之后执行`group_by`:

```{r}
bmi_breaks <- c(0, 18.5, 25, 30, Inf)
starwars %>%
  group_by(bmi_cat = cut(mass/(height/100)^2, breaks=bmi_breaks)) %>%
  tally()
```


### 删除分组变量

要删除所有分组变量，使用`ungroup()`:

```{r}
by_species %>%
  ungroup() %>%
  tally()
```


### 动词

`summarise()` 计算每个组的汇总，表示从`group_keys`开始右侧添加汇总变量

```{r}
by_species %>%
  summarise(
    n = n(),
    height = mean(height, na.rm = TRUE)
  )
```


该`.groups=`参数控制输出的分组结构。删除右侧分组变量的历史行为对应于`.groups =` "drop_last"没有消息或.groups = NULL有消息（默认值）。

从1.0.0版开始，分组信息可以保留`(.groups = "keep")`或删除 `(.groups = 'drop)`


```{r}
a <- by_species %>%
  summarise(
    n = n(),
    height = mean(height, na.rm = TRUE),.groups='drop') %>% 
  group_vars()

b <- by_species %>%
  summarise(
    n = n(),
    height = mean(height, na.rm = TRUE),.groups='keep') %>% 
  group_vars()

object.size(a)
object.size(b)
```

在实际使用中，当数据较大时需要删掉分组信息。以上可以看到保留分组信息的比没保留的大了两倍多。

## 常用函数

### 条件判断 

相比于`base::ifelse`,`if_else`更为严格，无论`TRUE`或`FALSE`输出类型一致，这样速度更快。与`data.table::fifelse()`功能相似。

```{r eval=FALSE}
if_else(condition, true, false, missing = NULL)
```

与`ifelse`不同的是，`if_else`保留类型

```{r}
x <- factor(sample(letters[1:5], 10, replace = TRUE))
ifelse(x %in% c("a", "b", "c"), x, factor(NA))
if_else(x %in% c("a", "b", "c"), x, factor(NA))
```


### case_when 

当条件嵌套条件较多时，使用`case_when`,使代码可读并且不易出错。与sql 中的case when 等价。

```{r}
Dates <- as.Date(c('2018-10-01', '2018-10-02', '2018-10-03'))
case_when(
  Dates == '2018-10-01' ~ Dates - 1,
  Dates == '2018-10-02' ~ Dates + 1,
  Dates == '2018-10-03' ~ Dates + 2,
  TRUE ~ Dates
)
```

### 计数函数

- 计数

`count()`函数用来计数。下面两种表达方式等价。

```{r eval =FALSE}
df %>% count(a, b)
# same above
df %>% group_by(a, b) %>% summarise(n = n())
```

```{r}
starwars %>% count(species)
# same above 等价
starwars %>% group_by(species) %>% summarise(n = n())
```


- 非重复计数

`n_distinct()`与` length(unique(x))`等价，但是更快更简洁。当我们需要给门店或订单之类数据需要去重计算时采用该函数。

```{r}
x <- sample(1:10, 1e5, rep = TRUE)
length(unique(x))
n_distinct(x)
```

### 排序函数

`dplyr`共六种排序函数，模仿SQL2003中的排名函数。

- row_number():等于 rank(ties.method = "first")
- min_rank(): 等于 rank(ties.method = "min")
- dense_rank(): 与min_rank()相似,但是没有间隔
- percent_rank():返回0，1之间，通过min_rank()返回值缩放至[0,1]


```{r }
x <- c(5, 1, 3, 2, 2, NA)
row_number(x)
min_rank(x)
dense_rank(x)
percent_rank(x)
cume_dist(x)
```

### 提取向量

该系列函数是对`[[`的包装。

```{r eval=FALSE}
nth(x, n, order_by = NULL, default = default_missing(x))
first(x, order_by = NULL, default = default_missing(x))
last(x, order_by = NULL, default = default_missing(x))
```

```{r}
x <- 1:10
y <- 10:1
first(x)
last(y)
nth(x, 1)
nth(x, 5)
```


### group 系列

group_by(),group_map(), group_nest(), group_split(), group_trim()等一系列函数。

其中我常用group_by(),group_split()两个函数。group_by()是大部分数据操作中的分组操作，按照group_by()的指定分组条件。

- group_by()

```{r}
#group_by()不会改变数据框
by_cyl <- mtcars %>% group_by(cyl)
by_cyl
# It changes how it acts with the other dplyr verbs:
by_cyl %>% summarise(
  disp = mean(disp),
  hp = mean(hp)
)
# group_by中可以添加计算字段 即mutate操作
mtcars %>% group_by(vsam = vs + am) %>%
  group_vars()
```


- group_map()

group_map，group_modify,group_walk等三个函数是purrr类具有迭代风格的函数。简单关系数据库的数据清洗一般不涉及，常用在建模等方面。

但是目前三个函数是实验性的，未来可能会发生变化。

```{r}
# return a list
# 返回列表
mtcars %>%
  group_by(cyl) %>%
  group_map(~ head(.x, 2L))
```



```{r}
iris %>%
  group_by(Species) %>%
  group_modify(~ {
    .x %>%
      purrr::map_dfc(fivenum) %>%
      mutate(nms = c("min", "Q1", "median", "Q3", "max"))
  })
```


```{r eval=FALSE}
# group_walk
dir.create(temp <- tempfile())
iris %>%
  group_by(Species) %>%
  group_walk(~ write.csv(.x, file = file.path(temp, paste0(.y$Species, ".csv"))))
list.files(temp, pattern = "csv$")
unlink(temp, recursive = TRUE)
```


- group_cols()

选择分组变量

```{r}
gdf <- iris %>% group_by(Species)
gdf %>% select(group_cols())
```




### 其它函数

- between

- cummean cumsum cumall cumany

累计系列函数

```{r}
x <- c(1, 3, 5, 2, 2)
cummean(x)
cumsum(x) / seq_along(x)

cumall(x < 5)
cumany(x == 3)
```


- distinct 

```{r eval=FALSE}
df <- tibble(
  x = sample(10, 100, rep = TRUE),
  y = sample(10, 100, rep = TRUE)
)

distinct(df, x)
distinct(df, x, .keep_all = TRUE)
distinct(df, diff = abs(x - y))
```



## 用`dplyr`编程

Programming with dplyr:

<https://cloud.r-project.org/web/packages/dplyr/vignettes/programming.html>

本节概念性东西较多且复杂不易理解，先尝试会使用，概念再慢慢消化理解。

虽然复杂但是比较实用，尤其是当我们需要定义一些通用功能函数时

以下是对原文引用

两种情况：

- When you have the data-variable in a function argument (i.e. an env-variable that holds a promise2), you need to ** embrace ** the argument by surrounding it in doubled braces, like `filter(df, {{ var }})`.

The following function uses embracing to create a wrapper around `summarise()` that computes the minimum and maximum values of a variable, as well as the number of observations that were summarised:

```{r eval=FALSE}
var_summary <- function(data, var) {
  data %>%
    summarise(n = n(), min = min({{ var }}), max = max({{ var }}))
}
mtcars %>% 
  group_by(cyl) %>% 
  var_summary(mpg)
```


- When you have an env-variable that is a character vector, you need to index into the .data pronoun with [[, like summarise(df, mean = mean(.data[[var]])).

The following example uses .data to count the number of unique values in each variable of mtcars: 

```{r eval=FALSE}
for (var in names(mtcars)) {
  mtcars %>% count(.data[[var]]) %>% print()
}
```

Note that .data is not a data frame; it’s a special construct, a pronoun, that allows you to access the current variables either directly, with `.data$x` or indirectly with ` .data[[var]]`. Don’t expect other functions to work with it.


### 案例

当我们不知道接下来会用哪个变量汇总时：

```{r}
my_summarise <- function(data, group_var) {
  data %>%
    group_by({{ group_var }}) %>%
    summarise(mean = mean(mass))
}
```


如果在多个位置使用：

```{r}
my_summarise2 <- function(data, expr) {
  data %>% summarise(
    mean = mean({{ expr }}),
    sum = sum({{ expr }}),
    n = n()
  )
}
```


当多个表达式时：

```{r}
my_summarise3 <- function(data, mean_var, sd_var) {
  data %>% 
    summarise(mean = mean({{ mean_var }}), sd = mean({{ sd_var }}))
}
```

如果要输出变量名时：

```{r}
my_summarise4 <- function(data, expr) {
  data %>% summarise(
    "mean_{{expr}}" := mean({{ expr }}),
    "sum_{{expr}}" := sum({{ expr }}),
    "n_{{expr}}" := n()
  )
}
my_summarise5 <- function(data, mean_var, sd_var) {
  data %>% 
    summarise(
      "mean_{{mean_var}}" := mean({{ mean_var }}), 
      "sd_{{sd_var}}" := mean({{ sd_var }})
    )
}
```


任意个表达式：

这种使用场景更多

```{r}
my_summarise <- function(.data, ...) {
  .data %>%
    group_by(...) %>%
    summarise(mass = mean(mass, na.rm = TRUE), height = mean(height, na.rm = TRUE))
}
starwars %>% my_summarise(homeworld)
starwars %>% my_summarise(sex, gender)
```




<!--chapter:end:07-Data-manipulation.Rmd-->

```{r include=FALSE, cache=FALSE}
set.seed(1014)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
 # cache = TRUE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)

options(dplyr.print_min = 6, dplyr.print_max = 6)
```
# tidyr

在实际工作中，我们数据分析工作者80%的时间可能贡献在数据准备和数据清晰上。另外发现新问题时，可能又要重复数据准备、数据清晰的过程。如果采用不能完全复现的方式做数据准备清洗的工作，那将是一场灾难。

数据工作者最常用的工具可能是Excel,但是Excel并不具备很强的数据清洗能力，即使Excel有POwer query 、Dax等两大利器。工作中，实际面临原始的数据是脏乱无须的，业务系统仅仅只是记录了历史过程数据。当我们需要分析某一现象时，需要按照自己的需求重新采集数据，清洗为“标准”的数据格式。

> 标准数据：达到工作需求的数据，可以直接用Excel,power bi ，tableau等BI工具直接使用的程度。

`R`中的tidyverse系列构建了一种一致的数据结构，当我们用tidyverse软件包提供的“数据整洁工具”整洁数据时，我们将花费更少的时间将数据从一种形式迁移到另外一种形式。从而，我们拥有更多的时间专注在具体的业务问题上。



## 安装

本章节，我们重点关注`tidyr`包，这个软件包提供了许多的功能函数整理混乱的数据。tidyr是tidyverse的核心成员包

```{r eval=FALSE}
## 最简单是的方式就是安装tidyverse
install.packages('tidyverse')

## 或者仅仅安装 tidyr:
install.packages('tidyr')

## 或者从github 安装开发版本
## install.packages("devtools")
devtools::install_github("tidyverse/tidyr")

# CTEST CODE
```


## 主要功能

整洁的数据表现为：

1. 每个变量是单独的一列
2. 每一个观察的值都在自己的行
3. 每一个值都是独立的单元格

大部分的数据集都是用行和列构成的`data.frame`。用Excel的单元格来表示，即每列代表不同意义的字段，每行是某个情形下的一系列字段；单元格则是独立的值,属于某个变量的观察值，这样构建的二维数据结构则是“整洁数据”。



```{r}
library(tidyr)
```

`tidyr`包中的函数可以分为5个主要大类

- `pivot_longer()` 和 `pivot_wider()` 宽转长以及长转宽

- `unnest_longer()` 和 `unnest_wider()`,`hoist()` 将列表嵌套转化为整洁数据

- `nest()` 数据嵌套

- `separate()`,`extract()`拆分列,提取新列

-  `replace_na()` 缺失值处理


### 宽转长 

详情查看`vignette("pivot")`,以下是照搬该图册中的内容

#### 基础

长数据与宽数据之间的转换，类似我们常用的EXcel中的透视表功能。接下来用`tidyr`包自带的插图案例记录相关函数用法



在Excel中有时候方便我们肉眼观察，可能一个数据集会有很多列,如下所示：

col1 | col2 | col3  |col4   |col5 |col6 |col7
---- | ---- | ----- |------ |-----|-----|----
v1   | v2   | v3    |v4     |v5   |v6   |v7
vb1  | vb2  | vb3   |vb4    |vb5  |vb6  |vb7

方便观察，但是不方便统计分析，这是我们需要把数据做处理，从"宽数据变成长数据"即宽转长。

```{r}
library(tidyr)
library(dplyr)
library(readr)
```

```{r}
relig_income %>% 
  pivot_longer(cols = !religion,names_to = 'income',values_to = "count")
```


* 第一个参数是数据集
* 第二个参数是那些列需要重塑，在该例中除了`religion`的其他全部列
* `names_to`这个参数是新增的列名
* `values_to`是新增的存储之前数据集中数据的列名

#### 列名带数字

```{r}
billboard %>% 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  )
```

`names_prefix` 调整内容前缀，配合`names_transform`参数使用

```{r}
billboard %>% 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    names_prefix = "wk",
    names_transform = list(week = as.integer),
    values_to = "rank",
    values_drop_na = TRUE,
  )
```

经过以上转换`week`列属性变成了整数，当然达到以上效果有其他的途径，如下：

```{r eval=FALSE}
library(tidyverse,warn.conflicts = TRUE)

# method 1
billboard %>% 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    names_transform = list(week = readr::parse_number),
    values_to = "rank",
    values_drop_na = TRUE,
)

# method 2
billboard %>%
  pivot_longer(
    cols = starts_with("wk"),
    names_to = "week",
    values_to = "rank",
    values_drop_na = TRUE,
  ) %>%
  mutate(week = str_remove(week, "wk") %>% as.integer())
```


#### 多变量列名

该案列设计比较复杂的正则表达式,`new_?(.*)_(.)(.*)`需要一定正则表达式基础。
`new_?`表示匹配`new`或`new_`，`(.*)`匹配任意0次或多次任意字符。

[正则表达式介绍](https://www.runoob.com/regexp/regexp-syntax.html)

```{r}
who %>% pivot_longer(
  cols = new_sp_m014:newrel_f65,
  names_to = c("diagnosis", "gender", "age"), 
  names_pattern = "new_?(.*)_(.)(.*)",
  values_to = "count"
)
```

进一步处理列`gender`，`age` 。

```{r}
who %>% pivot_longer(
  cols = new_sp_m014:newrel_f65,
  names_to = c("diagnosis", "gender", "age"), 
  names_pattern = "new_?(.*)_(.)(.*)",
  names_transform = list(
    gender = ~ readr::parse_factor(.x, levels = c("f", "m")),
    age = ~ readr::parse_factor(
      .x,
      levels = c("014", "1524", "2534", "3544", "4554", "5564", "65"), 
      ordered = TRUE
    )
  ),
  values_to = "count",
)
```


#### 一行多观测值

```{r}
family <- tribble(
  ~family, ~dob_child1, ~dob_child2, ~gender_child1, ~gender_child2,
  1L, "1998-11-26", "2000-01-29", 1L, 2L,
  2L, "1996-06-22", NA, 2L, NA,
  3L, "2002-07-11", "2004-04-05", 2L, 2L,
  4L, "2004-10-10", "2009-08-27", 1L, 1L,
  5L, "2000-12-05", "2005-02-28", 2L, 1L,
)
family <- family %>% mutate_at(vars(starts_with("dob")), parse_date)
family
```

```{r}

family %>% 
  pivot_longer(
    !family, 
    names_to = c(".value", "child"), 
    names_sep = "_", 
    values_drop_na = TRUE
  )
```


```{r}
anscombe %>% 
  pivot_longer(everything(), 
    names_to = c(".value", "set"), 
    names_pattern = "(.)(.)"
  ) %>% 
  arrange(set)
```



```{r}
pnl <- tibble(
  x = 1:4,
  a = c(1, 1,0, 0),
  b = c(0, 1, 1, 1),
  y1 = rnorm(4),
  y2 = rnorm(4),
  z1 = rep(3, 4),
  z2 = rep(-2, 4),
)

pnl %>% 
  pivot_longer(
    !c(x, a, b), 
    names_to = c(".value", "time"), 
    names_pattern = "(.)(.)"
  )
```


#### 重复列名

```{r}
df <- tibble(id = 1:3, y = 4:6, y = 5:7, y = 7:9, .name_repair = "minimal")
df %>% pivot_longer(!id, names_to = "name", values_to = "value")
```

### 长转宽

`pivot_wider()`功能与`pivot_longer()`相反。通过增加列数减少行数使数据集变得更宽，通常我们在汇总时候使用，达到类似Excel透视表结果。

#### 基础

```{r}
fish_encounters %>% pivot_wider(names_from = station, values_from = seen)
```

缺失值填充

```{r}
fish_encounters %>% pivot_wider(
  names_from = station, 
  values_from = seen,
  values_fill = 0
)
```

#### 聚合

```{r}
warpbreaks <- warpbreaks %>% as_tibble() 
warpbreaks %>% count(wool, tension)
```

需要通过`values_fn`指定聚合方式

```{r}
warpbreaks %>% pivot_wider(names_from = wool, values_from = breaks,values_fn= list(breaks = sum))
```


#### 从多个变量生成新列名

```{r}
production <- expand_grid(
    product = c("A", "B"), 
    country = c("AI", "EI"), 
    year = 2000:2014
  ) %>%
  filter((product == "A" & country == "AI") | product == "B") %>% 
  mutate(production = rnorm(nrow(.)))
production
```

```{r}
production %>% pivot_wider(
  names_from = c(product, country), 
  values_from = production
)
```

通过`names_sep`和`names_prefix`参数控制新的列名，或通过`names_glue`


```{r}
production %>% pivot_wider(
  names_from = c(product, country), 
  values_from = production,
  names_sep = ".",
  names_prefix = "prod."
)
```

```{r}
production %>% pivot_wider(
  names_from = c(product, country), 
  values_from = production,
  names_glue = "prod_{product}_{country}"
)
```

#### 多值变宽

```{r}
us_rent_income %>% 
  pivot_wider(names_from = variable, values_from = c(estimate, moe))
```


### 处理json,html的数据

实际工作中不是经常使用，需要使用的时候往往会用相关的包处理：`jsonlite` 

可通过`vignette("rectangle")`自行学习

```{r}
library(tidyr)
library(dplyr)
library(repurrrsive)
```

```{r}
users <- tibble(user = gh_users)
users
users %>% unnest_wider(user)
```


### 嵌套数据

```{r}
library(tidyr)
library(dplyr)
library(purrr)
```


#### 基础

嵌套数据即：数据框中嵌套数据框，如下所示：

```{r}
df1 <- tibble(
  g = c(1, 2, 3),
  data = list(
    tibble(x = 1, y = 2),
    tibble(x = 4:5, y = 6:7),
    tibble(x = 10)
  )
)
df1
```

因为`data.frame()`的列特性【每列都是列表】【不确定理解对不对】：可以做如下操作：

```{r}
df2 <- tribble(
  ~g, ~x, ~y,
   1,  1,  2,
   2,  4,  6,
   2,  5,  7,
   3, 10,  NA
)
df2 %>% nest(data = c(x, y))

#sample above
#df2 %>% group_by(g) %>% nest()
```


nest的反面 unnest

```{r}
df1 %>% unnest(data)
```


### 嵌套数据和模型

```{r}
mtcars_nested <- mtcars %>% 
  group_by(cyl) %>% 
  nest()

mtcars_nested
```

```{r}
mtcars_nested <- mtcars_nested %>% 
  mutate(model = map(data, function(df) lm(mpg ~ wt, data = df)))
mtcars_nested
```

```{r}
mtcars_nested <- mtcars_nested %>% 
  mutate(model = map(model, predict))
mtcars_nested  
```

### 拆分和合并


#### 拆分

有时我们需要将一列拆分为多列：

```{r}
library(tidyr)
df <- data.frame(x = c(NA, "a.b", "a.d", "b.c"))
df %>% separate(x, c("A", "B"))
```

拆分数多列或少列时用`NA`补齐：

```{r}
df <- data.frame(x = c("a", "a b", "a b c", NA))
df %>% separate(x, c("a", "b"))
```

多余的部分舍弃，缺失填充在左边还是右边：

```{r}
# The same behaviour as previous, but drops the c without warnings:
df %>% separate(x, c("a", "b"), extra = "drop", fill = "right")
```

多余部分合并，缺失填充在左边

```{r}
df %>% separate(x, c("a", "b"), extra = "merge", fill = "left")
```

或者全部保留

```{r}
df %>% separate(x, c("a", "b", "c"))
```


指定分隔符
```{r}
df %>% separate(x, c("key", "value"), sep = ": ", extra = "merge")

```

使用正则表达式

```{r}
# Use regular expressions to separate on multiple characters:
df <- data.frame(x = c(NA, "a?b", "a.d", "b:c"))
df %>% separate(x, c("A","B"), sep = "([.?:])")
```

#### 新列提取

```{r}
df <- data.frame(x = c(NA, "a-b", "a-d", "b-c", "d-e"))
df %>% extract(x, "A")
df %>% extract(x, c("A", "B"), "([[:alnum:]]+)-([[:alnum:]]+)")
# [:alnum:] 匹配字母和数字
```


以上本质是字符处理，[正则表达式](http://baiy.cn/utils/_regex_doc/index.htm)

#### 合并

```{r}
df <- expand_grid(x = c("a", NA), y = c("b", NA))
df
df %>% unite("z", x:y, remove = FALSE)
# expand_grid 类似笛卡尔积功能
```

移除缺失值

```{r}
df %>% unite("z", x:y, na.rm = TRUE, remove = FALSE)
```

合并后再拆分

```{r}
df %>%
  unite("xy", x:y) %>%
  separate(xy, c("x", "y"))
```


### 缺失值处理

`replace_na()`用特定值替换缺失值。

```{r}
df <- tibble(x = c(1, 2, NA), y = c("a", NA, "b"))
df %>% replace_na(list(x = 0, y = "unknown"))
```

```{r}
df %>% dplyr::mutate(x = replace_na(x, 0))
```


<!--chapter:end:06-tidy-data.Rmd-->

```{r include=FALSE, cache=FALSE}
set.seed(1014)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
 # cache = TRUE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)

options(dplyr.print_min = 6, dplyr.print_max = 6)
```

# stringr 


实际工作中,经常需要处理字符串.R包stringr处理字符相对简单,本章记录工作中常用的字符处理方式方法。

本文部分案例照搬[R for Data Science](https://r4ds.had.co.nz/strings.html)的字符部分。

Excle中自带的字符函数如: `left`,`len`,`mid`,`find`,`Proper`,`rept`,`trim`,`upper`,`substitute`,`concatenate`,以及`Excle`2019新出的`concat`,`TEXTJOIN`等函数，新出的`textjoin`函数我个人比较喜欢用。 

学习的时候可以先用`stringr`包实现以上相对应功能。

* <https://cran.r-project.org/web/packages/stringr/vignettes/stringr.html>

## 基础

字符串处理的难点，个人觉得在于【正则表达式】的掌握程度，但是需要用到正则表达式时都是比较复杂的字符处理工作，在实际商业文本数据中

运用较多。对大部分常规商业数据分析工作者的面对的表格数据而言，字符处理可能仅仅只是合并、剔除、删除空格、倒叙等基础操作。


### 单双引号

`R`语言中字符串输入时，可以使用单引号，也可以使用双引号。

 - 单双引号用法和意义没有差别
 
 - R中推荐使用双引号分隔符，打印、显示时都是用双引号
 
 - 单引号字符串通常用在字符串内包含双引号时，如用R执行sql字符串代码时

### 转义 

要在字符串中包含单引号或双引号，可以使用\ 转义它，即遇到特殊符号时需要转义。

```{r}
#install.packages('stringr')
library(stringr)
char <- "我是一名\'小学生\'"   #字符串建议用双引号包裹,单引号也可以
char
```

打印会显示转义符。要查看字符串的原始内容,可使用writeLines()或cat()

```{r eval=FALSE}
x <- c("\"", "\\")
x
#> [1] "\"" "\\"
writeLines(x)
cat(char)
#> "
#> \
```

在正则表达式中\ 有特殊含义,有时需要两个\ ，多体会下面这段，代码实现移除"||"的功能。

```{r}
str_remove(string = 'a||b',pattern = "\\|\\|")
```


另外常见的\\n, \\t需要被转义处理,在字符清洗,如小说语义分析,网页爬虫后整理等数据清洗过程中经常用到.


### 字符串长度

```{r}
char <- "我是R语言学习者"
str_length(char)
# 向量化
str_length(c("a", "R for data science", NA))

```

### 连接字符串

R中字符串不像python中可以用加号连接字符串,如下所示:

R 版本

```{r}
#base R
paste0('a','b')

#stringr
str_c("a","b")
str_c("a", "b", sep = ", ") #sep 参数控制分隔符
```

Python 版本

```{python}
'a' + 'b'
```


多个字符串合并为一个字符,`stringr`中的函数都是向量化的，合并一个和多个字符都是同样道理。

```{r}
#base R
paste0(c('a','b','d','e'),collapse = ',')
#stringr
str_c(c('a','b','d','e'),collapse = ',')  #collapse 参数控制
```


实际运用案例

 * 合并

```{r}
library(data.table)
dt <- data.table(col=rep('a',10),letters=letters[1:10])
dt[,newcol:=str_c(letters,collapse = '|'),by=.(col)][]
```

* 拆解

```{r}

#工作中路径需要拆解 类似商品品类路径 进口水果-热带水果-生鲜,用户行为路径等
dt <- data.table(col='a',letters=str_c(letters[1:10],collapse = '|'))

my_str_split <- function(x){
  
  str_split(x,pattern = "\\|") %>% unlist()  #str_split 拆解出来是列表 需要向量化
}

dt[,list(newcol=my_str_split(letters)),by=.(col)]
```


### R4.0后新特性

[新特性](https://www.r-bloggers.com/4-for-4-0-0-four-useful-new-features-in-r-4-0-0/)


```{r}
char <- r"(\\a\ab\d\e\f)" #windows下路径好用,不用转义路径复制和直接可用
char
```

```{r}
char <- "我是一名\'小学生\'" 
cat(char)

char <- r"(我是一名'R语言'学习者)"
cat(char)
```



## 常用函数


### 截取

与`Excle`中`left`,`mid`,`right`函数功能类似

str_sub() 函数 三个参数:

string:需要被截取的字符串

start: 默认1L,即从最开始截取

end:默认-1L,即截取到最后


```{r}
#注意end 3 和 -3的区别
str_sub(string = '我是R语言学习者',start = 2,end = 3)
str_sub(string = '我是R语言学习者',start = 2,end = -3)
```



### 匹配

查看函数帮助文档,str_match()按照指定pattern(正则表达式)查找字符.重点困难点正则表达式的编写.

```{r eval=FALSE}
?str_match()
?str_match_all()
?str_extract()
?str_extract_all()
```

str_extract()函数返回向量,str_match()函数返回矩阵.

```{r}
#原文来源烽火戏诸侯的<剑来>
strings <- c('陈平安放下新折的那根桃枝,吹灭蜡烛,走出屋子后,坐在台阶上,仰头望去,星空璀璨.') 
str_extract(strings,'陈平安')
str_match(strings,'陈平安')
```

* 匹配中文

匹配中文的正则表达式\[\u4e00-\u9fa5\]

```{r}
str_extract_all(strings,'[\u4e00-\u9fa5]') #返回list
```

* 匹配数字或英文

查找数字的正则表达式[0-9];查找英文的正则表达式:[a-zA-Z]


```{r}
strings <- c('00123545','LOL league of legends')
str_extract_all(strings,'[0-9]')
str_extract_all(strings,'[a-zA-Z]') 

```


### 添加字符

str_pad() 函数向字符串添加字符

像工作中处理月份的时候,1,2,3,4,5,6,7,8,9,10,11,12变成01,02,03,04,05,06,07,08,09,10,11,12.按照日期时间输出文件名称,如下所示:


```{r}
str_pad(string = 1:12,width = 2,side = 'left',pad = '0')
```

### 去除空格

与`excel`中`trim`函数功能类似，剔除字符中的空格，但是不可以剔除字符中的空格

```{r}
# side 可选 both  left right
str_trim(' ab af ',side = 'both')
```


### 分割字符

`str_split()`处理后的结果是列表

```{r}
# 得到列表,需要向量化
str_split("a,b,d,e",pattern = ',')

str_split('ab||cd','\\|\\|') %>% unlist()
# same above
#str_split('ab||cd','\\|\\|') %>% purrr::as_vector()
```

当待处理的字符串是字符串向量时，得到的列表长度与向量长度一致

```{r}
fruits <- c(
  "apples and oranges and pears and bananas",
  "pineapples and mangos and guavas"
)

str_split(fruits, " and ")
```

### 替换字符

`str_replace()`，`str_replace_all()`函数用来替换字符

```{r}
fruits <- c("one apple", "two pears", "three bananas")
str_replace(fruits, "[aeiou]", "-")
str_replace_all(fruits, "[aeiou]", "-")
```

### 移除字符

`str_remove()`,`str_remove_all()`移除字符。本人常用该函数剔除文本中的空格。

```{r}
fruits <- c("one apple", "two pears", "three bananas")
str_remove(fruits, "[aeiou]")
str_remove_all(fruits, "[aeiou]")
```

移除文本中空格

```{r}
str_replace_all(string = ' d a  b ',pattern = ' ',replacement = '')
```


### 字符排序

numeric参数决定是否按照数字排序。

```{r eval=FALSE}
str_order(x, decreasing = FALSE, na_last = TRUE, locale = "en",
  numeric = FALSE, ...)

str_sort(x, decreasing = FALSE, na_last = TRUE, locale = "en",
  numeric = FALSE, ...)
```

```{r}
str_order(letters)
str_sort(letters)
```

numeric参数

```{r}
x <- c("100a10", "100a5", "2b", "2a")
str_sort(x)
str_sort(x, numeric = TRUE)
```

### 提取单词

从句子中提取单词。

- 参数

```{r eval=FALSE}
word(string, start = 1L, end = start, sep = fixed(" "))
```

- 案例

```{r}
sentences <- c("Jane saw a cat", "Jane sat down")
word(sentences, 2, -1)
word(sentences[1], 1:3, -1)
```

指定分隔符

```{r}
# Can define words by other separators
str <- 'abc.def..123.4568.999'
word(str, 1, sep = fixed('..'))
word(str, 2, sep = fixed('..'))
```



### 其他函数

* str_subset() str_which()

匹配字符串本身行筛选时候能用


```{r}

fruit <- c("apple", "banana", "pear", "pinapple")
str_subset(fruit, "a")
str_which(fruit, "a") # 匹配字符首次出现的位置
```

 
```{r eval=FALSE}
#str_which 是which(str_detect(x,pattern))的包装
#str_which()

#str_subset是对x[str_detect(x,pattern)]的包装
#str_subset()

#筛选出字母行
set.seed(24)
dt <- data.table::data.table(col=sample(c(letters,1:10),100,replace = T))
head(dt[str_which(col,pattern = '[a-z]')])

```


* str_dup()

复制字符串

```{r eval=FALSE}
fruit <- c("apple", "pear", "banana")
str_dup(fruit, 2)
str_dup(fruit, 1:3)
str_c("ba", str_dup("na", 0:5))
```



* str_starts()  str_ends()

从str_detect()包装得到.

```{r}
str_starts('abd','a')
str_detect('abd','^a')

str_ends('abd','d')
str_detect('abd','a$')


```

 * 大小写转换
 
```{r}
dog <- "The quick brown dog"
str_to_upper(dog)
str_to_lower(dog)
str_to_title(dog)
str_to_sentence("the quick brown dog")
```
 
 
## R实现Excel字符函数

以下函数实现，仅仅只是从`stringr`包的函数上修改，并且没有完善，没有报错提示等的简陋版本，如果感兴趣的可以尝试利用`Rcpp`写出高性能版本的同功能函数。

- left

```{r}
r_left <- function(str,num){
  str_sub(string = str,start = 1,end = num)
}
r_left('我是R语言学习者',3)
```

- right

```{r}
r_right <- function(str,num){
  str_sub(string = str,start = str_length(str) - num + 1)
}
r_right('我是R语言学习者',3)
```

- mid

```{r}
r_mid <- function(str,start,num){
  str_sub(string = str,start = start,end = start + num -1)
}
r_mid('我是R语言学习者',3,3)
```

其余函数可以自行实现

<!--chapter:end:03-strings.Rmd-->

```{r include=FALSE, cache=FALSE}
set.seed(1014)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
 # cache = TRUE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)

options(dplyr.print_min = 6, dplyr.print_max = 6)
```
# lubridate


数据清洗中,经常涉及到时间处理。个人R中用来处理时间的包是`lubridate`，本文将介绍该包中部分函数用法。

该包能灵活处理日期和时间数据，但是日期处理是比较复杂的，就拿简单的同环比来说，如果是想利用基础函数自定义函数来处理同环比，你遇到的第一个问题就是每个月的天数不一样，第二个问题就是闰年问题导致年天数不一致。

经过一番折腾，完全放弃了自己处理时间日期数据的想法，投入了`lubridate`包的怀抱。由于能力有限以及处理过的日期数据有限，并不能面面俱到，更加深入的问题，可自行去了解该包的文档，甚至去通读源码。


在`Excel`的`Power Pivot`中有一组DAX智能函数，如：

- 基础函数

`date`,`datediff`,`datevalue`,`edate`,`eomonth`,`quarter`,`TIMEVALUE`等等

- 智能函数

`dateadd`,` DATESBETWEEN`,`DATESMTD`,`TOTALMTD`,`TOTALQTD`,`TOTALYTD`等等

`Excel`中因为有了以上时间智能函数，用度量值在透视表中计算同环比变得简单

熟悉DAX时间智能函数，在`R`中设计相关功能或实现时可以借鉴参考DAX函数的思路。比如在R中写自动化报表时，涉及到同环比计算时就可以按照这个模式设计。

-------------------------------------------

注意事项：

`R`中日期起始时间是`1970-01-01`,Excel中是`1900-01-01`,转化成数字两者相差25568。在用R读取Excel文件时，设计到日期数字转化成日期时需要注意其中差异。

R中日期 : `r Sys.Date() ` 转化成数字: `r as.integer(Sys.Date()) `,
Excel 中 `r Sys.Date() `转化成数字:`r as.integer(as.integer(Sys.Date())+25568) `,两者相差25568.




## 基础用法

获取当前日期、时间；拆解时间日期中的年、月、日、星期、计算年月天数，记录时刻等常用的时间日期功能，`lubridate`包中都有相对应的功能函数。

### 安装包

```{r eval=FALSE}
install.packages("tidyverse")
# 仅仅只安装lubridate
install.packages('lubridate')
# 开发版
devtools::install_github("tidyverse/lubridate")
```


```{r}
# 加载包
library(lubridate,warn.conflicts = FALSE)
```

### 获取当前时间日期

- `now`函数

```{r}
now(tzone = 'Asia/Shanghai')
#base R
base::Sys.time()
```

输出结果中，`CST`是指中国标准时间，即时区概念。

查看时区，时区和所用系统设置相关

```{r}
Sys.timezone()
# windows 系统默认的时区 中国台北
# linux 上是"Asia/Shanghai"
```
 
- `today`函数

```{r}
today(tzone = 'Asia/Shanghai')
#base R
base::Sys.Date()
```

### 获取日期时间中的组成部分

```{r}
#获取年
year(now())  
#获取月
month(now())
# 当前时间所在年份天数
yday(now())
# 当前时间所在月天数
mday(now())
# 周几
wday(now(),label = TRUE,week_start = 1)
# 所在时刻
hour(now())
# 所在时刻
minute(now())
# 所在时刻
second(now())

```


## 处理时区

如果生成数据时区与本地一致时，没必要处理，但是当数据是跨时区的或者不同生产系统的时区不一致，我们将要处理统一。

用`with_tz()`，`force_tz()`处理时区问题

```{r}
time <- ymd_hms("2020-12-13 15:30:30")
time

# Changes printing
with_tz(time, "Asia/Shanghai")
# Changes time
force_tz(time, "Asia/Shanghai")

```



## 解析日期和时间

从时间表达式中提取想要时间。存储的数据源中日期列可能是各种的字符形式，需要转换为时间格式方便进行日期计算。商业环境中的数据是混乱的，生成库可能是不同的系统，导致时间日期格式混乱，如果没有BI，我们就需要自己清洗数据，将不同形式的日期格式转化为标准格式。

```{r message=FALSE,warning=FALSE,echo=TRUE}

# 整数和字符都可以
ymd(20200604) 
ymd('20200604')
mdy(06042020)
dmy(04062020)
```

遇到unix 时间戳 可以用 .POSIXct()函数转化.

[unix在线转换](https://unixtime.51240.com/)

```{r}
.POSIXct(1591709615)
ymd_hms(.POSIXct(1591709615))
```

unix时间戳里面有时区的概念，在用mysql，RDS数据库时需要注意时区，特别是需要提取时间点时。lubridate包里面tz参数指定时区

```{r}
ymd_hms(.POSIXct(1591709615),tz = 'asia/shanghai')
```


从下面三个时间观察时区，CST时间:中央标准时间;UTC时间:世界协调时间(UTC)是世界上不同国家用来调节时钟和时间的主要时间标准。


如:当UTC时间为0点时，中国CST时间为8点，因为零时区和中国北京时区相差8个时区.

* <https://home.kpn.nl/vanadovv/time/TZworld.html#asi>

```{r}
lubridate::now()
as_datetime(now()) #默认是UTC
as_datetime(now(),tz = 'asia/shanghai')
```




## 构造日期或时间

使用数值直接创建日期时间`make_date`和`make_datetime`函数默认时区为"UTC"

```{r eval=FALSE}
make_date(year = year(today()), month = month(today()), day = day(today()), tz = "asia/shanghai")
make_datetime(
  year = year(today()),
  month = month(today()),
  day = day(today()),
  hour = hour(now()),
  min = minute(now()),
  sec = second(now()),
  tz = "asia/shanghai"
)

```

使用数值或字符直接创建日期时间

```{r}
as_datetime('2020-01-09 09:15:40',tz='asia/shanghai')
as_date('2020-01-09') #ymd格式
# same above
#as_date('2020/01/09')
#as_date('20200109')
```

## 时间间隔

我们可以用`lubridate`将时间间隔保存为`interveal`类对象

```{r}
arrive <- ymd_hms("2020-12-04 12:00:00", tz = "asia/shanghai")
arrive

leave <- ymd_hms("2020-12-10 14:00:00", tz = "asia/shanghai")
leave

res <- interval(arrive, leave) 
# same above
res <- arrive %--% leave
```

两个时间间隔是否重复
 
```{r}
jsm <- interval(ymd(20201020, tz = "asia/shanghai"), ymd(20201231, tz = "asia/shanghai"))
jsm
int_overlaps(jsm, res)
```

更多详细用法`?interveal`

```{r eval=FALSE}
interval(start = NULL, end = NULL, tzone = tz(start))

start %--% end

is.interval(x)

int_start(int)

int_start(int) <- value

int_end(int)

int_end(int) <- value

int_length(int)

int_flip(int)

int_shift(int, by)

int_overlaps(int1, int2)

int_standardize(int)

int_aligns(int1, int2)

int_diff(times)
```

## 时间日期计算

时间日期计算以`number line`为依据计算。原文是`Because the timeline is not as reliable as the number line`。

```{r}
minutes(2)
dminutes(2)
dhours(2)
```

注意闰年时计算年份的差异

```{r}
leap_year(2019)
ymd(20190101) + dyears(1)
ymd(20190101) + years(1)

leap_year(2020)
ymd(20200101) + dyears(1)  # 注意查看闰年时的差异
ymd(20200101) + years(1)
```

`lubridate`中的函数都已向量化

```{r}
meeting <- ymd_hms("2020-12-01 09:00:00", tz = "asia/shanghai")
meeting <- meeting + weeks(0:5)
meeting %within% jsm
```

除法计算

```{r}
res / ddays(1)
res / dminutes(1)


res %/% months(1)
res %% months(1)
```

`as.period`用法

```{r}
as.period(res %% months(1))
```

对于日期而言，因为月天数、年天数不一致，导致不能直接加减天数，如下：

```{r}
jan31 <- ymd("2020-01-31")
jan31 + months(0:11)
```

`lubridate`中不存在的日期返回`NA`

解决方案是：`%m+%`或`%m-%`

```{r}
jan31 %m+% months(0:11)
jan31 %m-% months(0:11)
```



## 案例


### 年同环比

`floor_date()`函数根据要求周期回滚日期，

```{r}
floor_date(today(),unit = 'year')
floor_date(today(),unit = 'month') #可与rollback函数达到同样效果
floor_date(today(),unit = 'week')
```

- 计算年同比

```{r}
n <- 1 
date <- today()
# current 
current_start_date <-  floor_date(date,unit = 'year')
current_start_date
date 
# last year
last_start_date <- floor_date(date,unit = 'year') %m-% years(n)
last_start_date
last_end_date <- date %m-% years(n)
last_end_date
```

月同比类似，回滚时间周期调整为"month"即可

- 计算月环比

`%m+%`或`%m-%`可以很好解决月份天数不一的问题

```{r}
as_date('2020-03-30') %m-% months(1)
today()
today() %m-% months(1)
```


得到了两对时间周期，然后在订单数据或者其他中筛选即可获得同比维度数据

模拟计算

```{r}
# 构造数据
bill_date <- as_date((as_date('2019-01-01'):as_date('2020-12-01')))
area <-  sample(c('华东','华西','华南','华北'),size = length(bill_date),replace = TRUE)
dt <- tibble::tibble(bill_date = bill_date ,money = sample(80:150,size = length(bill_date),replace = TRUE),area = area)
head(dt)
```

```{r}
library(dplyr,warn.conflicts = FALSE)

y_to_y <- function(.dt,date,n = 1,...){
  
  date <- ymd(date)
  
  if(is.na(date)){
    stop('请输入正确日期格式，如20200101')
  } 
  
  # current 
 current_start_date <-  floor_date(date,unit = 'year')
 
 # last year
 last_start_date <- floor_date(date,unit = 'year') %m-% years(n)
 last_end_date <- date %m-% years(n)
 
 .dt %>% mutate( 类型 = case_when(between(bill_date,current_start_date,date) ~ "当前",
               between(bill_date,last_start_date,last_end_date) ~ "同期",
               TRUE ~ "其他")) %>% 
   filter(类型 != "其他") %>% 
   group_by(...) %>% 
   summarise(金额 = sum(money,na.rm = TRUE)) %>% 
   ungroup() 
 
 #%>% pivot_wider(names_from = '类型',values_from = '金额')
 
}
```

```{r}
y_to_y(dt,date = '20200101',n = 1,area,类型)
```

### 清洗不同类型日期格式

如将`c('2001/2/13 10:33','1/24/13 11:16')`转换为相同格式的日期格式;

通过一个简单自定义函数解决，本质是区分不同类型日期后采用不同函数去解析日期格式

```{r message=FALSE}

library(lubridate)
library(tidyverse)

date1 <- c('2001/2/13 10:33','1/24/13 11:16')

myfun <- function(x){
  
  n_length <- length(x)
  res <- vector(length = n_length)
  
  for(i in 1:n_length){
    n <- strsplit(x[i],'/') %>% `[[`(1) %>% `[[`(1)
    if(str_length(n)==4){
      res[i] <- ymd_hm(x[i],tz = 'Asia/Shanghai')
    } else {
      res[i] <- mdy_hm(x[i],tz = 'Asia/Shanghai')
    }
  }
  as_datetime(res,tz = 'Asia/Shanghai')
}

myfun(date1)

```


### 扫码后中奖时间匹配

假定有两张表，一张是用户扫码表，一张是用户中奖表，如下所示：

![数据源视图](picture/datetime/p1.png)

由于中奖时间和扫码时间不完全一致，导致没办法直接通过`客户ID`以及`时间`关联匹配找到客户每次中奖时的积分码,现在要求找到客户每次中奖时对应的积分码？

思路：通过观察数据，发现扫码后如果中奖，一般几秒钟内会有中奖记录，那我们就可以通过"每次中奖时间最近的一次扫码时间的积分码"就是该次中奖对应的积分码解决问题。这样我们通过简单编写自定义函数即可获取答案，即一个时间点从一串时间中找到离自己最近时间点。

```{r eval=FALSE}
testfun <- function(x,y){
  result <- data.frame() #应采用列表存储结果向量化
  n  <-  length(x)
  for( i in 1:n){
    res <- x[i]-y
    res <- abs(res) %>% which.min() #本处不对，应该判断res大于0的部分中谁最小
    kong <- data.frame(中奖时间 = x[i],扫的时间 = y[res])
    result <- rbind(kong,result)
    
  }
  return(result)
}
res <- testfun(dt$时间,scan_dt$时间)
```

改进代码

```{r  eval= FALSE}
testfun <- function(x,y){
  n  <-  length(x)
  result <- list()
  
  for( i in 1:n){
    y <- y[x>y]
    res <- x[i]-y
    res <- res %>% which.min() 
    kong <- data.frame(中奖时间 = x[i],扫的时间 = y[res])
    result[[i]] <- kong
  }
  return(result)
}

res <- testfun(dt$时间,scan_dt$时间)
```


理论上不同用户可以在同一时间扫码且同时中奖，那上面的代码即不可以获取正确答案。但是我们只要通过按照用户ID切割数据框后稍微改造上面的自定义函数即可。

```{r eval=FALSE }
testfun <- function(dt){
  
  x <- dt$中奖时间
  y <- dt$扫的时间
  n  <-  length(x)
  result <- list()
  
  for( i in 1:n){
    y <- y[x>y]
    res <- x[i]-y
    res <- res %>% which.min() 
    kong <- data.frame(中奖时间 = x[i],扫的时间 = y[res])
    result[[i]] <- kong
  }
  result <- dplyr::bind_rows(result)
  return(result)
}
dtlist <- split(alldt,'客户ID')
purrr::map_dfr(dtlist,testfun)

```


虽然可以通过寻找最近一次的扫码记录判断积分码，但是因为网络延迟或中途接电话等各种原因导致扫码时间和中奖时间相差并不是几秒，导致情景复杂，那我们就应该在设计系统时就设计好锁定对应关系，从根本上解决问题。



## 资料

* <https://cran.r-project.org/web/packages/lubridate/vignettes/lubridate.html>

* <https://www.rdocumentation.org/packages/lubridate/versions/1.7.8>

* pdf 下载  <https://rawgit.com/rstudio/cheatsheets/master/lubridate.pdf>

* Excle中dax时间智能函数  <https://docs.microsoft.com/en-us/dax/time-intelligence-functions-dax>

<!--chapter:end:04-lubridate.Rmd-->

```{r include=FALSE, cache=FALSE}
set.seed(1014)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
 # cache = TRUE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)

options(dplyr.print_min = 6, dplyr.print_max = 6)
```
# forcats

我在实际工作中因子数据类型使用较少,forcats软件包用来处理因子,该软件包是tidyverse的一部分.

因子是用于对数据进行分类的R的一种数据类型. 它们可以存储字符串和整数.它们在具有有限数量的唯一值的列中很有用. 像“男性”，“女性”和True，False等。它们在统计建模的数据分析中很有用.


因子变量会占用更小空间,R4.0改变了字符默认为因子的方式.想了解更多请参考 <https://r4ds.had.co.nz/factors.html>


```{r }
object.size(rep(letters,100000))
object.size(rep(forcats::as_factor(letters),100000))
```

## 创建因子

实际工作中,可能各个事业部或部门之间没有实际顺序,但是在数据处理过程中需要指定顺序可以用因子.

```{r}
library(forcats)
vec1 <- c('部门a','部门b','部门d','部门f')
sort(vec1)
vec2 <- as_factor(c('部门f','部门d','部门a','部门b'))
sort(vec2)

```

如上所示:实际工作中可以通过指定因子水平从而达到排序效果,在可视化中也可以运用,像指定X轴的顺序.


<!--chapter:end:05-forcats.Rmd-->

```{r include=FALSE, cache=FALSE}
set.seed(1014)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
 # cache = TRUE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)

options(dplyr.print_min = 6, dplyr.print_max = 6)
```
# data.table


data.table包是我数据处理最常用的R包，是我目前觉得最好用的数据处理包,大部分我需要用到的功能集成在包里，不需要很多的依赖包。我简单接触过python，julia两种语言，并没有深入比较，所以我这个好用的印象仅仅是个人感受。

data.table包是我用了较长一段时间tidyverse系列后发现的“数据处理包”。已经忘记最初是什么吸引了我，我猜测可能是“大数据处理利器”之类的标签吸引了我，因为我喜欢“快”。但是和大部分人可能不同的是，初次接触时，语法的“怪异”并没有给我带来多少麻烦，因为我本来就没有编程基础以及很深的R语言基础。

所以我死记硬背data.table里一些常用用法，尤其喜欢拿Excle的一些用法参照，去实现Excle上面的部分操作，从读取、增、改、删除、筛选、计算列等常规操作入手。慢慢熟悉data.table语法之后，将会享受data.table带来的便利，其简洁的语法以及高效的计算速度（相比tidyverse系列）。

另外，Python中也有该包，目前正在积极开发中，期待ing，毕竟python也是很好用，在不同需求下选择不同的语言实现功能。

官方关于data.table的基础介绍请参阅:

https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html

data.table 优势：

- 速度快
- 内存效率高
- API生命周期管理好
- 语法简洁




## 基础介绍

本部分从data.table安装，内置的案例查看，到data.table的句式语法，实现基础行列筛选和聚合计算。

1.安装

安装详细信息请参考[the Installation wiki](https://github.com/Rdatatable/data.table/wiki/Installation)，有关于不同系统安装首次以及相关说明。

```{r eval=FALSE}
install.packages("data.table")
# latest development version:
data.table::update.dev.pkg()
```

2.使用说明

通过以下代码查看内置的使用案例。

```{r eval=FALSE}
library(data.table)
example(data.table)
```


### 读取数据

在我实际工作中接触的数据大部分以数据库,csv,Excel等形式存在，并且CSV格式数据较少。但是data.table包读取数据的`fread`函数仅接受CSV格式。如果是Excel格式文件，需要通过如`readxl`，`openxlsx`等包读入后转换为`data.table`格式数据。

fread 函数可以直接读取CSV格式文件,无论是本地文件或者在线文件.

本文会照搬很多官方关于data.table的demo.

```{r}
library(data.table)
input <- if (file.exists("./data/flights.csv")) {
   "./data/flights.csv" #本地文件
} else {
  "https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights.csv" #在线文件需翻墙
}
flights <- fread(input) #具体参数请参照文档  实际工作中可能会用到的encoding参数,编码 encoding='UTF-8'

head(flights)

```

本文读取本地文件,如果该数据集下载失败,可更改地址为(http://www.zhongyufei.com/datatable/data/flights.csv)

```{r eval=FALSE}
flights <- fread("http://www.zhongyufei.com/datatable/data/flights.csv")
```


数据集记录的是 2014 年,纽约市3大机场(分别为:JFK 肯尼迪国际机场、 LGA 拉瓜迪亚机场,和 EWR 纽瓦克自由国际机场)起飞的航班信息。

具体的记录信息(特征列)，包括起飞时间、到达时间、延误时长、航空公司、始发机场、目的机场、飞行时长，和飞行距离等。



### 基本格式

`DT[i, j, by]`是data.table的基本样式，在不同位置上实现不同功能。

![i-j-by](https://gitee.com/zhongyufei/photo-bed/raw/pic/img/data.table-i-j-by%E4%BB%8B%E7%BB%8D.png)

```{r eval=FALSE}
DT[i, j, by]
##   R:                 i                 j        by
## SQL:  where | order by   select | update  group by
```

data.table个人理解主要有三大类参数,i参数做筛选,j参数做计算,by参数做分组.

拿Excel透视表类别,i位置参数当作『筛选』,by位置用来做汇总字段『行』,j位置当作『值』,如下所示:

![透视表截图](./picture/data-table/01picture.png)

1.代码实例

代码求2014年6月,从各始发机场到各目的机场的飞行距离求和.

```{r}
library(data.table)
flights <- fread("./data/flights.csv")
flights[year==2014 & month==6,.(求和项distance=sum(distance)),by=.(origin,dest)]
```

2.代码解释

i 的部分：条件year==2014 和 month==6 ;

j 的部分：求和项distance=sum(distance)，写在.()中或者list()中；

by 的部分.(origin,dest),重点是写在.()中,和Excel透视表一一对应。


至于为什么要用.()包裹起来，最开始默认为格式强制要求。就这个问题我想说：大部分人可能觉得是比较“怪异”的用法，并且不理解，从而可能留下data.table不好用，很古怪的印象，但是我觉得任何东西存在即合理，你学一个东西总得接受一些你可能不认可的东西，这样可能才是真正的学习，就像拿Python来做数据分析，我刚开始觉得pandas很难用，很反人类，但是后来知道python代码可以直接打包封装成exe后，觉得真香，说这么多主要是想表达我们学会挑选合适的工具用，适应它，用好它就可以了。




### i j by 使用

使用data.table处理数据，接下来我们就用该函数读取数据演示i,j,by的简单使用。




#### i行筛选

行筛选是一种很常见的数据操作行为，类似我们Excel中的筛选，即按照一定条件筛选符合要求的数据。条件筛选一般分为单条件筛选、多条件筛选；

在筛选时涉及到条件判断，R语言中常用的条件判断分为逻辑运算、关系运算。常用的关系运算符 >、 <、==、!=、>=、<=分别代表大于、小于、等于、不等于、大于等于、小于等于。常用的逻辑运算符 &、|、！等。


```{r eval=FALSE}
#单条件筛选
filghts[year == 2014] #筛选year==2014
#多条件筛选 用 & 链接
flights[ year == 2014 & month == 6] 
# | 相当于中文条件或 
flights[ month == 5 | month == 6] 
# %in% 类似sql中in用法
flights[month %in% c(1,3,5,7,9)] 
# %between% 类似sql中between and 用法
flights[month %between% c(1,7)]
```

#### j列操作

数据集较大、字段较多时，由于无效信息较多可以做适当精选，这时需要我们筛选列。与sql中的select用法一致，即保留想要的字段。

.()或list()是data.table中的比较特殊的实现列筛选的用法。常规数字索引，字符向量索引同样有效。

```{r}
#注意前面的. .()
flights[,.(year,month,day,dep_delay,carrier,origin)] 
# flights[,list(year,month,day,dep_delay,carrier,origin)]  same above

# not run
# flights[,1:3]

# not run
# flights[,c('year','month','day')]
```

setcolorder函数可以调整列的顺序，将常用的字段信息排在前面可以用过该函数实现。

```{r}
# not run
# setcolorder(x = flights,neworder = c( "month","day","dep_delay" ,"arr_delay","carrier" )) 
# 按照指定列顺序排序 其余字段保持不变,不是建立副本,是直接修改了flights 数据的列顺序
```

- 常规计算

根据最开始的Excel透视表截图，我们想要获得如截图一样的结果该怎么实现呢？代码如下：

```{r,eval=FALSE}
flights[year==2014 & month==6,.(求和项distance=sum(distance),平均距离=mean(distance)),by=.(origin,dest)]
```

在i的位置做筛选，j的位置做计算，by指定分组字段。在j的位置可以做各种各样的计算，R中自带的函数，或者是自己定义的函数。

```{r}
myfun <- function(x){
    x^2/2
}
flights[year==2014 & month==6,.(myfun(distance)),by=.(origin,dest)]
```

#### by 分组

分组是按照某种分组实现一定条件下某种聚合方式的计算。分组可以是单字段，多字段以及条件字段等。

1.按月分组

```{r}
flights[,.(sum(distance)),by=.(month)]
```

2.多条件分组

```{r}
dt <- flights[,.(sum(distance)),by=.(carrier,origin)]
head(dt)
#可直接重新命名
dt <- flights[,.(sum(distance)),by=.(newcol1 = carrier,newcol2 = origin)]
head(dt)
```


3.按月份是否大于6分组

即得到是否大于6的两类分组

```{r}
dt <- flights[,.(sum(distance)),by=.(month>6)] #by里面可以做计算
head(dt)
```


### 行列筛选总结

行筛选在 i 的位置上进行, 列筛选在 j 的位置上进行;data.table中j的位置比较灵活多变，但是i的位置大部分时候都是进行条件筛选。我们通过上述的行列筛选已经大概知道data.table中i,j的用法。也就是我们常规数据清洗过程中的数据筛选过程，筛选符合要求的数据记录。

```{r}

dt <- flights[ year == 2014 & month == 6 & day >=15,.(year,month,day,dep_delay,carrier,origin)] 
head(dt)

```




## 常规操作


### 行筛选

上文已经大致讲过行筛选，但是行筛选使用有一定的技巧，涉及到运算的快慢。主要是逻辑条件的设置，交集并集之间的差异。除了上文中的关系运算筛选，逻辑运算筛选除外，data.table中还有几个常用的筛选函数。

- 数字向量筛选 

%in%用法与 sql 中 in 用法类似。

```{r eval=FALSE}
# 筛选 %in% 
flights[ hour %in% seq(1,24,2) ]

```

- 字符向量筛选

%chin%用法与 %in% 类似，但仅仅针对字符。

```{r eval=FALSE}
# 字符筛选
flights[ origin %chin% c('JFK','LGA')]
# not run 同上 %chin% 对字符速度筛选速度更快
#flights[ origin %in% c('JFK','LGA')]

```

- between 筛选 

该函数的新特性矢量化挺实用。

```{r}
#between 函数参数
#between(x, lower, upper, incbounds=TRUE, NAbounds=TRUE, check=FALSE)
X <-  data.table(a=1:5, b=6:10, c=c(5:1))
X[b %between% c(7,9)]
X[between(b, 7, 9)] #效果同上
X[c %between% list(a,b)] # 矢量化
```

- like 筛选

%like% 用法与SQL中 like 类似。

```{r}
# %like% 用法与SQL中 like 类似
DT = data.table(Name=c("Mary","George","Martha"), Salary=c(2,3,4))
DT[Name %like% "^Mar"]
```

### 新增更新列


新增或删除或更新列是我们数据清洗过程中的常规操作，`data.table中`实现该类功能是通过`:=`符号实现。

- 选择列

```{r}
dt <- data.table(col1=1:10,col2=letters[1:10],col3=LETTERS[1:10],col4=1:10)
dt[,.(col1,col2)]
# same above
dt[,list(col1,col2)]
```


- 新增列

如下所示:新增addcol列，最后的[]是为了显示新增列的数据框,可不增加。

```{r}
#data.table()函数创建data.table数据框
dt <- data.table(col1=1:10,col2=letters[1:10],col3=LETTERS[1:10],col4=1:10)
# 新增列 :=
dt[,addcol:=rep('新列',10)][] #最后的[]是为了显示新增列的数据框,可不增加
#dt[,addcol:=rep('新列',10)] 不会显示返回结果,加上[]会显示返回
# 新增多列
dt[,`:=`(newcol1=rep('newcol1',10),newcol2=rep('newcol2',10))][]
```



- 删除列

删除列即将列赋值NULL即可

```{r}
# 删除列
dt[,col1:=NULL][]
# 删除多列
dt[,c('newcol1','newcol2'):=NULL][]
```


- 更新

更新即重新赋值，将现有列参与计算等于是重新赋值，可以看成是更新列。

```{r}
# 更新列
dt[,col1:=11:20][]
# not run 
# 两列间计算 也可以理解为更新
dt[,newcol:=col1/col4]
```

> Note: DT[a > 4, b := c] is different from DT[a > 4][, b := c]



### 排序

当我们清洗数据时，我们需要将数据框排序，我们可以使用`setorder`或`setorderv`函数实现排序。函数是`data.table`包的函数，比base R 中的`order`函数要节省内存。
注意：按照函数文档说法：Note that queries like x[order(.)] are optimised internally to use data.table's fast order。即x[order(.)]这样的用法会被优化为data.table的排序方法。


```{r}
set.seed(45L)
DT = data.table(A=sample(3, 10, TRUE),
         B=sample(letters[1:3], 10, TRUE), C=sample(10))

setorder(DT, A, -B) #将DT按照A、B排序 A 升序,-B降序

# 和上面同样的效果 但是函数变成 setorderv
setorderv(DT, c("A", "B"), c(1, -1))
```








## 常用函数

常用函数指我们常用功能的函数，如排名、排序、非重复计数、判断、表连接、长宽转换等功能。


### 特殊符号

.SD,.BY,.N,.I,.NGRP和.GRP,.SDcols等,只能用在 j 的位置,.N 可以用在 i 的位置。

如果想要记住用法需要自己多尝试练习，对于我来说.N使用较多。

```{r}
DT = data.table(x=rep(c("b","a","c"),each=3), v=c(1,1,1,2,2,1,1,2,2), y=c(1,3,6), a=1:9, b=9:1)
DT
X = data.table(x=c("c","b"), v=8:7, foo=c(4,2))
X

# 用在i的位置
DT[.N] #取DT最后一行,.N 计数函数
DT[,.N] #DT 共有多少行记录 返回一个整数
DT[, .N, by=x]  #分组计数
DT[, .SD, .SDcols=x:y]  # 选择x 到y 列
#DT[, .SD, .SDcols=c("x","y")] 与上面不一样

DT[, .SD[1]] #取第一行
DT[, .SD[1], by=x] #按x列分组后
DT[, c(.N, lapply(.SD, sum)), by=x] #按照x分组后 行数计数和每列求和
```


### 排序函数

`frank`和`frankv`函数参数如下：

```{r eval=FALSE}
frank(x, ..., na.last=TRUE, ties.method=c("average",
  "first", "last", "random", "max", "min", "dense"))

frankv(x, cols=seq_along(x), order=1L, na.last=TRUE,
      ties.method=c("average", "first", "random",
        "max", "min", "dense"))
```

官方案例,如下所示:

```{r}
# on vectors
x = c(4, 1, 4, NA, 1, NA, 4)
# NAs are considered identical (unlike base R)
# default is average
frankv(x) # na.last=TRUE
frankv(x, na.last=FALSE)

# on data.table
DT = data.table(x, y=c(1, 1, 1, 0, NA, 0, 2))
frankv(DT, cols="x") # same as frankv(x) from before
frankv(DT, cols="x", na.last="keep")
frankv(DT, cols="x", ties.method="dense", na.last=NA)
frank(DT, x, ties.method="dense", na.last=NA) # equivalent of above using frank
```


* frankv在排序时,NA被认为是一样的,基础base R 中认为不一样.


```{r}
x <-  c(4, 1, 4, NA, 1, NA, 4) 
frankv(x)
rank(x)
```


* 升序降序选择

order参数只能为1或者-1.默认为1代表升序

```{r}
frankv(x,order = 1L)
frankv(x,order = -1L)
```


* 排序方式选择

默认 average,还有dense,random,first,last,max,min等方式。其中dense是紧凑排名，random是随机让相同的随机排列后排名


```{r eval=FALSE}
x <- c(1,1,1,2,3)
frankv(x)  #大小相同 排名相同,下一位排名除以2
frankv(x,ties.method = 'min')  #大小相同 排名相同,取最小排名
frankv(x,ties.method = 'max')  #大小相同 排名相同,取最大排名
frankv(x,ties.method = 'first') #相同大小排名以后往后递增 根据实际情况决定
frankv(x,ties.method = 'dense')
frankv(x,ties.method = 'random')

```

* NA处理

默认是将NA排在最后,NAs是相同的，与base R 不一样。

na.last参数等于TRUE时，缺失值被排最后；如果等于FALSE,放在前面；如果等于NA，将被移除；如果等于"keep",将会保留NA.

```{r}
frankv(c(NA,NA,1,2,3), na.last = TRUE,ties.method = 'first')
frankv(c(NA,NA,1,2,3), na.last = FALSE,ties.method = 'first')
frankv(c(NA,NA,1,2,3), na.last = NA,ties.method = 'first')
frankv(c(NA,NA,1,2,3), na.last = 'keep',ties.method = 'first')
```


### 非重复计数

`uniqueN`相当于`length(unique(x))`,但是计算更快，内存效率更高。

```{r}
x <-sample(1:10,50,replace = TRUE)
uniqueN(x)

DT <- data.table(A = rep(1:3, each=4), B = rep(1:4, each=3),
                 C = rep(1:2, 6), key = "A,B")

uniqueN(DT, by = key(DT))
uniqueN(DT)
```




### 判断函数

- fifelse

fifelse()类似`dplyr::if_else()`函数,相比base::ifelse() 更快。

```{r}
x <-  c(1:4, 3:2, 1:4,5)
fifelse(x > 2L, x, x - 1L)

fifelse(x > 2L,fifelse(x >= 4L,x + 1L,x),x-1L)
```

- fcase 

与sql中的case when，与dplyr中的`case_when()`函数用法相似。相比fifelse相比，嵌套更加方便。

```{r}
x = 1:10
fcase(
	x < 5L, 1L,
	x > 5L, 3L
)

# not run 两种函数实现方式
fifelse(x > 5,fifelse(x >8,2,1),0)
fcase(
  x > 8,2,
  x > 5,1,
  default = 0
)
```


### 交集 差集 合并


相当于base R 中 union(),intersect(),setdiff() 和setequal() 功能.all参数控制如何处理重复的行,和SQL中不同的是,data.table将保留行顺序.

```{r eval=FALSE}

fintersect(x, y, all = FALSE)
fsetdiff(x, y, all = FALSE)
funion(x, y, all = FALSE)
fsetequal(x, y, all = TRUE)

x <-  data.table(c(1,2,2,2,3,4,4))
x2 <-  data.table(c(1,2,3,4)) # same set of rows as x
y <-  data.table(c(2,3,4,4,4,5))

fintersect(x, y)            # intersect
fintersect(x, y, all=TRUE)  # intersect all

fsetdiff(x, y)              # except
fsetdiff(x, y, all=TRUE)    # except all
funion(x, y)                # union
funion(x, y, all=TRUE)      # union all
fsetequal(x, x2, all=FALSE) # setequal
fsetequal(x, x2)            # setequal all
```



### 长宽转换

主要是两个函数`dcast`以及`melt`实现长宽转换，实现Excel中部分透视表功能。具体的函数参数请自行查阅文档。

- dcast函数能实现长转宽

参数如下：fun.aggregate函数指定聚合函数，value.var参数指定参与聚合的字段。formula指定聚合维度，格式用x+y~z，其中x,y在行的位置，z在列的位置。

```{r eval=FALSE}
dcast(data, formula, fun.aggregate = NULL, sep = "_",
    ..., margins = NULL, subset = NULL, fill = NULL,
    drop = TRUE, value.var = guess(data),
    verbose = getOption("datatable.verbose"))
```

示例如下：


```{r}
dt <- data.table(分公司=rep(c('华东','华南','华西','华北'),1000),
              季度=rep(c('一季度','二季度','三季度','四季度'),1000),
              销售额=sample(100:200,4000,replace = TRUE))
dcast(dt,分公司~季度,value.var = "销售额",fun.aggregate = sum)
```

从版本V1.9.6起可以同时对多个值实现不同聚合后的长转宽。

fun参数即 fun.aggregate的简写，可以是自定义的函数。


```{r}
dt <-  data.table(x=sample(5,20,TRUE), y=sample(2,20,TRUE),
                z=sample(letters[1:2], 20,TRUE), d1 = runif(20), d2=1L)
dcast(dt, x + y ~ z, fun=list(sum,mean), value.var=c("d1","d2"))
dcast(dt, x + y ~ z, fun=list(sum,mean), value.var=list("d1","d2")) #注意value.var是向量和列表时的区别
```


- melt函数实现宽转长

```{r eval=FALSE}
melt(data, id.vars, measure.vars,
    variable.name = "variable", value.name = "value",
    ..., na.rm = FALSE, variable.factor = TRUE,
    value.factor = FALSE,
    verbose = getOption("datatable.verbose"))
```

示例如下:

```{r}
ChickWeight = as.data.table(ChickWeight)
setnames(ChickWeight, tolower(names(ChickWeight)))
DT <- melt(as.data.table(ChickWeight), id=2:4) # calls melt.data.table
DT
```




### 表连接

两个数据框之间左连,右连等操作,类似数据库中的left_join right_join,inner_join 等函数.

键入?merge()查看函数帮助,data.table 包中和base R 中都有merge 函数,当第一个数据框是data.table格式时启用data.table::merge(). 

```{r eval=FALSE}
?merge()
merge(x, y, by = NULL, by.x = NULL, by.y = NULL, all = FALSE,
all.x = all, all.y = all, sort = TRUE, suffixes = c(".x", ".y"), no.dups = TRUE,
allow.cartesian=getOption("datatable.allow.cartesian"),  # default FALSE
...)
```

x.y为连个数据框,当两个数据框连接字段相同时,用by=c('','')连接,不同时采用,by.x=,by.y= ,all,all.x,all.y等参数决定连接方式,sort 默认为排序,当不需要排序时更改参数,allow.cartesian=是否允许笛卡尔,默认不允许,当需要时设置为TURE.


## 高级函数

高级函数并不是指使用难度，而是使用频率可能不高，但在实现某些功能时特别便利的函数。

如分组聚合的`groupingsets`,前后移动的`shift`等函数。

### groupingsets

产生多个层次的合计数据，与`sql`中的[grouping set](https://www.postgresql.org/docs/9.5/queries-table-expressions.html#QUERIES-GROUPING-SETS)功能相似。

**用法**

```{r  eval=FALSE}
rollup(x, j, by, .SDcols, id = FALSE, ...)
groupingsets(x, j, by, sets, .SDcols, id = FALSE, jj, ...)

# rollup
rollup(DT, j = lapply(.SD, sum), by = c("color","year","status"), id=TRUE, .SDcols="value")
rollup(DT, j = c(list(count=.N), lapply(.SD, sum)), by = c("color","year","status"), id=TRUE)

```

如果要达到像Excel中透视表一样的效果，如下所示:

![Excel groupingsets透视表](./picture/data-table/Excel-pivot-groupingsets.png)


- rollup 

```{r}
library(magrittr)
DT <- fread('./data/data-table-groupingsets.csv',encoding = 'UTF-8')
(rollup(DT,j =list(以下项目的总和 =sum(value)),by = c("area","store_type"),id = TRUE) %>% setorderv(cols=c('area','grouping'),na.last = TRUE))
```

通过上述计算,发现计算结果与Excel透视表一样。


- cube

观察`cube()`计算结果与`rollup()`差异，发现`cube()`聚合层次更多。

```{r}
cube(DT,j = sum(value),by = c("area","store_type"),id = TRUE)
```

- groupingsets

根据需要指定指定聚合的层次。

```{r}
# 与本例中rollup 结果一致
groupingsets(DT,j = sum(value),by = c("area","store_type"),sets = list('area',c("area","store_type"), character()),id = TRUE)

# 与本例中cube 结果一致
groupingsets(DT,j = sum(value),by = c("area","store_type"),sets = list('area',c("area","store_type"),"store_type", character()),id = TRUE)
```

> groupingsets: sets参数,用list()包裹想要聚合的字段组合,最后character(),加上该部分相当于不区分层级全部聚合,用法类似sql中"()".

> SELECT brand, size, sum(sales) FROM items_sold GROUP BY GROUPING SETS ((brand), (size), ());



[comment]: <> (This is a comment, it will not be included)


### rleid

该函数根据分组生成长度列。

即将0011001110111101类似这种分组成1 1 2 2 3 3 4 4 4 5 6 6 6 6 7 8。在特定时候是很便捷的一个函数。如在计算股票连续上涨或下跌天数时。

```{r}
rleid(c(0,0,1,1,0,0,1,1,1,0,1,1,1,1,0,1))
```

用法：

```{r eval=FALSE}
rleid(..., prefix=NULL)
rleidv(x, cols=seq_along(x), prefix=NULL)
```

```{r}
DT = data.table(grp=rep(c("A", "B", "C", "A", "B"), c(2,2,3,1,2)), value=1:10)
rleid(DT$grp) # get run-length ids
rleidv(DT, "grp") # same as above
rleid(DT$grp, prefix="grp") # prefix with 'grp'
```

### shift

向前或向后功能,通俗来说就是向前或向后移动位置。


示例如下：

```{r}
x = 1:5
# lag with n=1 and pad with NA (returns vector)
shift(x, n=1, fill=NA, type="lag")
```

其中参数n控制偏移量，n正负数和type的参数相对应。, n=-1 and type='lead' 与 n=1 and type='lag'效果相同。

在data.table上使用：

```{r}
DT = data.table(year=2010:2014, v1=runif(5), v2=1:5, v3=letters[1:5])
cols = c("v1","v2","v3")
anscols = paste("lead", cols, sep="_")
DT[, (anscols) := shift(.SD, 1, 0, "lead"), .SDcols=cols]
```

例如求某人连续消费时间间隔天数时：

```{r}
DT = data.table(dates =lubridate::ymd(c(20210105,20210115,20210124,20210218,20210424)))
DT[,newdate:=shift(dates)]
DT
```

通过构造新列newdate，然后将两列相减`dates-newdate`即可得到每次购物间隔天数。


### J

J 是`.()`,`list()`等的别名。`SJ`是排序连接，`CJ`是交叉连接。

用法：

```{r eval=FALSE}
# DT[J(...)]                          # J() only for use inside DT[...]
# DT[.(...)]                          # .() only for use inside DT[...]
# DT[list(...)]                       # same; .(), list() and J() are identical
SJ(...)                             # DT[SJ(...)]
CJ(..., sorted=TRUE, unique=FALSE)  # DT[CJ(...)]
```


- CJ 

我喜欢用`CJ()`函数创建笛卡尔积表。例如在商品运营中，时常需要将门店和商品形成笛卡尔积表，相比起`dplyr::full_join()` ,`data.table::merge.data.table(allow.cartesian = TRUE )`,`CJ`更加方便快捷。

```{r}
# CJ usage examples
CJ(c(5, NA, 1), c(1, 3, 2))                 # sorted and keyed data.table
# do.call(CJ, list(c(5, NA, 1), c(1, 3, 2)))  # same as above
# CJ(c(5, NA, 1), c(1, 3, 2), sorted=FALSE)   # same order as input, unkeyed
```

- SJ

SJ : Sorted Join. The same value as J() but additionally setkey() is called on all columns in the order they were passed to SJ. For efficiency, to invoke a binary merge rather than a repeated binary full search for each row of i.


















## 小技巧

### 用{}抑制中间过程输出

默认只返回未命名花括号中定义的最后一个对象。

```{r}
dt <- data.table(mtcars)
dt[,{tmp1=mean(mpg); tmp2=mean(abs(mpg-tmp1)); tmp3=round(tmp2, 2)}, by=cyl]
```

在我不知道上述技巧之前，我可能的操作是

```{r}
dt <- data.table(mtcars)
res <- dt[,tmp1:=mean(mpg), by=cyl][,.(tmp2=mean(abs(mpg-tmp1))), by=.(cyl)]
res[,.(round(tmp2,2)),by=.(cyl)][]
```


保留中间变量

```{r}
dt[,{tmp1=mean(mpg); tmp2=mean(abs(mpg-tmp1)); tmp3=round(tmp2, 2); list(tmp2=tmp2, tmp3=tmp3)}, by=cyl][]
```

不写分号的方式

```{r}
dt[,{tmp1=mean(mpg)
     tmp2=mean(abs(mpg-tmp1))
     tmp3=round(tmp2, 2)
     list(tmp2=tmp2, tmp3=tmp3)},
   by=cyl][]
```


### 使用[]打印data.table

在测试代码查看结果时很有用。

```{r}
df <- head(mtcars) # doesn't print
(df <- head(mtcars)) # does print
```

```{r}
# data.table way of printing after an assignment
dt <- data.table(head(mtcars)) # doesn't print
dt[,hp2wt:=hp/wt][] # does print
```


## 运用

### 自定义函数计算

1.自定义函数处理列

按照自定义函数计算修改单列或多列

```{r}
# 测试函数

fun <- function(x){
  x <- x^2+1
}

DT <-  data.table(x=rep(c("b","a","c"),each=3), v=c(1,1,1,2,2,1,1,2,2), y=c(1,3,6), a=1:9, b=9:1)

DT[,.(newcol=fun(y)),by=.(x)]

#Not run
#DT[,lapply(.SD,fun),.SDcols=c('y','a'),by=.(x)] #多列参与计算


# 批量修改列
#Not run

# myfun <- function(x){
#   return(x)
# }
# 
# dt <- dt[,colnames(dt):=lapply(.SD[,1:ncol(dt)],myfun)] #很重要的用法

```


### 带汇总的聚合运算

按照by的字段级别汇总.

1. rollup

分组聚合后设置id=TRUE将各个级别的汇总显示清晰,当by字段只有一个是和正常聚合计算没有区别.以下是官方案例.

```{r}
#Usage
#rollup(x, j, by, .SDcols, id = FALSE, ...)
n = 24L
set.seed(25)
DT <- data.table(
    color = sample(c("green","yellow","red"), n, TRUE),
    year = as.Date(sample(paste0(2011:2015,"-01-01"), n, TRUE)),
    status = as.factor(sample(c("removed","active","inactive","archived"), n, TRUE)),
    amount = sample(1:5, n, TRUE),
    value = sample(c(3, 3.5, 2.5, 2), n, TRUE)
)
rollup(DT, j = sum(value), by = c("color","year","status")) # default id=FALSE
#rollup(DT, j = sum(value), by = c("color","year","status"), id=TRUE)
```



个人运用,实际工作中常常需要汇总项,汇总项在Excel透视表中很简单,在R中我之前是构造重复的数据源聚合汇总出现汇总项,极大浪费内存,运算速度减慢.


* 新方法 rollup

```{r}
set.seed(25)
N <- 1000
dt <- data.table(col1=sample(LETTERS[1:5],N,replace = T),col2=sample(letters[1:5],N,replace = T),num=1:N)

rollup(dt,j=c(list(sum(num))),by=c('col1','col2'))
#同上 添加汇总项名称 total
#rollup(dt,j=c(list(total=sum(num))),by=c('col1','col2'))
#添加id=TRUE参数,多出的grouping 列显示聚合级别
#rollup(dt,j=c(list(total=sum(num))),by=c('col1','col2'),id=TRUE)
```

2.groupingsets

按照指定字段聚合.包作者说相同与SQL中的 GROUPING SETS 操作.详情参照[postgresql](http://www.postgresql.org/docs/9.5/static/queries-table-expressions.html#QUERIES-GROUPING-SETS)


```{r}
res <- groupingsets(DT, j = c(list(count=.N), lapply(.SD, sum)), by = c("color","year","status"),
             sets = list("color", c("year","status"), character()), id=TRUE)
head(res)
```

注意groupingsets函数中sets参数,用list()包裹想要聚合的字段组合,最后还有一个character(),加上该部分相当于全部聚合.当by只有一个字段时,相当于汇总.用法类似sql中"()".


```{r eval=FALSE,echo=FALSE}
library(DBI)
con <- dbConnect(odbc::odbc(), .connection_string = "Driver={SQL Server};server=Vega;database=ghzy;uid=zhongyf;pwd=Zyf123456;", timeout = 10)
```


上述语句结果等同于下面sql.

```{sql eval=FALSE}
select color ,year, status,count(*) count,sum(amount) amount,sum(value) value 
FROM dbo.DT
GROUP BY
GROUPING SETS(
(color),
(year,status),
() ---- 类似 character()
)
```

最后还有cube()函数,可?cube查看用法


### 行列转变

* 一列变多行

用tstrsplit()函数实现

```{r}
n <- 10
dt <- data.table(name=LETTERS[1:n],char=rep('我-爱-R-语-言'),n)
res <- dt[,.(newcol=tstrsplit(char,'-')),by=.(name)]
head(res)
```

* 多行变一列

```{r}
res[,.(char=paste0(newcol,collapse = '-')),by=.(name)]
#同上
#res[,.(char=stringr::str_c(newcol,collapse = '-')),by=.(name)]
# A	我-爱-R-语-言			
# B	我-爱-R-语-言			
# C	我-爱-R-语-言			
# D	我-爱-R-语-言			
# E	我-爱-R-语-言			
# F	我-爱-R-语-言			
# G	我-爱-R-语-言			
# H	我-爱-R-语-言			
# I	我-爱-R-语-言			
# J	我-爱-R-语-言
```


<!--chapter:end:01-datatable.Rmd-->

```{r include=FALSE, cache=FALSE}
set.seed(1014)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
 # cache = TRUE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)

options(dplyr.print_min = 6, dplyr.print_max = 6)
```

```{r setup1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,eval = FALSE)
```


# database

实际工作中，需要从数据库获取数据并清洗，R与数据库有多种交互方式,目前工作中打交道数据库主要是MSSQL,Oracle,mysql等,本文主要从以上数据库介绍记录“R与数据库的连接”。

R中与数据库交互的包主要有DBI,RODBC,RMySQL,ROracle,odbc等包。DBI库在查询或上传工作中效率比RODBC高,特别数据量较大时,上传效率差异巨大,具体[差异](https://github.com/r-dbi/odbc)请点击查看详情。


即使你暂时没有用数据库，也建议你未来用数据库存储数据，尤其是当有一定数据量时;在我最开始接触数据时，数据一般保存在Excel,那时候数据量大概在50万行左右，当公式较多，尤其时需要大批量vlookup时，Excel表格将会很卡顿。


## 安装数据库

如果暂时没有数据库使用经验，如果是使用Windows系统，直接去微软官网下载安装数据库即可。如果决定用R做数据分析相关工作，尤其时商业环境下，使用数据库有较强的必要性。安装数据库后，利用数据库做数据分析的练习测试也是不错的体验。另外也可以积累ETL相关经验。

仅简单介绍 MS SQL Server 安装

- Win环境下安装

MS[下载](https://www.microsoft.com/zh-cn/sql-server/sql-server-downloads)，选择开发版或精简版(Developer、Express)其中一个版本下载即可。

![数据库下载](./picture/chap2/ms install.png)

成功下载后，按照提示一步步确认即可安装成功。另外使用`SSMS`工具，微软配套的MS SQL SERVER数据库链接工具连接数据库。至于详细的数据库配置尤其是远程连接、账户等信息请自行查阅相关资料。

- Linux环境下安装

[官网安装指南](https://docs.microsoft.com/zh-cn/sql/linux/sql-server-linux-setup?view=sql-server-ver15)

以下用于 SQL Server 2019 的命令指向 Ubuntu 20.04 存储库。 如果使用的是 Ubuntu 18.04 或 16.04，请将以下路径更改为 /ubuntu/18.04/ 或 /ubuntu/16.04/，而不是 /ubuntu/20.04/。


```{bash}
# 导入公共存储库的密钥
wget -qO- https://packages.microsoft.com/keys/microsoft.asc | sudo apt-key add -

# 为 SQL Server 2019 注册 Microsoft SQL Server Ubuntu 存储库
sudo add-apt-repository "$(wget -qO- https://packages.microsoft.com/config/ubuntu/20.04/mssql-server-2019.list)"

# sudo add-apt-repository "$(wget -qO- https://packages.microsoft.com/config/ubuntu/18.04/mssql-server-2019.list)"

# 安装 SQL Server
sudo apt-get update
sudo apt-get install -y mssql-server

# 验证服务是否运行
systemctl status mssql-server --no-pager
```

至于其他如安装sql server 命令行工具请[查阅官网安装](https://docs.microsoft.com/zh-cn/sql/linux/quickstart-install-connect-ubuntu?view=sql-server-linux-ver15&preserve-view=true)。


接下来我们就R语言与数据库的交互包展开介绍。



## DBI



### 安装

```{r eval=FALSE}
install.packages('DBI')
```

### 连接数据库

- 连接MS SQL SERVER 

通过以下代码即可连接到服务器172.16.88.2(即IP地址)的数据库，成功连接后即可与数据库交互。

```{r}
library(DBI)
con <- dbConnect(
  drv = odbc::odbc(), Driver = "SQL Server", server = "172.16.88.2",database = "spb", uid = "zhongyf", pwd = "Zyf123456"
)
```


如果你用windows系统，通过DBI包连接数据库发现乱码时，根据数据库编码指定encoding参数即可，常规在win下连接sqlserver设置encoding = "GBK"。

```{r }
library(DBI)
#根据数据库编码方式指定encoding
con <- dbConnect(
  drv = odbc::odbc(), Driver = "SQL Server", server = "172.16.88.2",
  database = "spb", uid = "zhongyf", pwd = "Zyf123456", encoding = "GBK"
)
# 查看本机可用驱动 如缺少相应驱动则安装，ODBC Driver 17 for SQL Server 就是个人安装的驱动

Drivers_tbl <- odbc::odbcListDrivers() 
head(Drivers_tbl)
```

查询数据库编码方式,从而选择连接数据库时相应的编码方式。

```{r}
con <- dbConnect(
  drv = odbc::odbc(), Driver = "ODBC Driver 17 for SQL Server",
  server = "172.16.88.2", database = "spb", uid = "zhongyf", pwd = "Zyf123456"
)

#查看编码是否是936 代表中文简体
sql <- "SELECT COLLATIONPROPERTY( 'chinese_prc_ci_as', 'codepage' )"

dbGetQuery(con,sql)

# same above
# dbExecute(con,sql)

# 用完后记得关闭数据库连接
DBI::dbDisconnect(con)
```



- 连接mysql

`MySQL()`函数来源`RMySQL`包，用来创建`<MySQLDriver>`驱动，以下代码可连接到阿里云的MySQL数据库。

```{r eval=FALSE}
library(RMySQL)
con <- dbConnect(MySQL(),
  dbname = "test", user = "test_admin", password = "30HL1234M7#￥lD6gxjB",
  host = "prd-public-mypersonal.mysql.test.zhangjiabei.rds.aliyuncs.com"
)
```

或者通过本地已安装驱动连接数据库

```{r eval=FALSE}
con <- DBI::dbConnect(odbc::odbc(),
  Driver = "MySQL ODBC 8.0 Unicode Driver",
  Server = "localhost", UID = "root", PWD = "123456", Database = "mysql",
  Port = 3306
)

```

mysql数据库默认端口是3306,访问不通时记得检查3306端口是否开放。

### 执行sql任务

dbGetQuery()函数处理由DBI包创建的con连接查询任务,dbExecute()执行一些数据库任务

```{r eval=FALSE}
# dbGetQuery 直接查询
res_table <- dbGetQuery(con,'select * from table') #直接获取sql查询结果

#dbReadTable直接读取
dbReadTable(con,'tbl_name') #直接读取数据库中某表

# dbSendQuery 执行一个查询任务 
res <- dbSendQuery(conn = con,statement = 'select * FROM tab')
dbFetch(res)
dbClearResult(res)

# dbExecute
dbExecute(con,'delete from table where num <=1000') #类似任务

# dbWriteTable()
# 上传数据,指定表名,需上传的数据框df,overwrite是否覆盖,append是否可追加
dbWriteTable(conn = con,name = '表名',value = df,overwrite=TURE,append=FALSE)
```


### 函数介绍

查看数据库信息,查看表名,删除表，关闭连接等常用操作.

```{r eval=FALSE}
con <- dbConnect(
  drv = odbc::odbc(),
  Driver = "ODBC Driver 17 for SQL Server", server = "172.16.88.2", 
  database = "spb", uid = "zhongyf", pwd = "Zyf123456", encoding = "GBK"
)

#查看数据版本连接信息
dbGetInfo(con)

# 数据库中的全部表名
dbListTables(con) #win下中文表名还是会乱码

# 删除表
dbRemoveTable(con,'tbl_name')

# 关闭连接
dbDisconnect(con)
```



## odbc包

官方介绍：Connect to ODBC databases (using the DBI interface)

记录到此时，并不时特别清晰`odbc`与`DBI`之间的关系。

odbc可以运用于包括(SQL Server, Oracle, MySQL,PostgreSQL,SQLite)等odbc驱动程序于`DBI`兼容的接口，相比起来`DBI`包适用范围更广。

1.安装包

```{r eval=FALSE}
#安装包
install.packages('odbc')
```

2.连接数据库

连接数据库需要注意时区、编码，尤其是涉及到时间时时区如果设置有误，可能导致上传数据错误。

当你在Win系统上连接Sql Server时，如果你使用的数据库是中文环境时，最好设置`encoding`参数。

如果是linux上通过odbc连接SqlServer,一般情况下可以不用设置编码。如果还是乱码，在连接字符中设置字符编码charset=zh_CN.GBK，设置为gbk会报错。

```{r eval=FALSE}
library(odbc)
con <- odbc::dbConnect(odbc(),
  Driver = "SQL Server", Server = "Vega", Database = "ghzy",
  Trusted_Connection = "True"
) # windows身份认证连接
# con <- dbConnect(odbc::odbc(), .connection_string = "Driver={SQL Server};
#                                 server=Vega;database=ghzy;uid=zhongyf;pwd=Zyf123456;", timeout = 10)
con
## Not run
# Win
con_spb <- dbConnect(odbc(), .connection_string = "driver={ODBC Driver 17 for SQL Server};server=172.16.88.2;database=spb;uid=zhongyf;pwd=Zyf123456", 
                     timeout = 10, timezone = "Asia/Shanghai",encoding = 'gbk')
#Linux
con_dd <- dbConnect(odbc::odbc(), .connection_string = "driver={ODBC Driver 17 for SQL Server};server=172.16.88.2;
                 database=aojo_dd;uid=wj;pwd=12qw#$ER;charset=zh_CN.GBK", timeout = 10)

```

3.查询

```{r  eval=FALSE}
dt <- odbc::dbGetQuery(con,'select * from DT')
head(dt)
```

4.写入数据库

```{r eval=FALSE}
odbc::dbWriteTable(con,name = '表名',value = dt,overwrite = T ) # 是否覆盖
odbc::dbWriteTable(con,name = '表名',value = dt,append = T ) # 是否追加
```


## RODBC包

RODBC包是R语言对ODBC数据库接口,可以连接所有的ODBC数据库.


1.安装包

```{r eval=FALSE}
install.packages('RODBC')
```


2.SQL SERVER 数据库举例

```{r eval=FALSE}
library(RODBC)
con <- odbcDriverConnect("driver={SQL Server};server=192.168.2.62;database=dbname;uid=zhongyf;pwd=Zyf123456")
con
RODBC::sqlQuery(con,'select * from test')
```

在WINDOWS机器上,需要知道本机是否有相应数据库的驱动程序.

* 查看本机上可用驱动

```{r eval=FALSE}
odbc::odbcListDrivers()

```

* 怎样安装驱动

请参照[驱动安装](https://github.com/r-dbi/odbc#installation)

ODBC for sql server driver 下载地址[地址](https://docs.microsoft.com/zh-cn/sql/connect/odbc/download-odbc-driver-for-sql-server?view=sql-server-ver15)

3.数据库字符串

请参照[数据库连接字符串](https://www.connectionstrings.com/)


```{r eval=FALSE}
#ODBC Driver 17 for SQL Server
cn <- odbcDriverConnect("Driver={ODBC Driver 17 for SQL Server};Server=localhost;Database=name;UID=username;PWD=123456;") #server 数据库 UID 数据库账户 PWD 数据库账户密码
```

sql server 请参照[sql server连接字符串](https://www.connectionstrings.com/microsoft-odbc-driver-17-for-sql-server/)



## ROracle包


在第一次安装这个包时遇到了很多困难，首先需要安装oracle客户端，其次配置好环境变量，最后安装包。R与Oracle的连接需要安装[Oracle Instant Client](https://www.oracle.com/database/technologies/instant-client.html)，

1. 安装客户端

安装oracle客户端，根据电脑的位数选择相应的32位或64位，根据要连接数据库版本，可以去官网自行下载，本机需要下载的[客户端地址](https://www.oracle.com/technetwork/database/enterprise-edition/downloads/112010-win64soft-094461.html)

2. 配置环境变量

根据自己所使用的系统，配置环境变量

```
OCI_INC='D:\app\zhongyf\product\11.2.0\client_1\oci\include'
OCI_LIB64='D:\app\zhongyf\product\11.2.0\client_1\BIN'
```

   

linxu上安装`Roracle`包，可以参考我的

微信公众号：宇飞的世界

[公众号文章连接](https://mp.weixin.qq.com/s/QLwedZ5mTybqSXdHMTGRIw)


3. 安装包

安装Roracle包需要配置相应版本的Rtools并添加到环境变量，另外配置两个oracle的环境变量。代码中有注释,按照自己安装版本路径修改。

由于ROracle依赖于Oracle Instant Client,安装之前一定要先安装好客户端。

```{r eval=FALSE}
install.packages('ROracle')
```

4. 连接数据库

`Roracle`可以通过`DBI`包链接，除了驱动和连接字符串有差异，其他部分一样。

```{r eval=FALSE}
library(ROracle)
drv <-dbDriver("Oracle")
connect.string <- '(DESCRIPTION =
                    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.16.88.129)(PORT = 1521))
                  (CONNECT_DATA =
                      (SERVER = DEDICATED)
                    (SERVICE_NAME = bidev)
                  ))' #连接字符串

con <- dbConnect(drv,username = "query", password = "query",dbname = connect.string)
```

5. 乱码问题 

如果连接oracle数据库，中文乱码设置以下环境变量即可，或者在启动文件配置该环境变量。

linux下可以在文件Renviron中添加，记得引号，路径为[/opt/R/4.0.2/lib/R/etc/Renviron]

```{r eval= FALSE}
# 查询数据库编码
select userenv('language') from dual
Sys.setenv(NLS_LANG="SIMPLIFIED CHINESE_CHINA.AL32UTF8")
```



## RMySQL包

RMySQL包的主要作用可以提供驱动与mysql数据库进行连接，在本机未安装mysql的驱动的情况下.该包正在逐渐被淘汰，可以使用RMariaDB包替换。

### 安装

Win系统下直接安装即可，其它平台下需提前安装依赖环境。

```{bash }
#On recent Debian or Ubuntu install libmariadbclient-dev

sudo apt-get install -y libmariadbclient-dev
#On Fedora, CentOS or RHEL we need mariadb-devel:

sudo yum install mariadb-devel
#On OS-X use mariadb-connector-c from Homebrew:

brew install mariadb-connector-c

```

```{r}
install.packages('RMySQL')
```


### 连接使用

连接数据库，与上述连接方式基本一致。

```{r eval=FALSE}
library(RMySQL)
con <- RMySQL::dbConnect(drv = RMySQL::MySQL(),host='localhost',dbname="mysql",username="root",password='123456')
```

`RMariaDB`包与`RMySQL`包用法基本一致，在连接时注意驱动的选择即可。

```{r eval=FALSE}
install.packages('RMariaDB')
library(RMariaDB)
con <- RMySQL::dbConnect(drv = RMariaDB::MariaDB() ,host='localhost',dbname="dbtest",username="root",password='123456')
```


## 常见问题

在使用R包连接数据库时有些常见的问题，整理如下：

### 乱码问题

R中中文乱码问题一直都很麻烦，并且常常遇见，尤其是使用win系统时。

- MS SQL SERVER 乱码

修改encoding参数，在win系统下，可以考虑使用RODBC包连接查询数据库，因为该包将自动转换编码，不会存在乱码问题。但是上传效率奇慢，为了减少包依赖保持代码一致性使用odbc连接数据库时遇到乱码，在连接数据库时设定encoding即可。

```{r eval = FALSE}
# win
con_spb <- dbConnect(odbc(),
  .connection_string =
    "driver={ SQLServer};server=172.16.88.2;database=spb;uid=zhongyf;pwd=Zyf123456", 
  timeout = 10, timezone = "Asia/Shanghai", encoding = "gbk"
)

# linux 
con_spb <- dbConnect(odbc(),
                     .connection_string =
                       "driver={ODBC Driver 17 for SQL Server};server=172.16.88.2;database=spb;uid=zhongyf;pwd=Zyf123456", 
                     timeout = 10, timezone = "Asia/Shanghai", encoding = "utf8"
)
```

- MySQL乱码

1.代码修改

```{r eval=FALSE}
#执行查询语句前执行
dbSendQuery(con,'SET NAMES gbk')
```

2.ODBC配置

如果是通过ODBC数据源连接,可通过配置需改,如下所示：

![ODBC配置截图](./picture/chap2/pic1.png)


### 无法连接问题

首先需要装mysql的驱动,确保`RMySQL`成功安装 如果是测试自己安装的mysql,可以先用Navicat连接,如果出现Authentication plugin 'caching_sha2_password' cannot be loaded的错误。

可能是由于 mysql8 之前的版本中加密规则是mysql_native_password,而在mysql8之后,加密规则是caching_sha2_password,通过修改加密规则可解决无法连接问题。

```{sql eval=FALSE}

--cmd 登录本地数据
mysql -u root -p
--输入密码
password: 

--执行命令
ALTER USER 'root'@'localhost' IDENTIFIED BY 'password' PASSWORD EXPIRE NEVER;   #修改加密规则 
---ALTER USER 'root'@'%' IDENTIFIED BY 'password' PASSWORD EXPIRE NEVER; 看账号权限注意与上面的区别

ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password'; #更新一下用户的密码 
```


### 远程连接

当你需要远程连接时，需要确保数据库的远程连接已经开启。在数据库中开启某账户远程连接权限,在公司的话，数据库连接问题咨询公司的IT人员。自己个人电脑上安装的MS SQL SERVER数据库需要自行开启远程连接。

另外如果是云服务器上搭建的数据库,需要开启数据库端口，如Mysql默认端口3306;如果是阿里云的Rds数据库,找DBA管理员要数据库地址以及端口信息。



## dbplyr

`dbplyr`将`dplyr`包的函数转化为`SQL`语句去服务器获取数据；在数据量较大、计算较多时，可以将远程连接数据库中的表当作内存中的数据框使用，当本机内存不够大时，这样做的好处不言而喻。

至于为什么使用`dbplyr`而不是直接编写`SQL`,因为：
 
 - `dbplyr`写起来简洁高效，基本跟用`dplyr`没有差别
 
 - 能利用数据库所在服务器的算力，配合上并行计算，在处理大量数据时，大大加快速度。
 
 - 不同数据库的语法存在差异，当源数据存在不同数据库时，用R的`dbplyr`包清洗数据时能加快效率
 
 - 通过`dplyr`动词方便实现复杂的逻辑，当过程越多越复杂时`dbplyr`的优势越明显，不用一层层嵌套语句。 
 



### 基础用法


```{r eval=FALSE}
library(dplyr)
library(dbplyr)

mf <- memdb_frame(x = 1, y = 2)

mf %>% 
  mutate(
    a = y * x, 
    b = a ^ 2,
  ) %>% 
  show_query()
```



```{r eval=FALSE}
library(dplyr)
#connect database
con <- DBI::dbConnect(RSQLite::SQLite(), path = ":memory:")
# 上传数据
copy_to(con, nycflights13::flights, "flights",
  temporary = FALSE, 
  indexes = list(
    c("year", "month", "day"), 
    "carrier", 
    "tailnum",
    "dest"
  )
)

# 查看库中全部表名
#dbListTables(con)

#tbl()引用表flights

flights_db <- tbl(con, "flights")
flights_db

# 开始查询
flights_db %>% select(year:day, dep_delay, arr_delay)
flights_db %>% filter(dep_delay > 240)
flights_db %>% 
  group_by(dest) %>%
  summarise(delay = mean(dep_time))
```

部分简单不复杂的sql语句可以用dplyr的语法代替.

```{r eval=FALSE}
tailnum_delay_db <- flights_db %>% 
  group_by(tailnum) %>%
  summarise(
    delay = mean(arr_delay,na.rm = T),
    n = n()
  ) %>% 
  arrange(desc(delay)) %>%
  filter(n > 100)
tailnum_delay_db
tailnum_delay_db %>% show_query()
tailnum_delay <- tailnum_delay_db %>% collect() #把数据从数据库加载到R内存中
```



### 无法正确转化


在使用过程中发现无法识别`lubridate`包的函数，但是`dbplyr`对于不认识的函数都将保留。

利用这个特性，可以使用数据库中原生的相关函数：如下所示，在Oracle中`to_date`函数

以下的自定义函数可以实现按照想要`group_by`的字段汇总金额、数量、吊牌额、折扣率等,其中关于时间周期的筛选就利用了该特性。

- date

```{r eval=FALSE}
#个人写的争对目前公司数仓写的包中获取销售数据的一段代码
get_sales_data <- function(con,...,start_date,end_date,brand_name,channel_type = NULL ,area_name = NULL,boss_name = NULL,category_name = NULL,shop_no = NULL){

  store_table <- store(con,brand_name = brand_name,channel_type = channel_type ,area_name = area_name,boss_name = boss_name,shop_no = shop_no) #门店信息
  
  sku_table <- sku(con,category_name =  category_name ) #商品信息
  
  tbl(con, in_schema("DW", "DW_SALE_SHOP_F")) %>% #DW层
    select(BILL_DATE1, SKU_NO, SHOP_NO, BILL_QTY, BILL_MONEY2, PRICE) %>%
    filter(between(
      BILL_DATE1, to_date(start_date, "yyyy-mm-dd"),
      to_date(end_date, "yyyy-mm-dd")
    )) %>%
    mutate(年 = year(BILL_DATE1), 月 = month(BILL_DATE1)) %>%
    inner_join(store_table) %>%
    inner_join(sku_table) %>%
    group_by(...) %>%
    summarise(
      金额 = sum(BILL_MONEY2, na.rm = TRUE),
      数量 = sum(BILL_QTY, na.rm = TRUE),
      吊牌金额 = sum(BILL_QTY * PRICE, na.rm = TRUE)) %>%
    collect() %>%
    mutate(折扣率:= 金额 / 吊牌金额) %>% 
    arrange(...)


  # return(res)
}

```


- like

```{r eval=FALSE}
mf %>% 
  filter(x %LIKE% "%foo%") %>% 
  show_query()
```


- 特殊用法

特殊情况可以使用`sql()`函数

```{r eval=FALSE}
mf %>% 
  transmute(factorial = sql("x!")) %>% 
  show_query()
```



## 参考资料


`DBI`包资料<https://dbi.r-dbi.org/reference/>

`dbplyr`包资料<https://dbplyr.tidyverse.org/>

rstudio关于数据库介绍 <https://db.rstudio.com/databases>

数据库连接字符串介绍  <https://www.connectionstrings.com/>

个人博客关于Roracle的安装介绍  <http://www.zhongyufei.com/2020/07/25/roracle-install/>

<https://www.r-consortium.org/blog/2017/05/15/improving-dbi-a-retrospect>

<!--chapter:end:02-database.Rmd-->

```{r include=FALSE, cache=FALSE}
set.seed(1014)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
 # cache = TRUE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)

options(dplyr.print_min = 6, dplyr.print_max = 6)
```
# Loop structure

实际场景中,当需要重复做某动作时,可运用循环结构。


## 简单示例

利用循环实现1到100连续相加求和

```{r}
total <- 0
for(i in 1:100){
  total <- total+i
}
print(paste0('1到100连续相加求和等于:',total))

# loop structure
# for (var in seq) {expr}
```


## 循环基础

### 循环结构 

R中有三种循环结构：

- Repeat

```{r}
i <- 1
total <- 0
repeat{
  total <- total+i
  i <- i+1
  if(i > 100){
    print(paste0('连续相加求和等于:',total))
    break
  }
}
```

- while

```{r}
i <- 1
total <- 0
while(i <= 1000){
  total <- total+i
  i <- i+1
}
print(paste0('1到1000连续相加求和等于:',total))
# not run
# sum(1:1000)
```

- for 

代码如示例所示

```{r message=FALSE,warning=FALSE}
library(tidyverse)
df <- tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

output <- vector("double", ncol(df))  # 1. output
for (i in seq_along(df)) {            # 2. sequence
  output[[i]] <- median(df[[i]])      # 3. body
}
output
```

循环中尽可能利用R中的向量化,比如指定output的长度,当数据量大的时候效率提升将比较明显,养成向量化的意识对提高代码效率有显著效果.

上面代码中 `vector`函数创建一个空向量带指定长度，有两个参数，第一个时向量类型('逻辑','整数','双精度','字符'等)，第二个是向量长度 `vector(length=5)`,类型默认是逻辑型.

`seq_along`可以`?seq`查看用法.

hadely 解释如下:

You might not have seen seq_along() before. It’s a safe version of the familiar 1:length(l), with an important difference: if you have a zero-length vector, seq_along() does the right thing:

```{r}
#wrong
seq_along(c())
1:length(c())

# generates the integer sequence 1, 2, ..., length(along.with). (along.with is usually abbreviated to along, and  seq_along is much faster.)
```

### next break 用法


- next 用法

```{r}
for(i in letters[1:6] ){
  if(i == "d"){
  next
  }
  print(i)
}
```

- break 用法

可以当条件满足时跳出循环常常与repeat循环结构配合使用。


### 嵌套循环


```{r}
# not run
v <- vector(length = 100)
for(i in 1:10){
  for(j in 1:10){
    v[i*j] = i * j 
  }
}
```


## 循环变化

### 修改已有对象

```{r}
res <- 1:100
for(i in seq_along(res)){
  res[i] <- res[i] * i
}
str(res)
```


### 循环模式

共有三种遍历向量的方法,之前展示的都是遍历数字索引`for (i in seq_along(xs))`,并使用提取值`x[[i]]`.还有两种方式:

- 循环遍历元素

`for(i in xs)`,例如我们需要保存文件时,可以利用这种循环模式

- 遍历名称

`for (nm in names(xs))`,我们可以使用`x[[nm]]` 该名称访问.当我们要在文件名中使用名称时会比较方便.

```{r eval=FALSE}
results <- vector("list", length(x))
names(results) <- names(x)
```

数字索引的循环模式最常用,因为可以根据位置提取名称和值.

```{r eval=FALSE}
for (i in seq_along(x)) {
  name <- names(x)[[i]]
  value <- x[[i]]
}
```



### 未知长度输出

有时候我们的循环我们不确定输出的长度是多少.这样会逐步增加向量的长度,如下所示：

```{r}
means <- c(0, 1, 2)

output <- double()
for (i in seq_along(means)) {
  n <- sample(100, 1)
  output <- c(output, rnorm(n, means[[i]]))
}
str(output)
```

但是这种方式浪费时间，当数据量大时候效率会很低下.因为时间复杂度为($O(n^2)$).解决方案是将结果保存在列表中,然后在完成循环后合并为单个向量:

```{r}
out <- vector("list", length(means))
for (i in seq_along(means)) {
  n <- sample(100, 1)
  out[[i]] <- rnorm(n, means[[i]])
}
str(out)
str(unlist(out)) #unlist将列表向量化
```


<!--chapter:end:08-loop.Rmd-->

```{r include=FALSE, cache=FALSE}
set.seed(1014)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
 # cache = TRUE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)

options(dplyr.print_min = 6, dplyr.print_max = 6)
```
# Iteration

常常需要重复操作同样的功能函数，这时可以用迭代来实现。purrr包提供了一套完整的函数来处理循环迭代,可以有效减少重复性工作和代码。

<https://purrr.tidyverse.org/>

## 简单用法


- map


用map循环迭代,map函数始终返回list对象。

```{r message=FALSE,warning=FALSE}
library(tidyverse)

# define function
addTen <- function(.x) {
  return(.x + 10)
}

map(.x = c(1, 4, 7), .f = addTen)
# not run
# map(c(1, 4, 7), addTen) # same above
```





- map_dbl

用map_dbl循环迭代，map_dbl函数返回vector。

```{r}
#library(purrr)
add1 <- function(x) {
  (x+1)*x
}
result1 <- map_dbl(1:1000,add1) # maP_dbl 输出结果为向量

#for版本
result2 <- vector(length = 1000)
for(i in 1:1000){
  result2[i] <- (i+1) * i
}
# test 
#not run
#table(result1 == result2)
# all equal
identical(result1,result2)
```


## map系列常用函数


- map_chr

`map_chr(.x, .f)` ,map_chr 返回对象为字符串

- map_dbl

`map_dbl(.x, .f)` ,map_dbl 返回数字向量(双精度)

- map_df

`map_df(.x, .f)`,map_df 返回对象为数据框,类似函数 `map_dfr(.x,.f)`,`map_dfc(.x,.f)`

- map_gl

`map_lgl(.x, .f)` 返回逻辑向量

- map_int

`map_int(.x, .f, ...)` 返回整数


map_df()函数示例

```{r}
# 采用匿名函数
map_df(c(1, 4, 7), function(.x) {
  return(data.frame(old_number = .x, 
                    new_number = addTen(.x)))
})

#同上
#step1 定义函数
make_dataframe <- function(x){
  data.frame(old_number = x,new_number = addTen(x))
}
#step2 计算
map_df(c(1,4,7),make_dataframe)

```


## 归约累计函数

reduce、accumulate()函数用法介绍.

- reduce

在实际工作中,我长用reduce函数实现merge()功能。示例如下：

```{r}
reduce(1:100,`+`)
reduce(100:1,`-`)
```

将函数功能不断运用到list上得到最后结果。

```{r eval=FALSE}
n <- 10
dt1 <- data.frame(a=letters[n],b1=rnorm(n))
dt2 <- data.frame(a=letters[n],b2=rnorm(n))
dt3 <- data.frame(a=letters[n],b3=rnorm(n))
dt4 <- data.frame(a=letters[n],b4=rnorm(n))

reduce(list(dt1,dt2,dt3,dt4),merge)
# not run
# reduce(list(dt1,dt2,dt3,dt4),merge,by='a') same above

```


- accumulate

```{r}
1:5 %>% accumulate(`+`)
accumulate(letters[1:5], paste, sep = ".")
```


## 安全函数 

possibly() 和 safely(),当循环时候遇到错误报错导致整个程序停止,这不是我们想要的。

```{r eval=FALSE}
l <- list(1,2,3,4,'5')
map(l,function(.x) .x+1)

```

以上程序将会报错,不能正确得到结果。

```{r}
l <- list(1,2,3,4,'5')
test_fun <- safely(function(.x) .x+1)
map(l,test_fun)
```

用safely()函数将原始function包裹起来,即使执行过程中遇到错误也可以完成整个任务,不会因为中途报错停止,在大型循环过程中,如爬虫过程中比较实用。

## 映射多个参数 

map2 和 pmap 函数可以映射两个及以上参数。

```{r}
li1 <- list(1,3,5)
li2 <- list(2,4,6)
map2(li1,li2,`+`)
```

类似函数 map2_dbl,map2_chr,map2_dfr等等。

```{r}
li1 <- list(1,3,5)
li2 <- list(2,4,6)
li3 <- list(2,4,6)
li1 <- c(1,3,5)
li2 <- c(2,4,6)
li3 <- c(2,3,4)
li <- list(li1,li2,li3)
pmap(li,sum)
```

同上有pmap_int,pmap_dbl,pmap_dfr等函数。


## 其他函数介绍

- flatten

flatten()系列函数可以将列表输出为稳定类型。purrr package 自带Examples。

```{r eval=FALSE}
x <- rerun(2, sample(4))
x
x %>% flatten()
x %>% flatten_int()
# You can use flatten in conjunction with map
x %>% map(1L) %>% flatten_int()
# But it's more efficient to use the typed map instead.
x %>% map_int(1L)
```

- imap

imap()系列函数官方描述：

imap_xxx(x, ...), an indexed map, is short hand for map2(x, names(x), ...) if x has names, or map2(x, seq_along(x), ...) if it does not. This is useful if you need to compute on both the value and the position of an element.


imap,当x有names(x)或者seq_along(x)属性,imap是map2的另一种表达方式。

使用公式快捷方式时,第一个参数是值(.x),第二个参数是位置/名称(.y)。

详情请查看:?imap

示例1：

```{r}
imap_chr(sample(10), ~ paste0(.y, ": ", .x))
```

sample(10),没有names(),只有长度信息。转化成map2表达如下:


```{r}
#same above

map2_chr(sample(10),1:10,~paste0(.y,": ",.x)) # 第二个list 为位置信息.

```


<!--chapter:end:09-iteration.Rmd-->

```{r include=FALSE, cache=FALSE}
set.seed(1014)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
 # cache = TRUE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)

options(dplyr.print_min = 6, dplyr.print_max = 6)
```
# define function


函数功能使我们尽可能避免复制粘贴代码,而且需要更改的时候不需要大面积修改代码仅需要调整函数参数,使代码整体更加模块化.


假设有工作任务需要给商品SKU排名,在代码中需要重复以下代码5次,当区间需要修改的时候就是灾难.

原始代码示例如下:

```{r message=FALSE,warning=FALSE}
library(tidyverse)
num <- sample(1:1000,1000)
res1 <- if_else(num <= 50,"1-50",
                if_else(num <= 100,"51-100",
                        if_else(num <= 150,"101-150",
                                if_else(num <= 200 ,"151-200",
                                        if_else(num >200,"200以上",'其他')))))


# same above
# case_when(num <= 50 ~ '1-50',
#           num <= 100 ~ '51-100',
#           num <= 150 ~ '101-150',
#           num <= 200 ~ '151-200',
#           num > 100 ~ '200以上'
#           )

# 个人倾向data.table 
# data.table::fifelse()
# data.table::fcase() 是sql中case when的实现
```

函数化后代码示例如下:

当需要修改区间时候仅仅只需要调整参数,而不必大量修改代码,当在脚本中需要调用多次时,能简洁代码.

```{r eval=FALSE}
# 排名区间函数
#library(tidyverse)
cut_function <- function(vecto,x,n){
  vec <- c(0)
  for(i in 1:n){
    kong <-  i*x
    vec <- c(vec,kong)
  }
  vec <- c(vec,Inf)
  labels <- c()
  j <- 1
  
  while (j<=n) {
    labels[j] <- str_c(vec[j]+1,"-",vec[j+1])
    j <- j+1
  }
  labels <- c(labels,paste0(vec[j],'以上'))
  res <- cut(x = vecto,breaks = vec,labels = labels) %>% as.character()
}

res2 <- cut_function(num,50,4)

# identical(res1,res2)
# > TRUE
```


[参考资料](https://r4ds.had.co.nz/functions.html)



## 简单示例


给函数取一个合适名字是很难的事情,徐尽可能从函数名称看出你实现的功能.

```{r}
add_ten <- function(x){
  res <- x+10
  return(res) #可以不用显示返回
}
add_ten(1)
```

写函数时需要考虑函数使用情况,尽可能考虑容错情况,当输入不符合预期时能友好提示错误.

```{r}
add_ten <- function(x){
  if(is.numeric(x)==TRUE){
    x+10
  } else {
    print('Error,请输入数字')
  }
}
```

## 条件执行

```{r}
has_name <- function(x) {
  nms <- names(x)
  if (is.null(nms)) {
    rep(FALSE, length(x))
  } else {
    !is.na(nms) & nms != ""
  }
}
```

### 多条件执行

```{r eval=FALSE}
if (this) {
  # do that
} else if (that) {
  # do something else
} else {
  # 
}
```

当需要很多if时可考虑用switch()功能

```{r eval=FALSE}
function(x, y, op) {
   switch(op,
     plus = x + y,
     minus = x - y,
     times = x * y,
     divide = x / y,
     stop("Unknown op!")
   )
 }
```


## 函数参数

函数的参数通常分为两大类,一组是提供要计算的参数,另外一组提供计算时的细节参数.


```{r}
mean_ci <- function(x, conf = 0.95) {
  se <- sd(x) / sqrt(length(x))
  alpha <- 1 - conf
  mean(x) + se * qnorm(c(alpha / 2, 1 - alpha / 2))
}
x <- runif(100)
mean_ci(x)
mean_ci(x, conf = 0.99)
```


### 参数名称

参数的名称很重要,方便我们理解参数含义,调用时不会混乱.以下时几个重要的参数名称

- x, y, z: vectors.
- w: a vector of weights.
- df: a data frame.
- i, j: numeric indices (typically rows and columns).
- n: length, or number of rows.
- p: number of columns.


### 检查参数值

在写函数时,并不清楚最终函数的输出,在编写函数时进行约束是有必要的.


```{r}
wt_mean <- function(x, w) {
  if (length(x) != length(w)) {
    stop("`x` and `w` must be the same length", call. = FALSE)
  }
  sum(w * x) / sum(w)
}
```

### ...参数

R中的许多函数都能接受任意数量的输入：

```{r}
sum(1,2,3,4,5,6,7,8,9,10)
stringr::str_c('a','b','d','e','f','g','h')
```

下面的例子中

```{r}
commas <- function(...) stringr::str_c(..., collapse = ", ")
commas(letters[1:10])
#> [1] "a, b, c, d, e, f, g, h, i, j"

rule <- function(..., pad = "-") {
  title <- paste0(...)
  width <- getOption("width") - nchar(title) - 5
  cat(title, " ", stringr::str_dup(pad, width), "\n", sep = "")
}
rule("Important output")

```



## 返回值

###  显式返回

函数返回的通常是最后一句代码的计算结果,可以显式利用return()提前返回。但是R for Data Science 中作者说:
'我认为最好不要使用return()来表示,您可以使用更简单的解决方案尽早返回'

- A common reason to do this is because the inputs are empty:

```{r}
complicated_function <- function(x, y, z) {
  if (length(x) == 0 || length(y) == 0) {
    return(0)
  }
  # Complicated code here
}
```


- Another reason is because you have a if statement with one complex block and one simple block. For example, you might write an if statement like this:

```{r}
f <- function() {
  if (x) {
    # Do 
    # something
    # that
    # takes
    # many
    # lines
    # to
    # express
  } else {
    # return something short
  }
}
```

### 编写管道函数

管道函数有两种基本类型: transformations and side-effects。使用transformations时，会将对象传递到函数的第一个参数，然后返回修改后的对象。使用side-effects时,不会对传递的对象进行转换。相反，该函数对对象执行操作，例如绘制图或保存文件。副作用函数应该“无形地”返回第一个参数，以便在不打印它们时仍可以在管道中使用它们。例如，以下简单函数在数据框中打印缺失值的数量：

以上从 R for Data Science 中翻译得来。

```{r}
show_missings <- function(df) {
  n <- sum(is.na(df))
  cat("Missing values: ", n, "\n", sep = "")
  
  invisible(df)
}
```

以交互invisible()方式调用它,则意味着输入df不会被打印出来:

```{r}
show_missings(mtcars)
```

但是结果仍存在，默认情况下只是不打印显示出来:

```{r}
x <- show_missings(mtcars) 
class(x)
dim(x)
```

在管道中继续使用

```{r}
mtcars %>% 
  show_missings() %>% 
  mutate(mpg = ifelse(mpg < 20, NA, mpg)) %>% 
  show_missings() 
```


## 环境

环境是复杂的,建议阅读原文.

The last component of a function is its environment. This is not something you need to understand deeply when you first start writing functions. However, it’s important to know a little bit about environments because they are crucial to how functions work. The environment of a function controls how R finds the value associated with a name. For example, take this function:


```{r}
f <- function(x) {
  x + y
} 
```

在很多其他的编程语言中这样定义函数是错误的，因为没有定义`y`.在R中,这是有效的代码,因为R使用称为` lexical scoping `的方式寻找关联值.在函数内部没有定义`y`,将在上一层环境中查看`y`:

```{r}
y <- 100
f(10)

y <- 1000
f(10)
```

具体详细的资料请查阅：

<https://r4ds.had.co.nz/functions.html#environment>

<http://adv-r.had.co.nz/>


## 拓展部分


在我之前工作中遇到需要分组计算时,我想要编写一个函数实现某些功能,但是分组的group_by()字段不一样时,导致代码没办法复用。

参考资料：<https://dplyr.tidyverse.org/articles/programming.html>

```{r eval=FALSE}
#library(tidyverse)
mean_mpg = function(data, group_col) {
  data %>% 
    group_by(group_col) %>%
    summarize(mean_mpg = mean(mpg))
}
mtcars %>% mean_mpg(cyl)
mtcars %>% mean_mpg(gear)
```

当编写如下函数时,代码将成功运行

```{r}
#自定义函数
my_summarise3 <- function(data, group_var,mean_var, sd_var) {
  data %>% 
    group_by({{ group_var }}) %>% 
    summarise(mean = mean({{ mean_var }}), sd = mean({{ sd_var }}))
}

res1 <- my_summarise3(data = mtcars,group_var = cyl,mean_var = carb,sd_var = gear)
my_summarise3(data = mtcars,group_var = am,mean_var = carb,sd_var = gear)
#正常写法
res2 <- mtcars %>% 
  group_by(cyl) %>% 
  summarise(mean=mean(carb),sd=mean(gear))

identical(res1,res2)

#res1 和res2 结果完全一致
```

 
以上my_summarise3()函数可以按照需求任意指定聚合汇总字段。

<!--chapter:end:10-function.Rmd-->

